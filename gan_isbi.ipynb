{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/lung-lesion_2/scale-25pc/29-041-Izd2-w35-He-les2.jpg\n",
      "images/lung-lesion_2/scale-25pc/29-041-Izd2-w35-He-les2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "def read_csv_file():\n",
    "\n",
    "\n",
    "    DATASET_MEDIUM_DIR = 'can_be_train.csv'\n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "    imgs_dirs = []\n",
    "    dataset_read_result = pd.read_csv(DATASET_MEDIUM_DIR)\n",
    "    i = 0\n",
    "    for each_img_dir, \\\n",
    "        each_landmarks_dir, \\\n",
    "        each_target_image, \\\n",
    "        each_target_landmarks, \\\n",
    "        each_status in zip(dataset_read_result['Source image'],\n",
    "                           dataset_read_result['Source landmarks'],\n",
    "                           dataset_read_result['Target image'],\n",
    "                           dataset_read_result['Target landmarks'],\n",
    "                           dataset_read_result['status']):\n",
    "        each_img_dir = 'images/' + each_img_dir\n",
    "        each_landmarks_dir = 'landmarks/' + each_landmarks_dir\n",
    "        each_target_image = 'images/' + each_target_image\n",
    "        each_target_landmarks = 'landmarks/' + each_target_landmarks\n",
    "\n",
    "        dataset_read_result.set_value(index=i, col='Source image', value=each_img_dir)\n",
    "        dataset_read_result.set_value(index=i, col='Source landmarks', value=each_landmarks_dir)\n",
    "        dataset_read_result.set_value(index=i, col='Target image', value=each_target_image)\n",
    "        dataset_read_result.set_value(index=i, col='Target landmarks', value=each_target_landmarks)\n",
    "\n",
    "        imgs_dirs.append(each_img_dir)\n",
    "        i = i + 1\n",
    "\n",
    "    print(dataset_read_result['Source image'][1])\n",
    "    print(imgs_dirs[1])\n",
    "    return dataset_read_result\n",
    "\n",
    "\n",
    "dataset_read_result = read_csv_file()\n",
    "\n",
    "# the first 10\n",
    "source_image_array = dataset_read_result['Source image']\n",
    "target_image_array = dataset_read_result['Target image']\n",
    "source_image_landmarks = dataset_read_result['Source landmarks']\n",
    "target_image_landmarks = dataset_read_result['Target landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        #使用super()方法调用基类的构造器，即nn.Module.__init__(self)\n",
    "        super(Generator,self).__init__()\n",
    "        # The first layer \n",
    "        # Input channels = 3, output channels = 6 ,,5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1) \n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        self.reg_1 = torch.nn.Linear(128 * 16 * 16, 700)\n",
    "        self.reg_1_1 = torch.nn.Linear(700, 70)\n",
    "        # self.reg_1_2 = torch.nn.Linear(70, 70)\n",
    "        \n",
    "        \n",
    "        self.deconv1=nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.bn_deconv1=nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.reg_2 = torch.nn.Linear(64 * 17 * 17, 700)\n",
    "        self.reg_2_1 = torch.nn.Linear(700, 70)\n",
    "        # self.reg_2_2 = torch.nn.Linear(70, 70)\n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        # self.fc2 = torch.nn.Linear(78, 78)\n",
    "        \n",
    "        ########### end of the first\n",
    "        self.conv1_y = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1) \n",
    "        self.bn1_y=nn.BatchNorm2d(32)\n",
    "        self.pool_1_y = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        \n",
    "        self.conv2_y = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2_y = nn.BatchNorm2d(64)\n",
    "        self.pool_2_y  = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.conv3_y = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.reg_1_y = torch.nn.Linear(128 * 16 * 16, 70)\n",
    "        self.reg_1_1_y = torch.nn.Linear(70, 70)\n",
    "        \n",
    "        self.deconv1_y = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.bn_deconv1_y = nn.BatchNorm2d(64)\n",
    "        self.conv4_y = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4_y=nn.BatchNorm2d(64)\n",
    "        self.reg_2_y = torch.nn.Linear(64 * 17 * 17, 70)\n",
    "        self.reg_2_1_y = torch.nn.Linear(70, 70)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        #Size changes from (3, height, weight) to (6, height, weight)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        #Size changes from (6, height, weight) to (6, height/2, weight/2)\n",
    "        x = self.pool_1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool_2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (6, height/2, weight/2) to (1, 6*height/2*weight/2)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x_1 = x.view(-1, 128 * 16 * 16)\n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 4608) to (1, 78)\n",
    "        x_1 = self.reg_1(x_1)\n",
    "        x_1 = self.reg_1_1(x_1)\n",
    "        \n",
    "        x = F.relu(self.bn_deconv1(self.deconv1(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x_2 = x.view(-1, 64 * 17 * 17)\n",
    "        x_2 = self.reg_2(x_2)\n",
    "        x_2 = self.reg_2_1(x_2)\n",
    "        #### end of the first image\n",
    "        \n",
    "        ### the first guess using the samiliar network\n",
    "        y = F.relu(self.bn1(self.conv1(y)))\n",
    "        y = self.pool_1(y)\n",
    "        y = F.relu(self.bn2(self.conv2(y)))\n",
    "        y = self.pool_2(y)\n",
    "        y = F.relu(self.conv3(y))\n",
    "        \n",
    "        y_1 = y.view(-1, 128 * 16 * 16)\n",
    "        y_1 = self.reg_1(y_1)\n",
    "        y_1 = self.reg_1_1(y_1)\n",
    "        \n",
    "        y = F.relu(self.bn_deconv1(self.deconv1(y)))\n",
    "        y = F.relu(self.bn4(self.conv4(y)))\n",
    "        y_2 = y.view(-1, 64 * 17 * 17)\n",
    "        y_2 = self.reg_2(y_2)\n",
    "        y_2 = self.reg_2_1(y_2)\n",
    "        \n",
    "        \n",
    "        # x = F.relu(self.fc2(x))\n",
    "        return x_1,x_2,y_1,y_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        self.reg_1_1 = torch.nn.Linear(70, 700)\n",
    "        self.reg_1_2 = torch.nn.Linear(70, 700)\n",
    "        self.reg_2_1 = torch.nn.Linear(70, 700)\n",
    "        self.reg_2_2 = torch.nn.Linear(70, 700)\n",
    "        self.cos_1 = nn.CosineSimilarity(eps=1e-6)\n",
    "        self.cos_2 = nn.CosineSimilarity(eps=1e-6)\n",
    "        \n",
    "        self.dense_1 = torch.nn.Linear(1, 1)\n",
    "        self.dense_2 = torch.nn.Linear(1, 1)\n",
    "        \n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.sigmoid3 = nn.Sigmoid()\n",
    "    def forward(self,x_1,x_2,y_1,y_2):\n",
    "        \n",
    "        x_1 = self.reg_1_1(x_1)\n",
    "        x_2 = self.reg_1_2(x_2)\n",
    "        y_1 = self.reg_2_1(y_1)\n",
    "        y_2 = self.reg_2_2(y_2)\n",
    "        x = self.cos_1(x_1,x_2)\n",
    "        y = self.cos_2(y_1,y_2)\n",
    "        \n",
    "        x = self.dense_1(x)\n",
    "        y = self.dense_2(y)\n",
    "        \n",
    "        print(x)\n",
    "        output = self.sigmoid1(x)+self.sigmoid2(y)\n",
    "        output = self.sigmoid3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Begin  0 epoch\n",
      "tensor([0.9376], grad_fn=<AddBackward0>)\n",
      "tensor([0.9192], grad_fn=<AddBackward0>)\n",
      "tensor([0.9142], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "transform_1 = transforms.Compose([transforms.Resize([512,512]),\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "loader = torch.utils.data.DataLoader(source_image_array, batch_size=1,shuffle=True, num_workers=2)\n",
    "generator=Generator()\n",
    "discriminator=Discriminator()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "loss = nn.MSELoss()# MSELoss可换为\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(1):\n",
    "    print(\"Begin \",epoch,\"epoch\")\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        # print(\"Begin \",epoch,\"epoch\")\n",
    "        inputs = data\n",
    "        # source_image = plt.imread(inputs[0])\n",
    "        \n",
    "        ## Train with all-real batch\n",
    "        discriminator.zero_grad()\n",
    "        label = torch.full((1,), real_label)\n",
    "        \n",
    "        \n",
    "        source_image_landmark = source_image_landmarks[i]\n",
    "        current = pd.read_csv(source_image_landmark)\n",
    "        source_X = current['X']\n",
    "        source_Y = current['Y']\n",
    "#         # X = X.transpose()\n",
    "        source_X = torch.FloatTensor(source_X[:70])\n",
    "        source_X = source_X.unsqueeze(0)\n",
    "        \n",
    "        source_Y = torch.FloatTensor(source_Y[:70])\n",
    "        source_Y = source_Y.unsqueeze(0)\n",
    "\n",
    "        target_image_landmark = target_image_landmarks[i]\n",
    "        current = pd.read_csv(target_image_landmark)\n",
    "        target_X = current['X']\n",
    "        target_Y = current['Y']\n",
    "        \n",
    "        target_X = torch.FloatTensor(target_X[:70])\n",
    "        target_X = target_X.unsqueeze(0)\n",
    "        \n",
    "        target_Y = torch.FloatTensor(target_Y[:70])\n",
    "        target_Y = target_Y.unsqueeze(0)\n",
    "\n",
    "        output = discriminator(source_X,source_Y,target_X,target_Y).view(-1)\n",
    "        # print(output)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output,label)    \n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward(retain_graph=True)\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Train with all-fake batch\n",
    "        \n",
    "        source_image = Image.open(inputs[0]).convert('RGB')\n",
    "        source_image1 = transform_1(source_image)\n",
    "        image_tensor= source_image1.unsqueeze(0)    \n",
    "        image_tensor = Variable(image_tensor)\n",
    "        target_image = Image.open(target_image_array[i]).convert('RGB')\n",
    "        target_image1 = transform_1(target_image)\n",
    "        target_image_tensor= target_image1.unsqueeze(0)\n",
    "        target_image_tensor = Variable(target_image_tensor)\n",
    "        x_1,x_2,y_1,y_2 = generator(image_tensor,target_image_tensor)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        output = discriminator(x_1,x_2,y_1,y_2).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward(retain_graph=True)\n",
    "        D_G_z1 = output.mean().item()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        generator.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = discriminator(x_1,x_2,y_1,y_2).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward(retain_graph=True)\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
