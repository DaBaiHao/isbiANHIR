{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可以使用torchvision中提供的API快速的创建一个reader实现在训练的过程中不断地读取图像和类别信息\n",
    "**transform** 表示把读取的图像resize到227 * 227并转换为PyTorch中的tensor类型，同时将其标准化到\\[ -1 , 1 \\]之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/lung-lesion_2/scale-25pc/29-041-Izd2-w35-He-les2.jpg\n",
      "images/lung-lesion_2/scale-25pc/29-041-Izd2-w35-He-les2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "def read_csv_file():\n",
    "\n",
    "\n",
    "    DATASET_MEDIUM_DIR = 'can_be_train.csv'\n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "    imgs_dirs = []\n",
    "    dataset_read_result = pd.read_csv(DATASET_MEDIUM_DIR)\n",
    "    i = 0\n",
    "    for each_img_dir, \\\n",
    "        each_landmarks_dir, \\\n",
    "        each_target_image, \\\n",
    "        each_target_landmarks, \\\n",
    "        each_status in zip(dataset_read_result['Source image'],\n",
    "                           dataset_read_result['Source landmarks'],\n",
    "                           dataset_read_result['Target image'],\n",
    "                           dataset_read_result['Target landmarks'],\n",
    "                           dataset_read_result['status']):\n",
    "        each_img_dir = 'images/' + each_img_dir\n",
    "        each_landmarks_dir = 'landmarks/' + each_landmarks_dir\n",
    "        each_target_image = 'images/' + each_target_image\n",
    "        each_target_landmarks = 'landmarks/' + each_target_landmarks\n",
    "\n",
    "        dataset_read_result.set_value(index=i, col='Source image', value=each_img_dir)\n",
    "        dataset_read_result.set_value(index=i, col='Source landmarks', value=each_landmarks_dir)\n",
    "        dataset_read_result.set_value(index=i, col='Target image', value=each_target_image)\n",
    "        dataset_read_result.set_value(index=i, col='Target landmarks', value=each_target_landmarks)\n",
    "\n",
    "        imgs_dirs.append(each_img_dir)\n",
    "        i = i + 1\n",
    "\n",
    "    print(dataset_read_result['Source image'][1])\n",
    "    print(imgs_dirs[1])\n",
    "    return dataset_read_result\n",
    "\n",
    "\n",
    "dataset_read_result = read_csv_file()\n",
    "\n",
    "# the first 10\n",
    "source_image_array = dataset_read_result['Source image']\n",
    "target_image_array = dataset_read_result['Target image']\n",
    "source_image_landmarks = dataset_read_result['Source landmarks']\n",
    "target_image_landmarks = dataset_read_result['Target landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize([227,227]),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "loader = torch.utils.data.DataLoader(source_image_array, batch_size=1,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_landmarks(image, X,Y):\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(X, Y, s=10, marker='.', c='r')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "plt.figure()\n",
    "source_image_1 = source_image_array[0]\n",
    "source_image_landmark = source_image_landmarks[0]\n",
    "current = pd.read_csv(source_image_landmark)\n",
    "X = current['X']\n",
    "Y = current['Y']\n",
    "\n",
    "show_landmarks(io.imread(source_image_1),X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练\n",
    "由于开始PIL读取图片导致图片过大，改了PIL文件Image.py中的MAX_IMAGE_PIXELS=none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算 output size feature size\n",
    "output = int((in_size - kernel_size + 2*(padding)) / stride) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "254\n"
     ]
    }
   ],
   "source": [
    "def outputSize(in_size, kernel_size, stride, padding):\n",
    "    output = int((in_size - kernel_size + 2*(padding)) / stride)+1 \n",
    "    return output\n",
    "print(outputSize(512,3,2,0))\n",
    "print(outputSize(255,2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class regNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        #使用super()方法调用基类的构造器，即nn.Module.__init__(self)\n",
    "        super(regNet_2D,self).__init__()\n",
    "        # The first layer \n",
    "        # Input channels = 3, output channels = 6 ,,5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1) \n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        self.reg_1 = torch.nn.Linear(128 * 16 * 16, 700)\n",
    "        self.reg_1_1 = torch.nn.Linear(700, 70)\n",
    "        # self.reg_1_2 = torch.nn.Linear(70, 70)\n",
    "        \n",
    "        \n",
    "        self.deconv1=nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.bn_deconv1=nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.reg_2 = torch.nn.Linear(64 * 17 * 17, 700)\n",
    "        self.reg_2_1 = torch.nn.Linear(700, 70)\n",
    "        # self.reg_2_2 = torch.nn.Linear(70, 70)\n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        # self.fc2 = torch.nn.Linear(78, 78)\n",
    "        \n",
    "        ########### end of the first\n",
    "        self.conv1_y = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1) \n",
    "        self.bn1_y=nn.BatchNorm2d(32)\n",
    "        self.pool_1_y = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        \n",
    "        self.conv2_y = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2_y = nn.BatchNorm2d(64)\n",
    "        self.pool_2_y  = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.conv3_y = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.reg_1_y = torch.nn.Linear(128 * 16 * 16, 70)\n",
    "        self.reg_1_1_y = torch.nn.Linear(70, 70)\n",
    "        \n",
    "        self.deconv1_y = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.bn_deconv1_y = nn.BatchNorm2d(64)\n",
    "        self.conv4_y = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4_y=nn.BatchNorm2d(64)\n",
    "        self.reg_2_y = torch.nn.Linear(64 * 17 * 17, 70)\n",
    "        self.reg_2_1_y = torch.nn.Linear(70, 70)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        #Size changes from (3, height, weight) to (6, height, weight)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        #Size changes from (6, height, weight) to (6, height/2, weight/2)\n",
    "        x = self.pool_1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool_2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (6, height/2, weight/2) to (1, 6*height/2*weight/2)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x_1 = x.view(-1, 128 * 16 * 16)\n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 4608) to (1, 78)\n",
    "        x_1 = self.reg_1(x_1)\n",
    "        x_1 = self.reg_1_1(x_1)\n",
    "        \n",
    "        x = F.relu(self.bn_deconv1(self.deconv1(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x_2 = x.view(-1, 64 * 17 * 17)\n",
    "        x_2 = self.reg_2(x_2)\n",
    "        x_2 = self.reg_2_1(x_2)\n",
    "        #### end of the first image\n",
    "        \n",
    "        ### the first guess using the samiliar network\n",
    "        y = F.relu(self.bn1(self.conv1(y)))\n",
    "        y = self.pool_1(y)\n",
    "        y = F.relu(self.bn2(self.conv2(y)))\n",
    "        y = self.pool_2(y)\n",
    "        y = F.relu(self.conv3(y))\n",
    "        \n",
    "        y_1 = y.view(-1, 128 * 16 * 16)\n",
    "        y_1 = self.reg_1(y_1)\n",
    "        y_1 = self.reg_1_1(y_1)\n",
    "        \n",
    "        y = F.relu(self.bn_deconv1(self.deconv1(y)))\n",
    "        y = F.relu(self.bn4(self.conv4(y)))\n",
    "        y_2 = y.view(-1, 64 * 17 * 17)\n",
    "        y_2 = self.reg_2(y_2)\n",
    "        y_2 = self.reg_2_1(y_2)\n",
    "        \n",
    "        \n",
    "        # x = F.relu(self.fc2(x))\n",
    "        return x_1,x_2,y_1,y_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(50787896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(51339972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(50990900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(50078088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(48119200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(47758352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(46838344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(48244520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(47296096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(46909072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(84083000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(79631896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(77762736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(84000352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(74682072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(72756144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(79034480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68107768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(74217808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(72260448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68305216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68509992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68355032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(71582264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68779536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68271032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(71214088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(68367200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(70734552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(70052752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7965353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8154040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8299175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7545649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6138777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6490343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5692527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6637958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5924329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6210186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13249193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13125120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13336506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13072640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12266151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12791606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12160588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12468460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12031728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12297451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19532184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19364256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20198352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18433406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18569100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19475768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17741204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19274936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17511120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18449174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9167826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9071157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9279705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9002309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8975144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8872914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8657796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8896364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8538416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8777431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12212349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13008732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11570311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12527923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10736225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9229041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9066648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9462128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9619490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7566753.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25095228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30515804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23883674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27187810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23165406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20841458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17427838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13911205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7967825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9796020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9293861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7992531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6312632.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6346587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7231235.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6616805.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6245799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5127642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4790929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5315351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4512962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3615353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4745634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4757559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4908778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3347411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3495999.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23233460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24876838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17916344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18194116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17610804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15332466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13900499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13128896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12164918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11046221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35720348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33124392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32842602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(36276448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31240392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30553908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33647632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26314308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29806760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29043136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28393856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27903156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26328886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27380076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29919944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28606156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29597130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26573768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27446442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25853748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19428376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25395964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17834296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16939850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15896858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13597169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11809331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11908649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9688805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8374689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9695064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840588., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8121378.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8718249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6742435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6609720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6098130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6371500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6151122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6214158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10624502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10357350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10949023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9739949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9653371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10233045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9095182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9999548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8904117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9249032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3487618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3328805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3378106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3237930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3110846.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3174221.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3006675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3123093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3082305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3140213.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10423424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12007676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11964834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12259861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11235769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9000165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10281427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11394893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11752801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10349480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30521446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(38855732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33985180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(37672204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35046816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30908644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31679974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23961738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17256814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21853998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20930062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19134698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17217692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15861953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18383288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15788010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14646793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13109379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9723377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7593123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6933252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5975545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6106260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4965371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3810854.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3625070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12014689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9892790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9624325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10323664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13821358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9752083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12207160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11186756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12328150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6790709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22687022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19597492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19128010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21293282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18880780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18173240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20349976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15252872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17307152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17721458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18889750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18950142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18123192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18497178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20179924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19045680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19676240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18285296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18763360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17081150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15271882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15893784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18417304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13281511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14615233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12738897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11053045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12072919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8094283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7078481.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6836686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7490816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5989259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5784083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4359010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4578535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3814484.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3449116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3861924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3290590.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5995482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5572633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5955487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5182434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4780567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5774257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4639030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4703640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159670.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4259992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1889705.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1792073.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1635911.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1709102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1638006.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1719391.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1646065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1520734.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1500237.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1533955.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9338160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11895344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11797453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11307132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10051669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9753146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9810786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11141612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11382588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10810004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29436172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34191700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31233970., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(35739536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34360760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30865872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32142794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22063108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20065732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18327748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19687340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17982146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16723517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14780805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18657300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18249102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15719616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11648826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11173045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7271904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8285678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5056951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7953369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6548864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6651767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3942440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4428127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4308755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6832935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5492523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8018707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9106610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8196802.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7536523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6533795.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7620871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5877254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22693228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18615962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19346134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18987228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16381444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16465470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18441980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14173312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14924491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15298546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17576440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18530900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16173862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16843952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18852864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17297270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17542302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15563412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16403231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15226482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14936807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14247491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12702608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15045374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11733357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13214299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11354801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11012033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8050970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6015798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5949685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4900770.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5176430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5005459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3782265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4178567.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3592914.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3486903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892048.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4664811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4772480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4634008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3454119.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464390.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3107352.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3051497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2825849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3079399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2039014.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1761113.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1703802.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1657906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1728460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1605448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1668032.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1471264.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1604446.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1625101.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9525955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12896447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11003822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11960072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11418906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9944458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9798062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11571017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12041600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10091277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28848318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33101904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31556162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33401876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34259412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31533328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31601966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21560868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20669842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18318568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18354012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14910473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14116746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18410386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18431450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15584596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15736241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13924529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12042780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7795771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7678224.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9618641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7803195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9442858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5819332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5141651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4081841.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4222270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7544220.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7997651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4960908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6287636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5185738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5033505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4765774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8514999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6004603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8317620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17372686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17189656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17196662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20616666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15417954., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14691650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16266552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13967234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13702075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13918006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16658642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19052428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15936460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16480532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17869382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16758669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17193564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15184316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15597099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14177144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20093954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20055792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14891666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21247720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15294189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15097632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11362394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10332048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12153048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7519191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5820388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8373667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4832447.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4314954.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3587363.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4387528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953668.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3639349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3235479.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3359625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4818071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3470332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4179866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3096962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3491854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3196975.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3242978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2931971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2406423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2815578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1686145.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1687211.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1627878.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1798595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1827252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1679331.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1709341.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1489024.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1418441.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1479944.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8516874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10180330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11766389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11618746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9312138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11663137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9948640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12423270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10086073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10818913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29232660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34780996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30139930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29679332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27357340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27281966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26709446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23843520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18997570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19487400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20102366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15681725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18084646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17616004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18239666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15475881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12752664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10982014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12043452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11047051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6893764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7626393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5340966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9406066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4169152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3724924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5073589.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4178207.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4265917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4062458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4371279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4407695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4365637.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9949880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5064103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4397617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16269776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14915350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15074989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18576990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18348588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19739478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15211288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11735082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13551169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13643487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16441999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16068066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14905433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16958460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19297804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16522642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16821080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15025670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15338659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14153446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28887494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23086388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19361760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15653888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15098366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13130835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16185761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12883579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11623501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6242894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8000497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7942211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4279189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4163374.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3062909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4423845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4132337.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2573261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2639347.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3983027.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3625800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3231517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2975579.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2858586.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3236768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2695151.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2546694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2227146.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2531905.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1884020.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1806581.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1659925.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1488544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1857657.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1627624.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1766503.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1527794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1555882.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1525435.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8075229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10664319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10485548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11336770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11480736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9066303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12395072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11729062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10166880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28668150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34425760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29719654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32068714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28900588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24812024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26571066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26064084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16428485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18047900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22413666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18934004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14092287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16024898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20963776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14875822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13099937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11143379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12985640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8891971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10862286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11271980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6560272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6384763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5302830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4058302.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8103655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5727517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174372.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4335415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5720366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3968222.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6598796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3869882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4008094.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6250650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3974853.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6222362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18057440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17666130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14344574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20134510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13381960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17370400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14187588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13886070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12791676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12527143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16252037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16027449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17079874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15053551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17441152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16676944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17623184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14483047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15901722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13826297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18931598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16318537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19132508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16723288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20533724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13918720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14253713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9033630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9439200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10884447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6679849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8644133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5588108.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7351381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4074964.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3690013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4714602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3065100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5148655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4044914.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3666798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3119463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3124315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3075172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4167963.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4183244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3705482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4202973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2354978.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2435613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2830610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1650338.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1946659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2078759.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2370245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1677645.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1552313.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1555483.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1611500.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1811975.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7437433.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8774312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8871323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11539570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11298548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8769812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10707129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11413345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10946762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22211512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26994802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28845670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29500452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30537868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29075352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28048956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17319130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21258038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21829652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15551736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20380704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19932554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19119162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14644877., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(17877748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17575574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13372454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13257251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8424584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12373088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10822528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10851270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6962041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10493983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8054030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5097941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4415304.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4545191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3895874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3897751.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4075338.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4502898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5956633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5542466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6853584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7049523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18335716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16915950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15222512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20390782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15429619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12397595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15472416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11191888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15281992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12460321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15029535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15602922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15321045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15196632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16932538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20373428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15934025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17828722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18043996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13881298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16519811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23194850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20287144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20785402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14239296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13378207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14265681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11754617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15546537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17654710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9156349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5880308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6485090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3891275.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6141565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3081957.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3371085.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2724534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4026799.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971099.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3415694.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3266037.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3488019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3109098.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4297734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2981500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2547125.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2633369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2300495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2641490.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1752273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1815886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2062425.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1582387.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1652683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1973601.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2304427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1397223.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1901039.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1789503.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8121195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10281421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10508978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10285297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8292463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10770859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10509603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8429320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9972414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11258760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25989738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27238504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22694070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25894508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31461968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29161914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22675816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23282434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18274162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16523148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20515062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17876502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19057090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17012050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12490233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17320498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11221915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18050376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10898987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13735079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10661116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4897307.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12901111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9624875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4673158.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3959485.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3890919.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3385901.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4222576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5463476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5471211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5383464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4176951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8494372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3878548.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3839682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9115104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5214179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14894755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16320362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18781928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17029904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15773529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18649564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19624822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13948731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14673112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12436688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15031821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18286024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16074436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16520192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15929614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17002164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16865674., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14689533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14225091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13572952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13347708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22047362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14513242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23641978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15068540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12190155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12398266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16547100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10099466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13171034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7158600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6528945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5548307.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4995195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8053744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4097292.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3626081.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2961896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6225104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3406990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6493014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4072051.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5544950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3588000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2848649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3258007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4211594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2781904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2505802.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2673603.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2676911.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1671276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1809848.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1499715.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2376422.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1639477.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1534594.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1444899.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1532968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1536691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6306269.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11324420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6801223.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9887521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7637205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10813136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10187504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7285992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7812503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12004707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26060804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33090676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25571908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31742738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24239368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27225658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20816056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21409442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18286116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22745630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20074604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20471888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17829286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15270057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20010330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12673782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11051267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10352738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12864234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12230613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6487470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8804994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11516676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9962347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8404221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8510437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6957619.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6863217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5302205.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4116910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3883389.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5528896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4118266.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4230865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8585238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4452583.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3951201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8417841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17864174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14329163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18826252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15475156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15744223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12639560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17260858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11155669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12343206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11742460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19494578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18719650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14307546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14139352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17381958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17697484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20203026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14000824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14883722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13277667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12451757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17834482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12581089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23243168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20371664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11189514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14310137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14313193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17255486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13701977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6913894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10048960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4942064.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4995832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4924046.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3929652.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4344016.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3317792.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2722934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2906533.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6222750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732887.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4134786.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5472404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3246230.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6338459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3187125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2530033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3628131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2620734.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2682487.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2515183.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1469838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1535629.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1651398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1776256.3750, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2030734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1958517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1211593.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7970953.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11055866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9654432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9620663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6423291.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11048767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9511000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6803604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9830920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8170477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24572968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25911242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25258568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22593892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23335024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26561590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20192436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23174270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13539648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12951451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24502514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19386132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19263500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19063062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10993027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16958616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11244258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15440136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7862969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12260550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10166152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4816915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6915765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10473326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9551726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8131707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7271844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6283354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4190415.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6945856.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5435366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4261082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5809744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9538720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4369458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3505343.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15440888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14100456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16891872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18549814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15886526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15509224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14430199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11521554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19701770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12523352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14832486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22529034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13640600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14541930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22973620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15334877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15118778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16962644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15362328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13649870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18081014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26526934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12170604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14384798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12448232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14021980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13871254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7891648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20824190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16116753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5354416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6833831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5767167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6137761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8140727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8044406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3562394.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3099062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3287318.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3878838.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3752342.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3296852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3422678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6720644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7557707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4668244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2624437.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2306735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2677030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2832227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2275083.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2855104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2129144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1881744.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2328082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1566897.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2412668.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1690864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1468416.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7424178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11129254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9201601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5802026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10634323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145213.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9937780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10458512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6824374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11023500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23471994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24540264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21164696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27742012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22462924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20254592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28809192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16764253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17425670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22256952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20182976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23648838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21079964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11453907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18051594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11786850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10597339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16474604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12439207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7613548.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10009839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6180128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12440186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12185613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7525296.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11703636., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3461977.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5866351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4833640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5750297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4128347.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6214130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5944336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3707254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3855381.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8492511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20625574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13137932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13233620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14801256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11979630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13257550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14026256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11476102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15978422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11738496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19104314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14857668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17466780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15518969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16390698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15868064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16019842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15413544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14742938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16051963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30039504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35059896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26095418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26511044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33696692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23477970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13414094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10843974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6886844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13388010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5468720.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10612066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5623248.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4711863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9304159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7891924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3052097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4727868.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3452189.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3504021.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3617679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6361606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3120340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7237596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3306046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3140040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2773951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4319720.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2575256.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1828613.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1762483.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1619354.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1815567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1830438.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1827472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1539271.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1936507.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2174665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1223291.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7536214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10544002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9432456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10306723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9230237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9757106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6589702.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9955320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7295356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11779573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18689270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29266114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19141374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21209480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26544256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27405346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25173378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25676930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18413146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13971365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19459368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18154908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13683551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16010295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24766304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17706998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8798606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9961274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11871896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14725428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10311943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10760359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7721906.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4715713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5852946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649078.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3447671.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7303768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5815096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5261308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4855211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4571392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5941829.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4457168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5845983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3755082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3792466.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3562787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16209013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13661950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16651569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22126148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12705587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12325872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13845308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11386043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13306936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15955806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14897078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13765749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16737051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15902335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16005117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15185678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15609304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14271050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13986652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12775227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21264728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27733128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15892363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27471866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26079374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22288018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14371939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13243204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18639380., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(18917588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9127871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5082841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13281086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6097078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6099144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7360415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3909041.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6421131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3454060.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3688731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3410381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6269377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6768555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3216358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3107979.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3224376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5043509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2671084.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5674134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5203182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1710858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1623760.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1773631.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3269848.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1761486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1600093.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2249887.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1678608.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1694562.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2553769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8619333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10586542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9919446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9559163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6172983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9663140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9879624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12118923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10941553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22917000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30156112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24236014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20555188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27992280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25609596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25865250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26178776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17952450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21071386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15912292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10639411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19833562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11973451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21828472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13667021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10857365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20146802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12733162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14892403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11765139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6700086.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16277168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11309042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4739329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2906548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9755197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3334117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4345184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5293685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6282633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5278483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4954618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4049593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3815075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3701331.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4105042.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15211584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16226318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13568321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14985952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15647545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12302669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13266628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15466062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11808573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11453362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19868446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14537599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13659180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19721946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16130232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19981220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15316836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18683400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14646478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14753515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(39102388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18190028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14539910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11813832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24556236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14153743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27049484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17663820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10090986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10818035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5969536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11494795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6744993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8417133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6297999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8867749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7492268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6214537.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3205280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3086563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4522127.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3707301.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3648054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6362835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3591947.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4921827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2305443.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2378552.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2602824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2122113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1628938.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1576265.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2520005.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2856075.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1824995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1918266.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1557104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2354390.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1771016.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4856111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6305771.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5993075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5647610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10296314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10655209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10516026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5869221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5261445., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11413715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15296272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27630890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24009430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20543222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17732908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24095120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27883608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22528952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17373730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20336332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20049684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11427624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17780506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19919046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18821880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11581837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15045559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7723074.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11684596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8191862.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11709522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4769117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13152626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6254863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5378243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982159.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8769366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13957422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6671965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4561849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4646737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6170689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8768780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4686143.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3950072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4160125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4466437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3787148.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14247209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13128789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14714351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18205958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18167450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12212070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12649742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11304766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11380802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15395997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14557577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14697767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12981537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13342587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15297477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18337972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18585924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17131528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17696774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13016817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17392542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28285696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9533034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25237604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17699244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13818492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12585222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10033013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21217396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20729558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8775686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15462801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6579904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6202164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4168928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5339417.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5294293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4717479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3689749.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3602696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8832223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4494037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6231624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047605.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362303.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6110807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8135414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2314618.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4859570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1777548.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2543235.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2077735.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2806400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1937992.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2169354.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2059341.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1326566.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4323857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1304868.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7173185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4430934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9029070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9588541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8608322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5690829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9444212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9184128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7933891.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24724240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26840684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16172234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26972900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19237386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23178404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28759128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23619694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11107643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22096164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13292877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17715906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13401197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15121478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17906794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25950692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10997237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10941500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16552558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6623533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6393335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4210684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6628451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4132841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10648239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7486960.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7740250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8323324.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4605974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4967621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5414459.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4309471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4785592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8791292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4039236.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5725370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7043897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5876752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15085896., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16185810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12907020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18073138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11699621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11889238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12608188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11157514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16192144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12254843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14218964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24686184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13329308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12764730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15682807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13389070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14128498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13023617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13954911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20147284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33659704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27513014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27091004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28234644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9739436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10979281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23403590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21359474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9794184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8016404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7207890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10870674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12909666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4856959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5677723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4597410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9548474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3678306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3058697.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8045008.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3740134.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4551941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6029253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3436013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3898708.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3309999.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2121674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4073466.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2541806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1910223.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3001012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2139652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3511075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4818263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1600781.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2751411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1370938.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1340096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1267474.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8800895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8643658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8745661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9985200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5792628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9885296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5869276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5002169.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10478842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6294464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14527837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21553006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17103886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24821540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26564810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17583426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24570472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22053648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11792090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18822578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12752545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21415546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17912634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20154594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17504784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10028285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16992694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9988695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20461974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10694621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6238080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5810412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13147132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12029898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4696741.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7134422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8187097.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9489623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4874262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6220828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7690745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8470041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4521376.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4266885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4033049.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7037712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5891713.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3726830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14275457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15043310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17131528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19456936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12631498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16757824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13560460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15374118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12127457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11029450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12884872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13193672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17401472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13028166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22669764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16604920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13666092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15723451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20664758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11916160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6514705.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12093188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17290240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15737594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26002540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21550486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15211852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23915204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22592262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26470232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6535669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7252550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3965046.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2818525.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9027568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6000477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165058.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6611416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2532449.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8056866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3823710.7500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3812217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3675124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3827293.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3948943.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3988865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3318210.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5745969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2055524.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2649740.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2716919.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1666973.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3171991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2027722.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3652681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2860940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2274022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1479363.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2063386.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1544258.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4351345.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4825076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4529591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7706405.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5436704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4727822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4536733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6024385.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5576896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11685889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20971356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32971068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24335242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26589236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29389162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24961978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23864122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21787898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16863432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19587708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21247644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11114392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19447848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20498274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16968164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21255824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10536683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9329145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7018147.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5924190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9420646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10979690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13435562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9997644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13510638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3696748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2389688.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7829008.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5154260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6803461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5252786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5745063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5658534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5973877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3875377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6840478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6844997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13840325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13332033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13682566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14003390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13544225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14955918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14592082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11220297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13126490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12109419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12574081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12952201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17484550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12486588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14421524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13266919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18051964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17267232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16661220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11720939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26472668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16419517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18237472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15790480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34893684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14612634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11347369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17229596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14721192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26280146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13174197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6704744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13587106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4386783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6024355.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2801162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10204998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7115762.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3667542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4373586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4272566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7068778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4125259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3580599.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6664719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6472884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3082603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6335371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4985560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5076929.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2487774.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4492656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1573320.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2303240.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4713222.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2038604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1892783.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3725589.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1829849.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2264470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7652995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5061572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8857376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5180166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9884552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11120155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11703858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8601788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5557003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10555305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20236392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27787726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24907090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35163280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18257034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29713176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19012666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24320024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11196598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15001522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24412094., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(18804408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18541656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17537738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17666132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23686892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16752072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15329176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7540231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12554435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12878003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12482317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11367016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16949942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13930775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2679841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3492155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13458492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5327408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4450609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4554726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4658113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5635380.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4046784.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3789593.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3773683.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5858765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3538540.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14536338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18914288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18027748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17822332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16831400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14076932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12386846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10742091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12847522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11657901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14742284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12127700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17260086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17469472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13225411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12973236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18307576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13482746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13180694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12253497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30435426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9558938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16674467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13925288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29047256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23517590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26972718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15335787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16708284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13105487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8647165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7465636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18845060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16248033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5570928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6527019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9454836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4468525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4163423.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4023398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5354282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3805755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4473623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7615895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7205321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9172351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8596180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3414991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2003318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2566036.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2567565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1939514.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2304320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1599583.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2735525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2248939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2197304.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3357101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1618088.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3097242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7659899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4614531.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10346291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5664222.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9462006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9568421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8945868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9657000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11320746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9906168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20807518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24672684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25070798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23991406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17194698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28346412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21517062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24818452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18405684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25712730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23280692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11335493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8605612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8629016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21348822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11819338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10912656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16495756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6744886.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7284601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5000159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5817288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4774500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6160739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4560240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3595817.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11103074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7624343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4562706.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4586325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5190823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6512310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4410165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4466230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5649980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4928382.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5367575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17723052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15367160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18125030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18058416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12158868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12500202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20412438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13615556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11848998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18610674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20470060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13420338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12481616., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12903978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17845460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13194082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13391252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18620752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17309734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17294778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10124381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9627295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16134205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13448804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15815341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13431515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11972100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19928772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6281698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14464225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9617995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16717198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8136074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16508084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10385090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5433005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9789404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12278621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3389475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4894381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4238960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4441947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4872238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7510554.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7728077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3703899.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3167777.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2492083.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2905137.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3058854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2000949.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1899592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2408349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1764526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3439232.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4390517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1264251.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1873360.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1862778.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3539126.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9486488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7869913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3478245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5990281.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5220035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4954208.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7445990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5045450.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6416590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13320563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18259906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12693420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27469908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25997572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17803692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27882464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23931400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16986272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10711728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17803646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11651219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17575528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18140018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17279864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17101176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21197076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17137978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17795118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5693536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10216059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21839646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11076808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7845163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13714459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8477038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8217518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6379811.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5322848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5884705.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4027374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6333050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5705002.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6827063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4220187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4275697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4878023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23056094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16471240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20821710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18752282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12070138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18075674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13120576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15487150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12614119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12246983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18834348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17081488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12954903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13127849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13156023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14025198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19389908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12161593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17799188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10845676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22717826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31234198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22927768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24006168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17352110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14242681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15039301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10838024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16167325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14338145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7418972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5748634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4606240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8859943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4972330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2716256.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3249384.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8689983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6887413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3131138.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4788810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3994031.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3170867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3906574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4100319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7736313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9679579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2308000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2088080.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2354575.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3979270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5971865.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2874025.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4384197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2625954.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5418568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1849160.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3037694.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3671522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6382591.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8931527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9434661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7368057.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9969304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8661432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11265355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7986883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5693629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11374640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20879564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27345656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13821196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26964662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31043448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26496660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22005414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26969556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10574285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19829358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14254235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16980002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16997926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18688910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20368058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19924432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15901131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14867175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21984456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10880600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11375238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10925353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6843922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10709344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10688360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13819046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8562392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14900400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4388693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5587241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5506010.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4531213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4129164.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4827165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732512.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3785252.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3427312.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16904286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13832710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12516440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17869104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12562835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17265540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13814468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15385117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15565206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14749454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23220376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12153873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12868960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11692028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14729038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11894110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16563453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15993529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19960580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11531267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17963726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10157150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28079388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31282242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27820742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14938721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14964742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11049088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22182648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15483418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4203899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8331077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5942326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6473358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6656428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10678983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10038537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4131634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6887951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3971395.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8789329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4910232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9236188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3823659.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4804449.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4826364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3874823.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7928019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3004473.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2505701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4773028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2889067.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1876951.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3955385.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5143981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1746582.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1663475.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1298073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3033342.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6734649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10384082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10545658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3707875.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6073444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7812186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9930664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5841867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7739273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9010990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15383399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25412978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19504126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16239142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17817228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15027557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20376534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24944598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19165638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19268918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22108100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15982768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17288432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17897150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11689646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11904243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15243653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14193493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14500176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8363926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16150358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4612886., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9919919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11480727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8716725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10008614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3058736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165951.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6260316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4414724.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4434718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5313463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4080302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3613136.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4601579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5947580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5230626.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20100918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20111208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12036945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13451321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15156292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14497330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12117814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13854116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13685446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12972404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13602042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12910194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15861840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16815724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13991673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13162026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12259066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14175719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13358690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10526641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19005388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5907862.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14679277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29930818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17875832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8537374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15788290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17097584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16520294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10317165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4355276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9826399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8604438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11317783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19673412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6774223.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5637422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7136398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11319902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9996072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10281426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4972433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5668605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11034176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5090367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907816.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4479619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6308201.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2322033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3466809.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2896292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3320076.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2643310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2882005.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5148498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1669194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4053887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4185190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2312757.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7944188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4048220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11036768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8855149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9170152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7917705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7597881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9602810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7018493.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9935390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13485016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15196010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20866990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26679012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23321348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22510154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14797187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23270722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11587421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14795919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21078280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16808882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14757540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9197756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11620130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15613128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7457727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6348616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13848318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10146037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10127492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14354392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5876243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4774799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8568763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2654009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1895140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3085467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5152236.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5598111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5358267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4766457.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4759251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5469075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4003190.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6777167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5776320.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9351667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18837220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12650809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12146673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17096922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16315556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11687762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17678514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9855924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12752410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11913482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12354646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18218972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13074378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20768246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12994769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18196108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17224376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11973836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17347190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14905988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10391118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6258444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27031588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17235292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17659238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11366803., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9739137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28400832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29224708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13225358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12313662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6234639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5665072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15064578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4378421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6695351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5795694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6162631.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2772808.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3857855.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13063776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4974730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4245562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4743709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5333225.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4076394.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2885116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2637750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6764245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5022996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1974044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257473.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2137984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4445827.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2172228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2717453.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3021996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2139569.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1678501.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356937.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4296523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9827176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8506694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10401845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7247297.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11403219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5147824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9292399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10133590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20984848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29939046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19625354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25445280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26424258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12858536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17117710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11670811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16408073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23471130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11260417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9998067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7416765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18791654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17831264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14947907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18291000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8663888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12663296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14536295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4794710.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5641867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4875129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8917032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8813942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3785551.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9575967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8519834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7723082.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5291040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4505317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5743354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4565124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3938733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9156383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6593313.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8695141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5848090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14699782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13005641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14417499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15729879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15370539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12066292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14988703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17974044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16608336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10669852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13412178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12232223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16359236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16048269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13261247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15655055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20345156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19455694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17002812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13121272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28465670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15420996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15720839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15325327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25220138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22500012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26130842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12202590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12236044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9559023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13369974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6602622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10042963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4223813.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3654779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3589814.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11105931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3295132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3367431.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5871184.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3837099.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8336817.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7401103.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4741523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4482263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7613886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2299159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2630360.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2615679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5506148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2819397.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2245851.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1963144.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2519279.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3929186.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1722271.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2885937.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2106967.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2038742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6648583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4785099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8534568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2922020.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8875740., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4941742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8163286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7117929.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7380058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5306482.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20363870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21954832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19694722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16792268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21300390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13993031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12660910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22801164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14460521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10315084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18535598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7523837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12102314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14713656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10259162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14487450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20014336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17037106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14933408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6715279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9223550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3995988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23673288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14100105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2931126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7824563.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15822184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14761751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5199793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4834030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4182780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957846.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4323810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5248513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5186583.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3893364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3690989.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5979295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14637870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16323984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12137743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15192798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17604782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10667456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16411962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10439546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18499510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15698357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15022882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12288747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21169192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12962485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23364140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12554458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12919732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13456720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20792568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11823248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9277250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13661283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14879157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8906936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26981636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24791082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15674312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20531056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3288908.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18216442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12144969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13525415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11924029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2415100.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3313683.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3717225.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5403483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3421801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8092584.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9727003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8315727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7629773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5045014.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3937147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4835402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5361071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10086240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6145062.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3142642.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3413640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5238046.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2008038.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2597681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5215411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2860653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2973826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2891858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2098953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2330320.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1906047.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7495233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4240542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9579594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8352781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9549345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7338726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037549.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5245581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10619067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11705962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19001224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23030316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22202538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28522758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24189422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20635632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22767616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20166208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16707274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18567654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16330273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10316318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7473897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7802847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9765264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9180895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9445219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18498454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20572252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6707349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5101842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12939418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15533627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3429266.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9969122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2768600.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9284393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9844840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6689305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4884460.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4630369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3871098.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4136769.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5122559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5848628., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7283488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3867421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3566738.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17036978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14997295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12015538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19303318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12143270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17644054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15558013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10526007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15804594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12118066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13813892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16141862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11641194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11770056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16432447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11738248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12625935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17773622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19130792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14530996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15653612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15581224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8000281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4036949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18370392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23940100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28068278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18160322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14724135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21970008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9240897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7838878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13877721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6831732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12227469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7249064.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3019302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13442360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4808522.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9509336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12929821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4645609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4702797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12657827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5061502.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11437537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3557439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6412191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2558286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3252140.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7440407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2909911.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4570913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1865944.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2124082.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2483681.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1877610.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5289914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2206319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5442659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8310546.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8390871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3728854.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9959816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8610915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8485690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10547159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4958712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12810286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18519906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23887524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15291590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28173212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22861262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22591952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12051736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21892774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11630498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20230874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13207813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21352004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16152500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12129323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11313841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10843943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14212706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14046160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4463828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20179170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10015343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12912641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5282389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12774785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7412576.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8289172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4342333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4333573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5254173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4241733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4130362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5685178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6244853.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6335086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5535036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3859797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16213298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15306970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15639273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13838443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15607998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11368168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16211516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12363830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15900364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10598086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21874378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11932253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15708462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11366072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12940996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11575918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12229128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16234552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12882465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14192456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14346864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2432851.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17989600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14947920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13056221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12434188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8231857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10225590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12276378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18671212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9496427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14296138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6230916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15290647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18891700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3124338.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7291426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15040368., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13111200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9531802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6614734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6055038.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5208200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4619829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4215980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11131295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3885119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8123295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5979889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5604707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3023321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4603965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1954909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851133.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1920933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1757530.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1866315.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2283024.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3174790.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1407114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6240641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8392833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8203001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6552946.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8988280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9939954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10091526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5240680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7586421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11722826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10867702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17235410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14627696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23052030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21977900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25173982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19093010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16096182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8225959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20411414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10232257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21533702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20585422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17425402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10707539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21638980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14897619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9520339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14602634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23826662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10346011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12813798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10768199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10722351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10096074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20982572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8588796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14712117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5776616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6461967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8038731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4024241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3984952.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3398130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4914701.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4715927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3753068.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6759371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15050805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16647018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15453756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20672188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12266808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11649084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13128865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13921258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11269987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14339200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15811094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11401753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12085449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10291608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13126220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16104747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13120308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16275550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17195852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11333451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15283132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27077196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10006346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13530876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29230048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22125124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6824333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24093754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20005174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27560992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16134035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12937133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5622903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6490091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5635244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7652517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3122013.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8390052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4495967.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5392510.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6692030.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4712623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3783360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4939131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4402421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5196559.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3678418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3197680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2588835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3158506.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3315766.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6746924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2513149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1709284.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3002496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2732943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461951.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2449964.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1870027.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1953033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6486158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8063073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7711943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4426912.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11607373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3658632.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4810421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4612640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3676886.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9505698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19527372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23420778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19009176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18353952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14023434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11717986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13847475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10527220., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16142548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12125903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29500966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28215490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18707962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14979119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17774256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20801814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9395339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10579162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12817475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7421540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9126445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14706156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10471457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12306311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15019748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1808292.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7700518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12076570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4091350.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4220323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4976616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5528290.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4035372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3519366.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3587025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3764052.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5047920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4155214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16237898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19063650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12794264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17337222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16408134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16308876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19374252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10566692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14298193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14426308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17350412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11233743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17795536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10321491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14580393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11136734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12531605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19809314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13473454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15285620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12138726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17021104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11624417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14046968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24518768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13566545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16652775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12255930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8809558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24967072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20946468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9049255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14652890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14854523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3373006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4557045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6230850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2256235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9902934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9254128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10495864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5926649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5144505.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9858806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8694683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9083548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6764005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3747638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3403825.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5812762.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6591065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5041003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3265523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7312412.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2416541.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2554433.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2987958.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1315384.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1965219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2387228.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6808186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8062194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9307626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7601963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8875765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7281987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8558751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7749936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6842070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6669117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17034708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23929658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20947804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18182734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22446968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20634364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14681005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18898554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16617800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16970626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17589506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15205980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24168572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10421119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15001502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20034800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6638567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17397770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12422923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4201634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5911651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3110485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16822642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8790904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13734267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6912562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8136460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3179340.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12015950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6531831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4654588.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5067764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5577204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7770315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3916976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4959654.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5495109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4520163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14458890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16192748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15315662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13089594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10986297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10325151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12209458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9577742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12537187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12188206., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13107064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18378922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11682897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12168749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11398938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18643980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12484722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20253114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12558929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14902223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20665814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31018352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18195934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31531788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17404078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16861042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20353322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9586160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13792233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21835158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17623856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12742657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7547750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6501375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11017910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8487996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6086682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3818467.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2163274.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7706234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4648228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4218687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8530094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5229097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7595743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3776371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3066895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5118169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2942460.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7374325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2919180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5092918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2808299.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2018393.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1833757.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1651153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1583760.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2264003.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2857211.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2815472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10151453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7429147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7215129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4662988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4846644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6798883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8558507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461218.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6674032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20889570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26307116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18759006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21787016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22613486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15696798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21388302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10832144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10024505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25372522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18993984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10685785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20256978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17973116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11540959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11104893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11719048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17828190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4584282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15280442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4004080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10276377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11146357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15233370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13308575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7668663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8652088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5023978.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5273223.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6522252.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6105999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4195645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4919514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4897138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4143527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3980022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3801010.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7718721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16123320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15468805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15376547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14495052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13914610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11078547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12195351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10962185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19588804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11844864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12426939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19975328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11938437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13915055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13900430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10606285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18557802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16622920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17128178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14672295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17848174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9548017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16293500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19497566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26528062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14692846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10567294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21401444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22036578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12166507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8733304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9502666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7603551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4770272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8978633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8013582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5493712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6217112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9358560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6863471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13065244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6358309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10684418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5995674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6115644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9547958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2571467.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11133613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6620833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2789074.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2733276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6037241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1886396.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7745518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2440270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2777211.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1288605.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2446714.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4656243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5667408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7599855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3032996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8837308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8579443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3597525.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3040237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6723618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7045827.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11957590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22728630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29070960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18067140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23212078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21207626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16632132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18976312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10330474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10601370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13432543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10537065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17490278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16885362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20875264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23128376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11526406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15419557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14323132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7962593.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4693677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222277.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11711368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11510338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5908471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11228239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10791256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3429921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17568226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5350989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4499088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8736524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5146999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11403323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5148800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5360525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7344253.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5926972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3189464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18226398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12458290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12780901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17302684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11239834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10711710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13801747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10533074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12625393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10883882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13095239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13447899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10961487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15260004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11834381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10726626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20527902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11983830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12969652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11326931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17975312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6154861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22184196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15726531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(38641388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10069685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(36687700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14338155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21387628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21635610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18010574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5473654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5032251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16748348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16207316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264156.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4203716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5481896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2840360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5308511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4590538.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5771063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4176792.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5110336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8305293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5105221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9766808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3168080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6125046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8178493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3484178.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1596531.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3216539.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4184788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5253194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3140401.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1880248.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4344494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1900268.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5708466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6888751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6569368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2532659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9641532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7933453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4149819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4138499.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8087255.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11650140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15234442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22718976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19015794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23992294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26966270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10468923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22352560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13604869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15272682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12083694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17288672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18828084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19926248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9019545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12877135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15967449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9838782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9301873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12068938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8368072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6196148., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(18025614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24582472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15555317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386460.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2160524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10840104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4334626.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9143268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4130301.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4854351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5973224.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3667484.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4204545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4090175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3640817.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4950086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16218198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12989370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11745810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17397652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11756794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16928538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11843661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10700452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19899400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14032020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17049110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20918582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13470328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16220076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17336010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11116298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11156083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13850367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13088327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13907677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16911296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22306300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11610888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11835278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15417683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13810760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6792608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11533504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24308182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17635874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14275967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17511076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19776780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15514603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17295268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6100065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2220941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4641410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8134707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12643005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4100570.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8739696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3425373.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4984439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4114982.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3562629.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2439136.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2321532.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3551265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2838400.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3306541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3079273.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4407176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5045164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2965594.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4191980.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1437509.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1366796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2246553.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5392582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7860457.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4178936.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4323624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8180530.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8425394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3180224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9854694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2915578.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5089832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17686186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25059476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16775311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11794449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16773716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19440342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21451968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22166734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10246206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11661384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21798504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19427662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14207518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28296278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15944392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19957866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13526479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18922508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18589178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10366215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9592535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11133645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9620407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10689461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816603.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6954997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20399580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8247527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4285384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5684478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3991036.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7494618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4604365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4853444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9469886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6047190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4512949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16882280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17161996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20108692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17737706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11988739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10441310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12624446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11003151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15043782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20199980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16907066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9933982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12431682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13240972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9471814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13575866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12116977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12380993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9677011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23510240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27200128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25295408., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(24607056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16348052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26035580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18204726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19163954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13217375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20781404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4441405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6910531.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12142582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7613893.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5085182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8358609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3476236.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6014161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4935357.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6130078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4721736.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12229011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5385410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4294508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4984100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4871910.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5310811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3804690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9851014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3994707.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8008355.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2998565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3307090.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7139194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3577478.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3908922.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4130614.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3085592.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4108862.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3870104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7489605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3708624.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10077510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8008304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3127692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4497153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8897634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7786705.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9000584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10498918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12567706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23290538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11075642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14347023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20243238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18899000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20370924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14539110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18416600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12563540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16877754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15295999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15902174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14982003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19723480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12841861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14318643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17537216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5807728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4472865.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13254723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11017336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12097357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12754709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5784888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7825203.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14454671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8219383.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5191474.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5376732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4680819.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4935029.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4255301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4732407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4920878.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4226804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3361594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13096622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12893189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17229046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14922045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11110168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10991008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15540734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16435932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10668222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11644332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10995189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10950231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8672265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20128078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11190384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11166726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12070891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15434285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19943382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14688200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17338152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24514686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19277418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28951758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14860605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29186194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4407778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19050214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15056012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4502753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11995719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12462228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7938744.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4354555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8228106.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15936262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6048469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8901433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5658267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4223470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13823673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5989263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8138839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5610668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5675464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7517526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8730335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5497116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2572530.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3052389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3963182.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2596404.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1617244.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2221083.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1760911.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3369590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3949613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4225217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2182306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5990787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4207968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6603925., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3872319.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10130672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7846142.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9047925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8024041.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3527261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6040898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18224804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20998024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17227258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15544426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20791466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19205072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22206212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17657118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15960579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10152913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19658200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22179832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23448752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13488002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16506042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21876186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13726682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17432254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11940489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8461407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13155514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5682164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13347110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9628213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18478836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2049696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2753738.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4696813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4863242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4363639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3857970.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5018298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3525820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3776585.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3333445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4836618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19147676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18066118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18357844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12868418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15915694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11450453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18805786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9546786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12395625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14193598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9325432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11806823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11012654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13539492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9461150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14644935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16076788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12012546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16174666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8822856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17056272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13689415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11529649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18283794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24220016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20447302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8968579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13632208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14972326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15377925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19494808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15735350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10653278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8566949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11238206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4019531.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9515527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5161489.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3388172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11862576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9254401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13393365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4039812.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10847582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6011317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4669770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2932529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5715146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9086329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1983025.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3661488.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4727230.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1643195.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3391093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2122279.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1877735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4404449.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4691941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2494740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5402371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8923556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8304399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6171017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8401839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119492.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3410781.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10399476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7582209.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10244156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15396900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23100608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18678214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23616516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16076560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14932708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18588770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21242464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17300402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13670882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16908028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15339154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18683830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13506078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8836393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15130656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10908424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8284683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7491856.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10648732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6047570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9978255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11422303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10863951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5688215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4581177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19914098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15102855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3939204.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4835528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5288719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4446095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5286660.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3721918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3673211.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3563789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6679254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6525948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12808832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11895262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11894218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18911218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14740256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10275378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14031966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17086652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18243470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10763880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12360170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16146338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14579176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8576840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12870554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14251200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15080539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15675672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10985526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13247404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20326686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10136621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14773080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16552156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19713638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6198939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18094172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10947075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15011966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24513100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2406229.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12433872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5957241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4969395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6587174.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7364450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10460543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6758350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3306686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4606366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10229702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6493324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6498183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8575934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6281366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13614533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3778379.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3367862.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3668586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4090165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1836541.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5335143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6462261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7617202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3467015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1955009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4591099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5671902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5957597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2636940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3256114.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8715845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7422308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2358826.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11133038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10669244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8025554.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4425164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7113801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6309267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16471111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16106250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23145472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23650440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20703326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18018326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21759418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24633738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19801936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15831212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25234556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18506134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14530364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8585968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15614216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11980481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14812069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10026402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12619112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13328435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9548110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4666342.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14964874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9439115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3343878.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2981649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7779571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2922768.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5173866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6743011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4850966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3696626.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4089368.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4782184.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5562164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5846086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4814987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5796187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13294000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14495034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11087712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19443002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12708689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11181392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13730200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9679673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16201577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16578643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10775174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11840360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13283210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16969312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16547339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12029306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13832530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11945647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10850641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14194510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9156915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7012738.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4642607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16450089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21906344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11555810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15362164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8839467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17824570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8146513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6218496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2950981.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5141379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6536647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11907232., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8742322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9310540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13334343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5658562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14863234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15873250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14735847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4420348.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3533344.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4155574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4154542.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5868480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9181205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2866716.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2800584.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3188268.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8310590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1980401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267262.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4846349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3256979.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2038510.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1913172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3880600.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1536014.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3100947.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10706731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3917729.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3694524.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4589155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7447153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7992545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8037078.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6452199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8593602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18045708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22999820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17500326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17725148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20572006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21385506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13070264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18247096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17243576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16224800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15443033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16563131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15628177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15508445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27219160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13142360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5829584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10909614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10833927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8443175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6045037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13110155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5898672.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10004929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7416649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7007940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8476227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4993770.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5057441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4396755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3348092.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4999395.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3438599.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4646545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4676360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10357589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12767070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12115489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11558742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13070005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17397706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11307321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22438194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12398308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12253298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17882494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12880278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12287147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14096848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19031190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10830480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16577890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15514954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12143946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13368482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13609672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17371768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6041574.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15865735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16407550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22073722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26811992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23586832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14956735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20564530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6576515.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20366508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3071642.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7843063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6863613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8856568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11571126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7231709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6371202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3612161.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11712028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4940015.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3388064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9069531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3857517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6181468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5181431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7998549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6519415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2700121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9675642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2247790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1591590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5550928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5911287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2940763.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2814338.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6748017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2166746.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4438599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2698314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5873540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3821281.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4100343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7112380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3164057.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6838990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9080377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6543725.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9306314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10837032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15001698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13139455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15702201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18792408., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(19188704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21990926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10301846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16720117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7992877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16328536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12050636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14048490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19970526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9858497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18944280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15035414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7835642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14512880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5574826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13972679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7087691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6251393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11844053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12918108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5723752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6431507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11547215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12398368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5188050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7369198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4060333.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6526466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5628863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795407.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3190428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5802606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3550356.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4605602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14041012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12110242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10837735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13016569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11360092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11143394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12511435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9341476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12131587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18404390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11981707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10171444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8112318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8369769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15156749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12328118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19117458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12369467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12823213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7254372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18473108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20925964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14468754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20969972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28941270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8830430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17412754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17445494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17257238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16368575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13870605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9133621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8715899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4852382.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12081656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5533303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6893357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7133339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2818072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5193283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4300284.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12571367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9056105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099232.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11418635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5486185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8017571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10972271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9981627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2530970.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6935576.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4358435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2996183.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6122108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4072899.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1802155.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3017502.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1946913.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5146681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3373119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7892744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8470598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2253972.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5838357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3026650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4723556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7592915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3439798.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7663981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4919648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12691539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20679558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13076657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17938336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22585150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19771394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25737480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22575300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14675411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20652750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16983688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11151936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11128593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14671935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7752335.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14860247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17439692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17649268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7838494.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15370771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11035727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16964802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14392329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16263016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10309728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6766121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7860429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5329399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5121073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4866948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4644386.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4488743.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11218532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3242162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4392138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3262468.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4040806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4849161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15248819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11169034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11624710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13171536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13661381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10643828., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11304020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10162318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14552298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18154078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19240394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20233506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16213827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15563348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13460186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10690176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12638238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11759809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16588943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10035780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17429768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5117562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8021808.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32090968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22931892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15746896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26786424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14415938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7067664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24563548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8799566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19383552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5313623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2052095.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6821566.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8073056.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4876046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1709664.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5642537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6812851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4326875.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9341309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4184879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8301772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6975662.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6590298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10689035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6767556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3807537.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6613580.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2678837.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4298426.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3807165.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4122013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972868.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3991241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3803031.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2312500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2810329.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2985291.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2531470.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5621781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2768663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6953924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5844908.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3941501.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6577724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7629885.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7064624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5996473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8030408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12594723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19462450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16992216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19539358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12949473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16679075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17165292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6818676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19171830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11151587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14640333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9907566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9229249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15983269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17534544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7008299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17666208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14345620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14719460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17817044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23081804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13411759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3668746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3734706.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7842567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7345214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4523860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4429032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5038291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3701927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4633646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4931348.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892674.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892496.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5126091.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7826301.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3746474.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13673405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12592212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11493182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15830526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10909389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13497650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17647774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9784972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10573343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14578805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14866144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10877129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10791044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9583827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13069491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11073968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14576173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12922640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11281360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10273617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28561836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18191314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15756539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30031872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17526832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18630176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17024490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9986189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11300657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24585712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2744790.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9323141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4403585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6316222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3160669.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3511938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2780059.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13612594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1288215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4499120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9109529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6503791.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5379287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5320972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4251444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10039674., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4954685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4715895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3082615.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9985242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4522524.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6063412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3881909.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7232862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2409426.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2011090.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1551966.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3445143.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3164127.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6925149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7636693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2832101.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3945469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8946986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8426480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7858810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7417695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8793482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13408621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19176010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20709448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10845243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19536406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16317342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17380480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9150111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16869586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21904414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13673204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9334990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8801224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18269918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17713972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16665378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9286601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19197880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4180727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10177702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3183024.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12852432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3322437.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4863651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9239312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4742779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3160518.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2864922.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3505398.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4836237.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3485146.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4659052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3483859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3494605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2857541.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3512540.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4578697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5054206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19025068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14618738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11112761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18418316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10598400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15358924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21794692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10092758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14559439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11435046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9387140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11579500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16321123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10983640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13283622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14216880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10288540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10634218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15683312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9389767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18591986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2744151.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16484522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18213786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17347932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18514848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32032858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14425814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9802485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17764994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10922781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9652584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18954926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17556978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12362547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3132126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11083125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8205072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2511133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10975876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5399091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6762097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10330089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9323682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4102645.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12187244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4375528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6285871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3006464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2554596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1761440.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3893349.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5139269.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3360323.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6204340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3405767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2810407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2316364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1951852.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3061685.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6782570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2817404.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3653508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6694759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6426682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3124828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4627330.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3584063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11322734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23934030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23087506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19832366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30012458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11043520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21474638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21864010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10648447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10007535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9300897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27210732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7860488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9493034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12356671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14658902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18374758., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5755873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21314620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13296825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11365167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6224928.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13884054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11715712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12686658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8586982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8578537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6321568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12226426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6817617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5461867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5091357.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11153515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3471882.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4366215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3891036.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11668540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4861795.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4778712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17644558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11836142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10422038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13056070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15618622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9745705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12548239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13040447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10491052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12058384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10616435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10259970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16093700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15886696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13667002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11526922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17161650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17698186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8488351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12779098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14345941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15907123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20001340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30901992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19063016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16097166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29113732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13917311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18039648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20323670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6327206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9126910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4083918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8324263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8961219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3128262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5682466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5169540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6751234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4845690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5607228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3734815.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14207224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7100174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4592131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2475050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3914775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2399995.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4210301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5734359.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3352461.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3494900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3437124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2221008.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3150610.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1958989.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5502948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2343896.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2265743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3260277.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9353395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3277400.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8798603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6880179.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2621448.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4186859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8897465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9495601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13914922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20141312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8879316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29986918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16696007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12633842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10109836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8996642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12790482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22935412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13957183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21530066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5980935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12358561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13747660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15640096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12447880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6030388.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11405676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12425012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5373450.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5252037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6324245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7731821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11832098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7302208.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7383447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11308609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4213219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3896983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3888019.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3625158.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4054622.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3096899.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4911767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3915959.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3320686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3433315.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13336380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14395178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11052649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18098594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10301598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10259584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19260360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11856137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10766896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11639927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7473396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19205812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10460752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13454922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10529637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14941212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17631980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18351836., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(20005976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13601606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31693878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16821930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22150090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20700952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12681720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19073686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16325104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15941635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14165292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14812715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5079214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9506921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1878690.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10416819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9223363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10996031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4438393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5643636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6297539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14374126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4719700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11769779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6216374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3511488.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5590600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3786821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3719167.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4593805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3152568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2625380.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7269863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4097872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6372817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2668627.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4796156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3348380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4173886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5972310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5414645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2638675.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5690655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8049461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7921909.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6686941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7876775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3048297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6654066.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6838534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9354618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5232832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8948982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21274178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14546118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20273902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17126152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21232748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13826700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24721440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19132616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15665397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16545933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17990248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9214512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15220866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8443634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10256796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10334630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9359424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7827164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11127808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9591481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6937723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13479303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10634597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10725267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19567182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15499398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4782002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4625606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400551.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4433930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5529025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2598646.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4218585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4847565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4966395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6394837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16965254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10677035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13324046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13426469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14319814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11164826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12826871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9211675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15281734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7181700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10298963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8662219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10236503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10666161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10719960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10234992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16077376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9467442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24165634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21132366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28826812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13453973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16132325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28925794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19965702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14743493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10192879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4666464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8924737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8991898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8262260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7661776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16714040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3038957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14074714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9105895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5647071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14422074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12421379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8886079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3544625.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5045245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12002149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5836640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4109800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9788604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2911753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8115149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8933968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2694351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2285659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4400004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3963984.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2307767.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1945629.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1451135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851075.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2799072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2208086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4148188.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6027329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2639758.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8066618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4023095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11459208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9434513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20063394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16066545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17296754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21613368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18615278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17167484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15209494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19212886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23033640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22950926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16720888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14182231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10164617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12828925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10812786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9066898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6876550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9051843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14329654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9982795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13574636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10789483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13575342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4414408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9159146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14168089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3504112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3611312.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4051828.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4607711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6198984.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4701130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4458218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3659022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3315842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3014901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3546601.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13000532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11329837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12562974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18663266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10703186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13527313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16816840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16096348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9833254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14522215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9865194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11265503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18973884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15795431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10210197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11097306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11568161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11622030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12809296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14120329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11461295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17282248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16825574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18959590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16583143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20616240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6116383.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24910044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8743060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9028154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9936940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17391708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10155002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20161304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5401800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9983037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9475285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12274720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6712400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6204337.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3876338.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4894237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4236836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8355543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7556606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4217872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9391206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6049140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6318690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7109132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3551673.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1546797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4461651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3303056.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3737019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3138971.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6581699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1765255.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6984233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6557642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8779244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9267576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3269383.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10857916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4191080.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9183246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14224508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29645450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10041916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14195196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18552062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12037401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17384986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21085304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15807882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11890616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17543968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21664360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14478767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15679906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7833558.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15876496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12820488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16160197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13779568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10725299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13170813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9660719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6051689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6196807.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9127464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14766769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7987514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5537476.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3804653.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6727438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4431319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5684537.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5159777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2725386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4604327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4918363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5680777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12401398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14121940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13442711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12311201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11233134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15654862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11013315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8573014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14326672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17758544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14236892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10928134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15127529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10436156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19724110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13073640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6871452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12253023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13321977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18513194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11134359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22024214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11659556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6152862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19800364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26589748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17422908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13832654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18103298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14493292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18420920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11769749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8247393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8346329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9324075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8512286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3271871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6963599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5903707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5763905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9041645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13136522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5137703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2689447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5768140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15075757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6278667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4684245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6777895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4395353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8268549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2725447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2891772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7342386.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3924904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957120.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1503902.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2529062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3270778.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2817528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7060906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4090656.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5582722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2747575.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7647494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6282578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10602592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3829843.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8249175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11821868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16499935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13913729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13996268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16245840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10061017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24278488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10075961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19823268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19865388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14824778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16898854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11985635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8744585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13082093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20063190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16853866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4754120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24168198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11104477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12180210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12568789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8372626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174822.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5025498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12240967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3530752.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4941344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3496523.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5083384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3015313.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5372855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5344079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3076514.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6216721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7114416.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15350574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21538920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11173816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12381339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13416606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16269057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17820008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12634737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11830170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10017556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11496639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11230594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12371966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16847778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13313884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14841422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11487724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13265696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14303075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14082319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15810258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29326732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18140300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16730216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18270602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16327417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16060528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14110123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15251577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21068988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4400489.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8392541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5478094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7954732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9031254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2943967.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14320848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8956706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1809240.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7341190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6875919.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4685596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6426991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5529356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5285519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12990992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10096455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4918441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3285464.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5239596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7837444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2413934.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9216772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4781575.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7352359.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2685562.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2852189.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2701980.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4700596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7846385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7048632.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5973137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8718363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6547932.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3763713.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9571390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8300539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8643334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15063101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24816400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16477094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10808331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13196830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12729374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20514302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8339675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15013894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18789224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20731208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15144895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20522530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6564476.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9739911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24826956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11602158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8079873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8381195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13281230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9022496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6414521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13884917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7542894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10417817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4860352.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11025766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3320029.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4760920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6976005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4500262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3074575.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497381.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2957392.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5964773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435512.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3492289.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5948963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13871910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13619410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10415148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15775750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16375600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14126494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13205611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9883489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10845185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18948236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11493725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17222924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7284867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10877896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13763216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10029657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19380346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17227422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17166676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10787116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16216494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30663390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4703838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28285336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12167014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7505286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17167528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10590493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14262011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19652610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14455562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5552867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3453212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7889518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10784285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4757726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7501286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5582514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5290828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3419852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13652534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6154507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5141767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13044722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7129394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4396531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7026342.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7100936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8806633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830021.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4263823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7864345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3933357.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3566499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4168649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3023518.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2939817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7051770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2364889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7021962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6802655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4097531.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6781037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6396827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3180426.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3881964.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10057414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9477864., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(21920398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19059408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16058779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17699848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9657593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12787586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16956044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7282164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15980850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19421108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10238102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9566238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16265450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14059726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13863960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19817760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13709640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6433988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3748029.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12585204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11156784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10612893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9277401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6284969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8150900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20174126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8514561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4876412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4804300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5463355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4380701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6172344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3846142.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4074220.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4536984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971732.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14137567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11642698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11813447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11291989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13437992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10429847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12002511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12932890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13845357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10976502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12647501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11606832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10557688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8005984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19368992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10892555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12314526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17438166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19843840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9726193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30058474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15245946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10320082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15441695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15796977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21015660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30649020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19604074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15393011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8009832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8894192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11505569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9236264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2565406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8662897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5114062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6651906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6462398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8538113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7106328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14088503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12623050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5098812.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11934164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6908994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4275811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6125294.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3944549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2332677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3689684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1812838.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4674725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1471108.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4083200.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6906448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3460733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6569852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2474648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3510833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1733270.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7178321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7318477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5723748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5888924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6740158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8960404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10815974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11213727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3784157.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5837042.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13966711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9382556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18105010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18306160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21508482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15783829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16215498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12087525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22155246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13796241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16511347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13579380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16122786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21558386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6917746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11528989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8993888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15116334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15063559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12187643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6296319.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4882961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5090371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15870085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3012177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5057896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14845649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6333000.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4752666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3528433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3252974.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4073493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2464773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4125737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6502659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6484515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2889560.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15230536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13799725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13022706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18218528., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12323707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10977700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21846610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9525391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9785500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12623011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11136867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14583489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12608443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10833583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9804566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13251175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12620838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11546054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9727884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17645118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12071989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26579140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11804608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17748376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14704610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20771948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4904914.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16408338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16050167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6265326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18645708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6011649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6303557.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17437600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12813786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7422987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7645440.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6176173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9903842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11436127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14698297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16907642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4087608.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4955623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7947120.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6077293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2315327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9639391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4829230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1517382.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3976640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2522012.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5903093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5005744.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6325832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2225951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2329036.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1440370.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2150845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7112752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3592768.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3391334.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7955199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10975778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7731588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9362222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3899322.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7349314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8930033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15834156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11176200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11136065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18263018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12569535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11503728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24026076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18060756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7376471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14867786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9405048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14728355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17980126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15184126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14167641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15135208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18707174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14745918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15436001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10623476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10050885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4809943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10652872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3470852.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9964454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2139685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15971348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10063960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4934708.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3744164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5091878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3440877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4814821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3696448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3214412.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3042131.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2942812.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18725760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13436267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10991862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12225231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11148647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10259076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17548710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12229382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19218940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15859734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13432311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11246327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10025832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12876874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12907552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10831115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13889121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14947677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12942995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10289383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20389300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18375402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7955665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20187124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8059390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18686546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17518174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4502384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3097378.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18524954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21122412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6040153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11394574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4334523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9621518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6315819.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5081007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4673639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2382078.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13005004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6572830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8082463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4679046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6621831., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(17908468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14556719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4680623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2333354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4441226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4303656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2934555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4192983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2428095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1819036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3226557.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3720273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3427317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3549300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3184268.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3402404.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2438898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1718776.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7537071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1533774.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3443107.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3727059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6068296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7019125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2323751.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4654985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10063203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11665351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23716190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14924822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15855034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11752208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16791388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16756303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5810986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7442898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9535370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8461615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6022814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11432929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6646989.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12342934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5389867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11971177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15542064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15005098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13935586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14884580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11253066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3305626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9863535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10355864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19648640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4006584.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3931138.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5777859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4736459.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7177921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738533.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7563662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3740998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7449151.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4060203.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3982871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18914888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12944130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13693470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12645466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13292567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12982203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22066698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11811702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9614853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10240236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10544509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11281412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12154930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11196189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10242806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8595803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14945124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14746508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11105110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18307432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17335088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26968282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17591932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17773738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17864110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28923268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9010485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14709863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7722573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19389956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19294444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16810206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7080976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5149955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4440725.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7255477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13902034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3467537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12942849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6499504.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12594333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11162846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3207050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7835235.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7769301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5328241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3939629.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2923685.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4250481.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4524592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8862202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2488629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3793867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2160829.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4289761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634164.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5717663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2090795.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1780431.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7342663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3804647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7303585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8689963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7668434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4062923.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9569938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8991714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7331359.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9832484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14056069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11541798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11920308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27896836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12549134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15677921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20070474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16407912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17916232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16151897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9993376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13604534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14718790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6618800., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7723715.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17621580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18936638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13260110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14287107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8487486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12671785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11345942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10423120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15392304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4561022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8439675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9667905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9079503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4659655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5007968.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5391224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6954392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3699267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3911350.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2579487.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3680423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7864976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12779743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13899173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10903829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17652178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9987299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12993258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17545836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15695504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14843620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18299798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13285291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10752750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13548782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8232191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13887840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8383881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17326328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14972997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11288649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16570700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11235481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21479276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16172540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12776894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16505119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11536687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22387206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16573200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14891341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1792949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9465115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17262860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3864219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5363327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8805555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7967359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3738609.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5241891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5064128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6419204.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6697284.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8210064.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4940226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6152767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3257716.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8199675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6017786.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4505194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5116364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8292715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6238007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4299261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3769496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5359896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2979397.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6031918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1876718.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2359773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3831795.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2066683.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7913804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9733839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8558356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6922022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7028231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5689056.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8862228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5578498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16038086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17116732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13298754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17448984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15916571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19401530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13064196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18574844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19934092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25862886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13952024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18008678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18302918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5545207.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13009412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13658145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11410664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13790012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7039059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4106102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10724580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12617004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3893211.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10703944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3237113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10024414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3986045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6365922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5206954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5767121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3077761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3558865.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4161041.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3218065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4310297.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15196812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10867670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11217017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22471920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12879368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10710350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16382241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14529200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14083608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15407840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8108311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18514554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11549116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10515787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10460721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14704408., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10912023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10460954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16285275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9842497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18376588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25881470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15111327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15869494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16815476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15709699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13735290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13921408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9654250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15641927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3628305.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18251460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7518559.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11784843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6347562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15962663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10715977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6309717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11090656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7990891.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10485152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12430472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5940270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3920421.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11201874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3269674.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5822865.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5495719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5046567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4900109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2182654.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2608591.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2174733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1559874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3578965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3447696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3705905.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1839698.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1998077.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7061034.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3628356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6305425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712717.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3682425.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8927443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6251209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8973212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9098780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10233552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7519386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17510636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18712188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17206024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19542158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9511364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15179104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8944053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12156387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24677260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18059120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18953110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5224428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14363390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13716165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13680504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9722700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14743530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18812318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6484987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8836945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10708783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9522484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6312838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6229065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11038719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5527974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5618667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4219785.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4801940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8342702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5521621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3018296.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2510360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9597757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4396593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3346060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12493994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13490347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12690707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14481444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9610847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12980522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14552188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15162026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14300394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9948769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16470806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9547090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8038839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11532902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17834916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9457196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16275845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16796358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13923699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10202096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6558859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17049436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9418348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29386008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24820194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15567750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15827476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9757095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12676753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24049172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9004006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7859033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7405696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13425706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4934930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6029090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7834531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7513837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6029837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4007537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6516296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3096554.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4289324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10565359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5823846.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11017815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5176052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6991630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5233043.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6773778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4644032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3205808.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2194940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3382076.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3607751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2106232.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1778675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1024247.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3675936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5554541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6063429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3809283.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5652012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3387015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6520496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5635953.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8625103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9007279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7128111.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8557292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20974750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17713006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8234025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8112464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19290180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17244020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15844618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17759508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7890501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24760310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16754415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21362116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21839948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14291978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13510002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21193776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11517371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10813823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3995315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11672067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12732452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15975064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14248140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14001827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9352950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11029394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3345162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9464864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11506424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4681928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2990792.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754363.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3545118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4590047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4161020.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5903840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13988545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11360136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10353429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11641220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9748076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14343872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10074830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15872160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10054732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14681710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8462542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10785072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9170932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13197130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11453568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9717262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15216410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11726174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12255383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10358277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16678942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17334352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10569072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17424196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22197520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7278374.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18750326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18504446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16917100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15777681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6166895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5584505.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16220540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4559106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2963010.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11417304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6890691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4291807.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5825532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8447140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8863811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11753409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6174669.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2656675.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4608902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8311215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2241036.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13358730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4641278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3465154.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8095119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3635147.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485287.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4181286.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3546112.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2005184.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2596363.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1529466.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2119928.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2308557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5506169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5565617.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5149492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5522559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7251445.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3973387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3880562.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8287607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5248232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10001247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9362573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10823472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18283622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9562742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15620754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19708126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12200069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12134186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14208285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15459329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6568288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16179150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21014656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13830098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7343190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11663307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11147647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4560798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18049478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9353694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7387457.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4103340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2528003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9340920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5340213., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8272750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19244606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4832120.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4875265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5058816.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4249717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5626399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5571016.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5767909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4580126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6018121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4231864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18291420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10762086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12763784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12787494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9839021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13384271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17355848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14565461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17055256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16307651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12775574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9728256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12373932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11827544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11788410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12611298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9837894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7677434.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10098280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18543254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12674244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8144496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14822008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18458532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18749532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34681008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17110126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17835604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14180881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18103704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8759540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3445367.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17107252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15184240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17838424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14893985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8343438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2685340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5132823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3519791.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5512428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7310877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4922082.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11524704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3800925.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5268222.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5940097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2219917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4895778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4600292.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4333665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2844822.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4022151.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987170.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3510492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1984329.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1372720.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2478868.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2395673.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4978595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5053070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6282089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6152712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5548614.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5929505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5421846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4298562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4938833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8614471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11801437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20379618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11692913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8019082.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16117335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11959799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17240440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9927707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10395360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14367467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19774242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6387283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7655877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8702898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25165758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10325254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3695252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12658810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11105249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11095500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7174008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13471105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13210259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11960378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12717060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7079981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2069488.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15235618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5224539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6354831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2881951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4515136.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4237192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3852173.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10935999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6043085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14035719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10768282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10164625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16931430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10012440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9659420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8254028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10132052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15278535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13545572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13411870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12717356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11944905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12124638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12299120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9457488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19044720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11853571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14500302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11483821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18012978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14765273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16663434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31113388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12042614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35093932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15581980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23214062., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13820921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26368198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5963407.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8487704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7786350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8058718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5500328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5636837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6133459.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972221.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5420675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5866435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6290297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7395575.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13597898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5916850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2992751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8474694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3561649.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3320296.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6242376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5167998.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4297918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4302654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2598488.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2139132.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3968463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1889513.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9995053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5425634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2567391.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5083575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3904531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6471005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9377548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8514455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3822697.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6627409.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6517175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8813507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6369711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8411098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23137906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7347528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15307030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15833622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16151323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8859959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19002676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18582180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7769010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14951340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11514931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23790798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295021.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13210254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6092349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12452269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23518888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12602140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15769250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13314941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8058623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9515909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6859254.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8305479.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14558519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6754667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4916204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5156932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3676823.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6414410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4689007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4180245.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2941016.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4135884.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4054910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3839158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17205876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11355283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14123915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14632717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8835429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11948399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20260048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10115349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12238987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13076776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10882344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10347079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7187563.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11177704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12571151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10811351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17916736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16462296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13025562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11712876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10937923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29327186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15539348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16268875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26734368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15251871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22073712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14628190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31662180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16034223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8943947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7743586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2135703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15100672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8209507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4706249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8913147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8586640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5396693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6873802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5845639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7164721.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6015794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10727000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5588863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5618033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2960487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4419698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3665488.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9117471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7513766.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2550543.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4852826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2577010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1850352.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4042874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3287296.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1602477.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2376641.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4596717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5049287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2377352.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3635431.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8880591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5534812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6183691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2878653.7500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4075168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9314492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20120618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9722859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13452020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9865055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18850054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12378392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21722048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18602546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15493231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18061048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12531020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24003610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11915856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11590860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8561519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6304871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11271239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16953648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8133059.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17083314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16191317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9883320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22502884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6484783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15448198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8566521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12591866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9942199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5031579.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5080899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4411171.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4065985.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3530635.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3800563.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3295594.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3158356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6755657.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4933906.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21689078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13921552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17542282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15932710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9875922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15135227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11823481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9731912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11912360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12924123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12744810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16267443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11700863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12730986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11469944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10028420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10885346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10292547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13190461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11555871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21412822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12429963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10315458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5411909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4711247.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12630870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18927140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16223963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17480390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28538786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6074599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5716980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9323301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5175896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9386285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9368057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7466489.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7626876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8902077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6122571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6753290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14231539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9501571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2337104.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7286154.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5175478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5894838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4274772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5339394.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4818453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2327334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8853333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5464211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1998498.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4718047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4136340.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4244860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3324524.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1951428.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7142483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4012022.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4909956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8436307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5926256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5368316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8170060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5620611.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8570367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5122198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10884451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12522720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10550145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10471721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18870988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8911036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24527576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12206621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7131045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13981156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9522670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14192527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13974008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7203022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16957990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19705438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24855878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8146375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15950384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11357158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16959424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10630124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9320169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10947974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9559578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4081766.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2721515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8596915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9705672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5708000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4672285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4631699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4929464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4084630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3834982.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3311481.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3769350.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3676620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3294541., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14669717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12419918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11742462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13820919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11691437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12068128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11324063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8294159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16701829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13783754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12908478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6323343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15289478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10802616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10189090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10534296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10762733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11239758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14955600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28342876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28374664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14849633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14617826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14765524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15473999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16485377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13923807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14688071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19859044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8026651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17133648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4517677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2594046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9530216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5530117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7436819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13500164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8007279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6949251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6171134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3303076.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5654634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5458449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4164751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6692974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3765526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7172659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3291900.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3015924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4734830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5603336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7567521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1845227.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2766017.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6224079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2035599.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3775699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1714649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3122219.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5134586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2995007.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8163810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3528492.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5141567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6464221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6498028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8885857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3860609.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7860846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4073980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26444456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17464972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14735282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15556548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7089061.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7168839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12822398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12500678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17745868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19223428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19177222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16618441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13189532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15709552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9659686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5324248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356811.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10556003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10834614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6817335.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7113643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22072936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9394250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3731955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5196394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9099030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14479183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4634208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3766739.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4102596.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3117501.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6159158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2910551.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4496940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849929.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6745071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11819181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10948179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11576294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14887069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12242438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13666184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9807830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10825325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13698884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13111184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12417790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8181299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14268464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13556183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13820304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15262882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16253783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7794211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11803602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10287832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28424820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27525080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14679578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34591656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12506188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24205672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11001081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27855732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822291.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16248583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7780117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3260125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9023077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6093764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4575862.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6204447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6151793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3314940.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4657380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4098466., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4247693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3148886.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5364036.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11536424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12082640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6813757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4440028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4096548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4005235.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4660973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2952401.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4467752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1956749.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1767667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5419559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2611271.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3959992.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1711522.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(973936.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3904639.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2873590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6466992.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6698542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2037620.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5887326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2941512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5380352.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3948863.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2003703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5771736.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19420184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13024788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21849586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18323364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18026172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22703644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15105802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16818978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6219033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10675383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19759094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6779992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13408089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7918622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17710350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15628749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11837091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14817214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11087623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11793730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6622581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6963501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7557111.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17105938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6395813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7978438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3565401.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13542223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4231222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4666569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4834288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5511372.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2577047.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2869682.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3592955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3548143.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4522338.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5003217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11682067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12670469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10990967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10049444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17043796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10445910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10896891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11691241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13580873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14902176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12099619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11674889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6157463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11935422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8814496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18239046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11809232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13919168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11948551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11224897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8056620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4405169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7044424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15623285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15306709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14089217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7994424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24809258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26396674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23181774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5991528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7626728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11122281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15527504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10962485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8152187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6473831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14374804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3526339.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10514503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3299469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8114653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6525413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5250473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6117505.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7190318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4471655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3332361.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2170915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5080567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2870223.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3823113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4168196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8065704.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174023.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4302592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3627521.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1090042.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1838265.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2236615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2487580.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2091479.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5666268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1880785.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7249744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4049970.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6724245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907808.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2633591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4227521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7571711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26857948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14064853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15822180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15454994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22935636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19949638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18660112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9453329., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(20555304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11163518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15616385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19741670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8621213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7094815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13265781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14129794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12833767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8195828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10516201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9509471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15457951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23291284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12453367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9564004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4456917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2914183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4175169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5939300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7262833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5843751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4342179.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3553586.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6142844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754206.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4243421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6354685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3263897.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11547366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12087754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13012716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9382182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13234231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9782483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16281268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9651149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13181199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11357366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10764969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8880796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14434705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9841236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10508629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14971144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16349553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11354938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11891898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17831480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33445834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15456125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21161286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18227704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16075522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12795611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11846116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23717844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12722842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4879295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10180840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1396281.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7027188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13249104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14530908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5894753.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7929737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2311012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7592269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12796727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5551093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7479439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3888635.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5857745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8788580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10809610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3699350.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6619079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7108829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2223633.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1864586.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4904477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7310228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7245213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3151596.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2370789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2866079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2238890.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3726116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2777411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8092423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2685644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1859913.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3663675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8801115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8310514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9364011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7026881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9151650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9219234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21765508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15168911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21173482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17144548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22440338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16315113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16320026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7615837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14638423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26270084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16005055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13853864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16242427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12759191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15320162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12340290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12722239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14816632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11968300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6610120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21142998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6697230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7401212.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10456966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9958673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9078833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9244456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4310985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3819519.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3425121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2629129.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2775129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3833574.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3585252.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3993630.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7461435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11398154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10457074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14357227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15729812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10307789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11252568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12999795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11576154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11516940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12510912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10192022., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11236574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11377618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15141794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11089954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12700676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15634060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10250530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17270116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12323336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26909334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14377835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15170895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17792566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14271951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18394268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11649776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10829316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11741679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14654841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9080330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5575860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8505160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13782306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15153350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13239573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17465926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6500278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3462404.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7152993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3422168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5934045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3328741.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2987195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12276981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7529436.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6889626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9262416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2922975.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10263181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3588599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4108948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6182982.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3794311.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2398603.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4384493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1916609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3384325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3102120.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3950478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6550786.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3487260.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10316128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7744058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5389877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7389574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7299942.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9828691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11507409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11447734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17604916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15189966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13768780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12928221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11149461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8993251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18402132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6513688.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14361481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21657456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13362842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10585696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5969118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14098138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10399453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9366571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12200555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11117107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14373385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9932312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15044748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5089086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10760763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21112274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3231438.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19403874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9445302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4695601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3819445.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2866490.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4437004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3263586.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2444044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2779209.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3882715.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5016837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4123350.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13643978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10781966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11944083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11291253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13261952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12171472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10233434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16258028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13270036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15467053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17117694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15364351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9567034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13724689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17640922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10832062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10220593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17320480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11420829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26616628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16163538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5706049.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16876136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12024087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9968013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19023914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13985749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15075038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5617774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7100270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5284911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8915891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8617007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10914264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7033402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4255485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6554413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3696623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7614423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3952336.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3631783.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6681722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5058576.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3551001.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6627344.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8121171.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3404057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6094009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2612338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400684.7500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5306792.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2985372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11424220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8904772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2771405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6808397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6728103.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1278387.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2280935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4240092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4613907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2594157.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3567432.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8163170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5567728.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6865826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5754224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12093932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14819649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15283468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9920562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11852496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11887558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16998104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21368946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16571786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12597718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13747075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10818508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13871848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10482265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13586966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6387688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13830664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16362756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13265987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22765308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13056837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14481551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4470421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5040656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3236256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6983831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8733472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8127972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9745553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4531798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6094585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11392895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992033.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4316099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998162.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3600039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7939748.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4211316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2928092.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11140696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12466225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9906954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10908605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18729134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5999758.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11719257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15994423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10429620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9259639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9945231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10004750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12055536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16027772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10651854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7869632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12844485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13605173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18746820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10390472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10707243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16090449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24192376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5054492.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26686390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18105762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19337236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14263160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7811469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11804230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6017482.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18083638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2969471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8749263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16263828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5350450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8912376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8098608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4491854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9104880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4539967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5119369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13172114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3079465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5004860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6275401.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6891758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5615108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5354670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8785950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4923242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3803819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3230845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4296924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4500574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4087289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4902384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(761759.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2980582.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3599873.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2329077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6200761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5394261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1531217.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5105122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7121687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8282971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6405478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7604966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10659974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8651760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21643952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14706986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23382454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19951020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8592583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9020117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6362780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11735295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22018466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14013576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16401239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6970959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15619563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10706781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16479593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12250895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11398820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11140598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10037234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12502894., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4253112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9521916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15408947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10814534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9286136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9847784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3663425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11650519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3379346.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3318227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4768944.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3778219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2617133.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4320062.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3821365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11578164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16377373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8176922.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14144684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9705405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16206038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15989263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12693444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10534405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11626953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11468480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5887292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8432647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11721574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7249151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9368997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11008283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15451924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14770330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7590794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16575045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15899262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14881760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10136508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15025067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15052986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10440879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6664293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15293955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17027920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9613985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22422776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4952408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4138994.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7959547.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3783338.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14939224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5781880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6389367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5927364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7794786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497882.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7061356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12646363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13116824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3714053.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3667861.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3011402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3921061.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2957584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6158365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2146929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5038189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3369125.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5944089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6477118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3413911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1243562.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7181747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3584151.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2751432.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4891150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6717287.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3792483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1673297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2282703.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3557535.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3443908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5955615.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12252113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12078065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22014554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14096596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12046452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22077532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7295823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16783318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13100603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18486734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26831676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18017968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13773472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15972001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9922723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6652460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14792331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12047169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13025903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18605318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14263760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8542409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13245674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10221682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14395683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3316182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12840483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17051992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5537418.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4506328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4191299.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2972690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400584.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2769034.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3528236.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3827366.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4010931.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5928755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11836281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13948546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9687503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13177330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10958154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11034028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15818359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11317534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10129994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12620479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9217584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17759260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10166270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14114491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13143217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16974076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11767917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10864652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10981501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14802941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17911824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16235797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15917344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16864596., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(26233682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15459144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13048983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10901336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15339540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13309719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10269891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9465184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1887543.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8918224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5974840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3833602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6468855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4516397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3750471.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10673452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7246249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3825299.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6629494.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6535114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7930214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4930466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11604569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6548208.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3856587.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5994635.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6304084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4118170.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4636349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1815405.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5224674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3237375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4879463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4324330.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1965686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3722780.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4818075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7172553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3218013.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6927003.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3056718.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2548379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3178149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3200639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2791697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11049349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9857130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19379074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12517445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21448912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16380785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9783764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8443832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17830774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8134833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7096687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17845200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4578276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6169616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5089706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10605424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20258454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10916290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17339580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11401160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6870723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9237140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10672457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10101463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8848285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8859239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7888871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7839736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4704970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4512961.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3434262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3710039.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5705581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3403907.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5825643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3498198.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113342.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2784301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4198387.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13319050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9807016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9399552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14761543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9722829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11544148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20877340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8779735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10471498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9014710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11256387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9376252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9301314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16199697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11163008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10711816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15868329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11638215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9059382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11770901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10145140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25596084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14429427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10660264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20561732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4647215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17994090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2554100.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9963700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8202650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11518183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5936539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3174492.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7904291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10063471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3752987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2242759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15372210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18232524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8705665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7845592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8056692.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6764881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7180515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13208822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5618723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9247586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5614859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1745387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8212584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1820913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2597211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3436156.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5756960.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8236594.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5010877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3091525.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7165752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2656801.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4150480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6498759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7081216.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3253668.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3125052.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3290313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2502660.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2280929.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6866540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5674306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8652744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12974910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6338605.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13763937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13960343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12935801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10019764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14111782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16722603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17763342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20313658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16293276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8773335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16010765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15592671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10144009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11470570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12249137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8325766.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3046042.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3716723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10384238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13919952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4599734.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4451272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9249972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19811044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14306627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3092567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12069895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4140127.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3591068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6887742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732370.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5481438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2377057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3329128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2996492.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11316565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14136231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9740244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12219400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9337079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9420132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11194425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6703986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10272758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12839452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10173493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15843824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11086111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11932635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17585350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16381219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9997305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12238426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12317676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15943238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10659031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14591588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15855610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15451907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14827277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20362656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8955061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14838809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7705274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1734308.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5454180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17401670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15014406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5387538.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2098228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7998965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12744714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13001071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14670403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7621978.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12402080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6174189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3027879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7036309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7101511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2471616.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5053200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5607594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1828447.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1722892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4299402.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10988547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4255516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2948223.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4593183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6069093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3278276.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1687980.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2589736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7767370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5811197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7773056.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5554680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4500198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8094373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4101439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3323312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7925833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5341671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15463319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10709730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15703629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13638343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21923836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21986754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17982284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15179925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11776935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7771713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12559090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25472826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5326085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18306244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12788017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14499406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037560.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11593299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22025110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8009518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6301651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13748248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12966201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10318797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9744381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13310015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5844348.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4978294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4568234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7143941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2407322.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4265938.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5531260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5275232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7681015.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2817553.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16865610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9355638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10115960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6661929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11667240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11610299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10121782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18573000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10860330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19902292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9665130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15134694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11865891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13821140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15539208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9780800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8807389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12341672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14082184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2415839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9359962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2585864.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15942795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10994788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14771211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15481234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20245494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13385627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10644267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6006072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17929312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8197500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17691660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9446306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8063858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8107941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2466585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8638433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8425565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7363836.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7394395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3858516.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5642328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7516069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6652140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3182895.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7586262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6091162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4609012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1487831.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8097812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397849.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6995122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5059020.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4391338.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2269595.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7069561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5053582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1318666.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5003146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6355458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9057792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6249906.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5258321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2403516.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11261068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5059918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9107195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14043547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17132402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14989594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14837956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20064282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13102822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6140392.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14170299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7441455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12743263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16905122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10687765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11470881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8987860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15173314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11137913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7174519.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12639348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8092988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10240295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6172419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4134329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17428008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13527606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12090229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14376302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6080885.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2688596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4565569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4320718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4102924.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3489781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3549965.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6046973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5113444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12649294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10419782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9019578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11891113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7383710.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16448900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8550364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12517910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12023175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11080602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10683144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13313835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9955063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10408257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17195228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12740879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12270033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18181480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21567490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10414287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5235040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12320921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13815495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15369016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15333034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9702654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16910498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5066176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5394372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20709342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14622013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16917304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4975801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8095747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8467627., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16340842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10492719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13297136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6338117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8684474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6738085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2012399.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3136833.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2121441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5031081.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6261014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3526436.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5811461.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4758999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6416266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4576302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4385728.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1543525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2287267.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2081476.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7954569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5792764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3835454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1421481.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3737955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5244435.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8044110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6163256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2919622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7353706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5666271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9586084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6594217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5632518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11762100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9435909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13869099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14272315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12017665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12049397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6904174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13545216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10075193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15146353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6774385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12089545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13116890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8100628.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11335783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17431342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15998575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13845816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16398897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12582966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10259903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3942279.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11379715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9011205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13384898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3423198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8939012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3704444.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3583467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4336623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3483164.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3871852.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5759773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2551719.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1819661.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4106112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4255221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3559150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16058195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9232687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9789977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18127640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11032417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13012985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10794378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9147094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10314621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15123358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10839096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12923801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9248876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14802915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9818203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12186196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11267914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16219980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10215265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14775260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4923216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31938040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18193926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16743538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22457318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11166776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12836107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15449490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18439152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13580173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17596030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7790002.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14447247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16334521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12142722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9652121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3585580.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5806793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3566661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5969979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6498306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5487461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3103252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8681200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5589738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4300841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6667823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5308577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2169421.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1150504.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2461920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8586445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5056078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3328571.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2699733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3510298.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3331605.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1723654.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6777265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2999670.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10282268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3988921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9665482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6371417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7924324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2882464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6521094.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5534837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12179715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16391195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7415434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14901890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15130043., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16124438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15543481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19431612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6633684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20289368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12610362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19123184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7150674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16602127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11983403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17181416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12823003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14679314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11728441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13424333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13366195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8168251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5221227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11593534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21428378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5294749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12336941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9795268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4498458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2520656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4463095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3687372.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3347796.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3027829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3125751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2187128.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3030111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1956899.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10556494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10990219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17322336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8036305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8987685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9524103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9740757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10189908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11877704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12855359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9315466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11159682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10250612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15332037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13613178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11629737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17768438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14324384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14282426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9935119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16870670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17273900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18792640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14805580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16336196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11736387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17115936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15959031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13816771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14586121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9446774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8954797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8299125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7653709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9958405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8986667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6627739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7079146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4867272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3681015.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4867824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6620873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9571229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6427071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6468612.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6364097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11006396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5565141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4861691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6277426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4311949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4475743.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7762741.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3111443.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2524942.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3990651.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6206334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4082442.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1085014.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2270430.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2965145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8567526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10117134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1589643.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2949289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2304800.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9881506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6846204.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7933365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15961891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13804449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15430106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17946610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20303150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24351786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7901861.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16631373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9776413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7329941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15340163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11339513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24114012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15846535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12617427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8438182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6135217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14905128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11824421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14032954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13881173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3697729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16416975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14980549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7807952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3550829.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3280141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12444242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7809446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3902080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4964403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4053191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3705292.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4651665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2964788.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5417949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3091621.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11748664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12760341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9016827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13398019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11565332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8442695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17286146., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9686621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15390398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12086822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12118069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10906408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12354285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9548042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11080261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10556339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7097413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10580305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12763943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12794203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16084781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2847359.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4179976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10973079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15185538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15412729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20982816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6041887.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16565384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13711070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15272171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18195544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5561841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3139471.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17111102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12397242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8206061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14983280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6630325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8883386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7073759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6730660.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7684579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6272101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4569805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3476884.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8846672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3240572.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3255036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9075595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3949067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5012558.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397713.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2864367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2702826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1317780.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3229872.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6468104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5897067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2880075.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8122225.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2251162.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7240724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3056629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5353947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4753977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6292072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5153425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10932764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13049711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21133216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16834678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12475642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12958774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7320799.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8406243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16277827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9578753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11895098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12529503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16961426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14051254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12258013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13649517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12272298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18358924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11616809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8838922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987375.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13898131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11901630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10373304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9655810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12395246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7588431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5469913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3764913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3611242.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2925121.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306679.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2751684.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4002738.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4087153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4528275.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2687964.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8864039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8552809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11582665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12311688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13742805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6532556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15218261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14929271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15427801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11612263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11747824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8205460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15458044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9847408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17748242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19877704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16392099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10292235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10046453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13727464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10447925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5638838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11012374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35664604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15898666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27085020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4622164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15409176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17030254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20342088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3106571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17371162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4062900.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12748695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7317269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7750196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14619392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15099444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8474363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4694694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9716806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842695.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6774914.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11233204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6593574.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5849189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4958396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5937232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4199324.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1745618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2386554.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2483102.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2539303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3810706.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4128623.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3659179.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1469437.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2700590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1000116.8125, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5827437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3110285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7097798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5692989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5409902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4244309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2963872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7364841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5733610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18696372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14638208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10343415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17293956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14247358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17809622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15733155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20778688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17873802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13307227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10658933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15428430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11520250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6911137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6553588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12119137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12244609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400662.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10515156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8318992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9149269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15645925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9752296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3929643.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10886903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7476681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9293490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2919717.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4350556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4373015.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3814176.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3323671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6439153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1795927.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3489228.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953550.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5557984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12903485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7078944.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13950878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11530234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8622053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12176693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10274148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9438775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7911269.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13052807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13820880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10935857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17825730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9815232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8946902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5262798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13396721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10542035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12826124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11589028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10909922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26035906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14715818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17431716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26461764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26821446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11274962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14309300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14333509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17851084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9820865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9610704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5117588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4297852.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797008.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7712901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13465666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13095068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3930654.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5358961.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7827380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13698681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4288988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11529347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3730587.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13174652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12400200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6549872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10535366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9966011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4256163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2056224.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3508148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1335646.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4038334.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5667434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3419533.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2714491.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1468641.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3750176.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6171710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4913051.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5391627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4873484.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5177644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6876244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2007915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8081495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8668344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11771770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15860178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14882225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6533479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26335160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14747896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15146791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22920800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20851476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17365272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14886471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8807970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20574354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10434922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15036201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6046589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14040789., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10250386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7573027.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9739829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12273764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8524818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14638765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6027795.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9827566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8040657.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12099847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10044027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4627695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4807308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6862349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386177.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6367328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3542660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3911743.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4068245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3775709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2768451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11408949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9968856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13165530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15565805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9439990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9954198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8509220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13767013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12669176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10217788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12946127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7305000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10660319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10872184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11131353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10631103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11884540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10782251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14762234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10495466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16373408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13223137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5072952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15933251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15871588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16840762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10071173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13287528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6649558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9344148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9041175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13450930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2769136.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9055820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16938538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2426495.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10561619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2676441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14717559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3692513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13321133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7522688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4407135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5134499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7165644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12268400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6442576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6179444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6611975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5051435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4624833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3560890.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2587504.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4777090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5132406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6769919.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2020241.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2404392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4470641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7844162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2526940.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4659902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8825825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6554019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6695695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1444212.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3699108.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7447284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4488855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9300785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15761877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10620000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14815757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18825938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6870490.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9197962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17543384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13445745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14034143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6545540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6209316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18365952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5934490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10832417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12431647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14980090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10331700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9936636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11026514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13293322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3926283.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6259233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11588057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13195539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3894914.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14386428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9208238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2922109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4603553.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3561191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4493842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3961455.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3841298.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3064181.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3642893.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1924659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11582257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6771914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7182821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12160434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9079971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11132321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16861214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8536348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15797539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12102372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10805021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17700788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9403463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9383945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11300874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10569013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9746222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13400361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10477363., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(15455752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16242575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14469248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14806115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16401775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14859485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14531646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15898616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2648892.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14713208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29377342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9493533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14037022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5128185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6120452.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6453044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13889886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6635032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9265842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8988819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6826519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5084441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4110678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5873202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4428411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7326582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3083802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6562195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2720430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10541160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3201824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4648427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12752963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634443.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6546347.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8620917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4245181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2570584.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6572787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7408361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4094419.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2640609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5426238.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1951103.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5447465.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6493323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2943191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5202438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5049452.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8487352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15514284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16204557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10577328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4799671.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21593982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17148484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7452835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24218590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5520148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25236642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12644158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15555542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11387627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11733442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12522853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11278161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10146573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11434560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10453254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14637248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6139655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9068281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13545517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3753044.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15038732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5412755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7849144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9385161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4164267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4530866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3030069.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4260943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3190093.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6001119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8537313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1805614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13028099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9245511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17815582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15738083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10610556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13078506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10408849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11978350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11220787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13015308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10974926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15844613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17806804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7919152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16851788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9278311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11980886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10808166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11716680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14348052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2368418.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16068297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25258638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20125540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14359248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17225802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15649852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15394424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13033447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14402774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15641402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5479990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7869620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2394516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7733489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13479205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1466678.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6942256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3077508.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10262954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13536245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9031166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7027742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3101339.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5390759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4495267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2925792.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7848518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3775308.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5759730.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5061903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5357149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3094039.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4505550.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7267154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5542635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4695771.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2854274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1909256.8750, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3713642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3476582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1943944.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6177521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7004342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2250320.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6798196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1611903.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514906.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4132675.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9468779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12473328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8007922.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14004114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19507720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25563060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14209986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14846411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14216995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10491004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19901200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13286867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12056259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6343143.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11071717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11338948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14795820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14200547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10992571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13210120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8575911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12959291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3231447.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12321656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11756954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8234886.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11103544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9888162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4460658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4084006.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6802062.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3834516.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2513871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3026255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3303787.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4660206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2699031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14597902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8866916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9766488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12420111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13280609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16703343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11788044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16579615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11369265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12198131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15592786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5446172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8824988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9741768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12091510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10626486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15173825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10530599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16416857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10463688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24715248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14054481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5150365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14624448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3553640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17568496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20332794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20544228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25845072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18218152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9342674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3283717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8842706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7442028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2516092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8099323.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9903003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2601261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9572525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8111900.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13347757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915583.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6173869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7276221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9735905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7065527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6043294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6382638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5369699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4899544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7647924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2910555.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3358578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4718958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2666320.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754219.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2379607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2396065.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2564077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5065711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5019328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1973506.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6704384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3600420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7872521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4052517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7658912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5363030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6856167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16984412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10869498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14717148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15279503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13870478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19248422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19414998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12062291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15486733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16327540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23439016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12985996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9832155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11368669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11773820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5613733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13479130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16966260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22314464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11678362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10461228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9651794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10307980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4653994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6437751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12370881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4962271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3058396., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3860361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4437761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3112304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2894749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1764170.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3440658.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5698771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822915.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9096758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9382532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6469882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11975187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9800121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12276250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12195532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13345970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12321544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10590166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9959284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5535500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10389066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12065081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13655051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11372605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8115193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10814958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11448454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12181257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14220632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34889116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12200831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17981996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6546991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12362244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24088306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9136964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13631232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17427188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1624505.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17129534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8607233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7902644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8067483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7909004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7008558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7919764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4843570.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5965723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6600974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9062463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5372218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11684898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7183389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6914173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6104482.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3711359.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5577390.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6239852.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3373810.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7687409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067436.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5961232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3560402.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2080505.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2431393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3213662.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1514600.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2281466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6417576.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5952751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2898872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2668635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4683037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1566675.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7057296.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4504714.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5070018.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6244043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8252956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13350580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17799088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7252151.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4477249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11107244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5600828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15178238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20615306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15307210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17821062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19944102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7861142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8543242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11914420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18435406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13621047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5001809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21868522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11547764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8139806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6070755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4624569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8347210.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21932906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17153548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5237135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4190462.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4107785.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3381768.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4020608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3840094.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5926144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5321504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2163850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4123117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2149174.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2909467.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10832238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9285344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13108148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15207057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9380515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8373114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8033154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11751438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11744879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14637933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11647442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12098493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4819019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14964823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10837521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17351514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13021439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15692241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12386270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9916243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11590792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5727869.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23055810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11545384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10232362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5516500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16898234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13606889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27149174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16874816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18429130., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10251516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8924969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11278049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9357410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16909324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3327577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12864467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6349836.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5738396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3381688.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7009195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6773926.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4559530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7138758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6664133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5087371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6245093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5000894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5642978.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13050426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8539039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4022385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3761771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3567145.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2277502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2593080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2735462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2862894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3979993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5796644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7224971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2409164.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4620415.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2167925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7848587.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3921865.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3527438.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3001082.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9681629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18155540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20583510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6947875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10104872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16524027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8630887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7819686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12555659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5314966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14214683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14635267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15885997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10600922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10197726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15365534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8480160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11650132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7422799.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10236553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9396939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13356248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13456168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11639826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8057049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8634470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9605470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15388727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14092056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4320727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4000563.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6464007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1886289.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454039.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3424089.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5705519.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5623079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6720044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14806248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10342495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12860394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13585250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11618054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15620306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11051359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6566546.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11768807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11395476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17010314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11996779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11131588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5512965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12412266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10502288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15916254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10641292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12060449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11223267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16353757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12048412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15299651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15800349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15499961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15100133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17262310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14601930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12504273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27230004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14909008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15956415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9138452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3447378.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8568608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5763337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15621686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4239290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669789.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4687867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6440087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19491940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10521700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6492420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6656822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5039579.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5683019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5802367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11271983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15465734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1779133.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5878046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2535583.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3788924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2829392.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2428379.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2566322.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2917066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3977791.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1737456.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6458034.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9203082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6175865.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5431503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7719179.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2147174.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2732334.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2041280.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7466810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4671452., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(15224282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13577175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14050079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9843700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15066582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12177333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17171450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8929500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8787240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8441540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23073122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12190900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9541733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13042910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12514465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11723611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12599341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14528915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6654548.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8735947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10980233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4446249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9797573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21611704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9408272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8535134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16005027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8681230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4904144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2787944.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4600291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4216958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6789505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2618979.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356975.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4468834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2775917.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12773098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12559934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9748815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11890652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15427160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9942001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11720121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8788127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15597722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16033278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10185283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10160642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12111843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10576144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15922463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18379332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12011389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13557449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13304404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10079954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14821132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14691592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28053158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8322374.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13997200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14970996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30632300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15028926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16657397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22915996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8577729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14122638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14367887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3752980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7759449.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3898401.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6854379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2454027.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5222707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6382953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4877806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9375893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5331974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7387565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998998.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5608409.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4430624.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4030846.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3445052.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6155831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4754813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4447139.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4271568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7954202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7921337.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2004953.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3802790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6273372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4456380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3153528.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5733863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7321493.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6586523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4190075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6756863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6510136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7941741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12485772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7813333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6406125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17081756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15798750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12447192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9270379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8299067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9678903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19782220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11779827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10417469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14692722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12202197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10947036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12354978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10695026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5768932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14114789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22874464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12505742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8564065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15512728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5492538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11940031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5477885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5246263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16273040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3074924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4284320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5871217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3856192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4065361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2603170.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3727821.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4374693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3358460.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2879137.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15392512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7844539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9028290., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10853225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13466129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9320242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15067677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8995392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11874596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11426667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11724082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10297428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12138230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11351472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7170008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10108435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11124921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14045263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12081604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10400536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18688030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11265375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14467626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22034482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11583416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14933404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33463788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22557186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15587235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13761084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19633380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1099503.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5563763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6867307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4922075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8047302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8325788.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6991935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8233333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4872137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4777894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6772826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3477754.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13625751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7155325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11830327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5430552.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16408053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4369866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3253922.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4594377.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8727410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5034913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2132983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8179062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1973174.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6553384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1519373.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3788626.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3341129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5970774.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6775707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4087545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1291008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7515907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2127060.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5127320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4684492.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8155710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18565040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16309893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17530684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9850383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14856106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11501952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11780345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8328260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13803914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15652206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6964505.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3762652.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23789710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5520359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13071211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14999852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9925548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7532475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15374124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11498775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8708857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19727844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6129368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4133740.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8647808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5419883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7399743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11084213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2528653.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5025648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3524915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4521055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104068.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3350781.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3530264.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5783635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6149031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5449748.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12035708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13050779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9986320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11570457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7136535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9239902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11144815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8663462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11311434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10377925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9138565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9146823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11318024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11062964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8468090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9885015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16186344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10706372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13061432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10912903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14356111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26490480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22512604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15432181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14740732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16914592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20428156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16686309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14168708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17100862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4748199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13918353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16141006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6393976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14183982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7433251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5895237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6570449.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11604051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6822428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13390454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5524967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3124375., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6058312.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12287852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14551367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4984820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2265123.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4578466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2718545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4160981.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7101074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4573146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3518656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2135126.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2455486.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4972301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1438228.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2983573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2970254.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4451061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6571130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8118998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3012275.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6556800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7272592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7491860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7465086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7134304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12240654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5371270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11656895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15929777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10351091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15093437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9797748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17980202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12955587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18621084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20139844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6811484.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16372520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9908262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13008345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13040063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14229563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16093315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14699421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14643970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12716554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10156304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9802938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10402256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20437324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20912634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13811683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3430258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4417950.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3781086.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2182510.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10301953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3747177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5234369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166548.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3707335.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3991229.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13640944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11868686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10742766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6985452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8330538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11091396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9917305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10986158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15036710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9818028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9235074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11363672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17275038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10172957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12219120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10283018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11349101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15857661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14263454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14051159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9897559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23891464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4810073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19615164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12453260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11924347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15232861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12076376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14265862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5438750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5841426.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23763770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7858432.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6428526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3678566.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3512986.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6841573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6062707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9401546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7702625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3101268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3307645.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5818341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8301049.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10158073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7389539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9014578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11694536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3347884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1653494.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3028030.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6763102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4515700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7656357.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4944246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3861029.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3902436.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7146037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2153402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4683576.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3100356.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5544988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6206454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5086941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6126954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2447194.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5570312.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4904389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12489526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12989931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3165172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13750602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16120807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11471184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8010901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14948515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12017035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13403407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6997435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22601998., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(15114820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15846440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5652493.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13077648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13442763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10200731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10071919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12250077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20741696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9314990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7669871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10565148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4609693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7986627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9888726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11685679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5166742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2517854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3596137.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3408430.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4410705.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2739092.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3595858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5834107.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3301696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3952994.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11776324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10324855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9416638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13724892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9813722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8195159.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13437923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9638693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11714838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8375625.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10928960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10087426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10171491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12712273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11937809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11587731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13722882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11546162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13664919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15810115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18457584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11488836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14441578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5482784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3104338.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15278432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18361184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19117148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(37168596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9395277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8614370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8654632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8930543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9648813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8776555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1478868.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6124784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3363872.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8094552.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6392408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14357025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6897903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5902582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3815620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5156919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6776915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3210380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7090698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9676617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3279409.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13247601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2996459.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6012215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3032047.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1919357.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8571286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2331355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4662251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858726.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2578643.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7239825.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842521.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4993510.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6197429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5629119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3378201.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5436542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10248357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8198811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13083050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14138132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11573033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6269067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13163071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15143509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19209116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4777478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13103316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6629005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14084760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13465951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14985869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20006700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7864998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11168028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4909300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12008188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22005780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4053122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4000423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9893299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11815001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12849158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10831264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3571681.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8497986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7377881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5800303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4775309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222933.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6200202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2494053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3436849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7903830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461950.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5956068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12193951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12427840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8953360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10695696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8527662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6445471.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10939874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9061872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10014122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16655644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10095356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16009786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12045135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13305798., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10366648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14084129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13512482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12826742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9924352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11697008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18563146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18098384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16098626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25645314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16775394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13773248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14507319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2927378.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14372117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25307424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5699835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8559505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12729097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3838012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15187717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12127364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6998768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6345967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7095832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7400496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4582510.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6554053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5140510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6637471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11401527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7467204.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7322581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5259854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3186699.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3684763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4530955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1638091.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3766282.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5049173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3771135.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9500154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5444923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2992448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2518695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053443.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4557790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2899690.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5857617.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6182312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6564549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7914773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5703280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2331502.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7393668.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4735255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14161041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12384329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7259936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15022653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7006820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15749087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22892470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14579365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7347629.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11419658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24443116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12536663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6037088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5148050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15633517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17230920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9610385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11489275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14097519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10978396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10092446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12130193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11049637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4411014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4034099.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9933357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10898606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9331647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4501251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4357960.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9303460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4490069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3794908.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3503031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7039469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4229803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6004219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3742261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11495938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6711136.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9162865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13114860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8939184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12467978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10157117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8669262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17413136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11073452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15612916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9181586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5086138.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9609578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11283237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10457949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12586107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11482994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12254640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12950526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6577300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15733295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12299487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15388286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11756906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4771276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772523.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17393748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13613128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19248140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11631406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1557106.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9706735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7183116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4285203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10489890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8133392.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15905898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7185651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9772132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4893651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14747021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6937606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13753436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14541454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8103871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3523667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7362812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5471594.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6156669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3909969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6519573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1543701.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9524053., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6239774.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5954571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8918690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4462181.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3369829.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3797763.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2695907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4271745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2858833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4118100.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1297150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5995494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6387855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5712240.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4700083.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4311161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4070573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12210041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11291564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13723965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15363601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15020256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11828233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13414093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12494528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6531141.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6578314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15743172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15727322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3942384.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14838122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18322046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13625446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13917339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7629133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10148752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17051818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10038853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11125069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23324240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5718130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10506846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8411975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10912720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6612646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5311969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4791769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816041.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3575013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3758693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5440884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3951892.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4886923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22322090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8346283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9061933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11517638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10959069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9078125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15700141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11101668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13636083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17401988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9578248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10630934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10776493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9884409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15977998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11253881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8577867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12926197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12068542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10230288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14593347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12700176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13946922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18704180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24232806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13628744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26015378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22909336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14347750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16064895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8437618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8325651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5084183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21158000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7704069.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7344389.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6668308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4455537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3170383.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8356712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6480760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6039083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3158205.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5821953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6328727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6586007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5656299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10458080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849999.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5534701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1976388.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4131726.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3802724.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2414683.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362162.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11720772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2940632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4086577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2977258.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4427999.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8033800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2627361.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5804798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2686973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8268542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3940652.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6259673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5828260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8107032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9722278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16213061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9843792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15141339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17048972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8377666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11505824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15239072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7272637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9247453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15783040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11683707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4751477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10828027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13605306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10793985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13919625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5111047.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9647085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12339606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11767486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4595490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9310729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13262144., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3982636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20490316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14486266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8540293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3564280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4506368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3944509.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3100214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1767533.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2638069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2738289.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4100581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3268985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5273892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9661700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14812190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9704058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5337642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12367748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16275528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11504675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8957155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13974477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15338860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13599275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12502030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10318567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11852768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13197371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11383906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13508012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15521992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13261469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13244049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17938120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13456891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12261115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14012190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13983920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13978475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13812323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12536743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16277516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17779786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5911499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11279539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8040335.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(761189.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12428721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5257413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13605313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4643100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4892787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8281637.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6623680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13664184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6400204.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6422692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7416857.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19428942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3731080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10598001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3975531.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3756960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3639433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1852405.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5214499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3333033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7556974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3915366.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2038135.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2172073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4061002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4327534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2471306.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7959746.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4926824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2704213.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9909561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5066056.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8681934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10970199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9003165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7606152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6433959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14324599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15252493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9285778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24319176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24323750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16783440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15026400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12205614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12822511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6532462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16717015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11593861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13439117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10403582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12967248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14524108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13675673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6686176.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4589910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11614150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12984954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9993246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9774229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10325196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13708206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4023240.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5471561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3904353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5207110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3824863.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3478113.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4805243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5778838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5650173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3086257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13117610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7301359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12207447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16938582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10102769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6990793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12639578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12698724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11954048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13396318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9361456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13819340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12381860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5731061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11233014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9705620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11189116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13413805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14929612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10198870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31803868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12498277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3949902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15070798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11536170., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14762829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11459272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13099991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14484503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7191522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6827875.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7945730.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5887904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14127733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6071080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4717946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7066044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5515254.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3812431.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4153319.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8113698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6412997.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797645.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6666007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5834742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5443304.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099831.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1425369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1571383.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4412716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009149.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3319915.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1981640.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2704973.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830380.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4065710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3409437.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3181607.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5113090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6984778.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3844365.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7060524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2629888.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4127513.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3574340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5613275.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10039008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15537230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12286780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6086190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16890260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12142171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15567281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15475227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7225096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9053373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23913660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15098603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5693464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8569588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5904735.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23028926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11567749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13878149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11341305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17320160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11483384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14490035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22568034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9125238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11326073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13258928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9219008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8606882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4484796.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3410975.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4509823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2938546.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5128496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2705187.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3027889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5027842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3041073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5482974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16652605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17403144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9649285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11096536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12427494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9673851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11169718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8670321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12944127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9044248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12660688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9995973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5224503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10228552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11568503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10041839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11226201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12743902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11034410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11542837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11659612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13259938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12365482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15392277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12082504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13255979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20084870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18507424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15948895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16092860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18763860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10304150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1940260.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8002889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9673912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7690397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9943222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6732752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13015865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8801229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18124284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20714010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2664671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4368345.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7347457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9519711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12650647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2877702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5517958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8040895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4295231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4807107.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2832724.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4892630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8093692.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7390928.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4155709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1782802.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2656167.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4015456.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7429981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2267689.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7325602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4422503.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5434781., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3875256.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5349920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5245413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4989770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7240462.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11256053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20125158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14604988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14620071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16056381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23331508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19348878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10064025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5938660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12569125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7390496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14780585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13307963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12472725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6591784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17159878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12557332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17032086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13736253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10660071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9503413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4566663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12312907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7536153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13289734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11452785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9334765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15378720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5394874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5345215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6223909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9396916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3197565.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4747472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4848510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3552497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9585485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9412601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8640228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11980328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9703913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10527417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13861779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12620114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8309331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13358760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10005711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9859474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8742049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17453906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11087095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10980337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10256402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10682019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11368894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8938558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13840044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7005028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15335221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4081216.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11671870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14591674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15776749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16014001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15453079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21162412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6111723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8593384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8429164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8238809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16853722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4762853.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6683528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14740548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3865968.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6953853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22646006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13747254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8703260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5882948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19951310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8751442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6789815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5662314.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3045788.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3777571.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1551448.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8498475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4442218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3698128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4107115.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3235036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7459675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4591155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2189481.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2228548.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6392845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5089408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4918001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3012105.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6413538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5768555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9177036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7253593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6394034.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8892686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10053546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15896180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14663100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18909630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12435688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16623900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11953433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17785080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12540240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14943097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9719803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11290723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9889583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11792818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12207463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22048912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10248782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10997610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13040015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13712385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14829199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15179837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4206446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9832808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12075275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5384054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5706280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6831513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353209.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3866956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3465801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4638013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3779726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2300204.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5872808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2917656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11182522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11313417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12726836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9714476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11605078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14300430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8674395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11462411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11506224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9723451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15073844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13484826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12170151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6714332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10215604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19552088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11733942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11404290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12715302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24255354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14080984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12775148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17233762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13103285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13672327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4253633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15868065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15230556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14151901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8728871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16274284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9734611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14566895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22819422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4144002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12989043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12739697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6165513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6713187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4304920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5034897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3326636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5860299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6856967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7141985.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7153633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5957453.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5359863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6641683.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4538011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4188176.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3131868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5724318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5164478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2913025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5398212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4322140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2719951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2064869.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2121138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4674294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12003271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(958717.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8655061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6767216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4840062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5183760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3257529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17304348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14220031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16177138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11905158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9569522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11053285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11716002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8358873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10461474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12539338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12980811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5727673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12332683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12688448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12636694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8547645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13410971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11330907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13471323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11855964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10584918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2311252.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10899507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4344038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11517178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9991677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19796166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10387994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6093417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4406749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3078022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5020903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5636838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3451709.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9760286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3332957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7677897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3533436.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10365454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14633610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8213665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7550695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10498663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14183881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11375361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10971125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13111178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12669812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14914936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9583104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13389837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9561742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13623151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12267702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10223506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15193964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11589988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12763091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14524688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12672473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9738413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14537218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15752687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22423880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12784376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10942764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25846234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8245145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7823212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5227960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3733823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7735717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15334281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5343594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10632870., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4105646.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13626807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6960422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9566915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6431644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12816478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9759940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5035927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5852096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5190249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5554863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5428624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5478148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3701448.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1347895.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6871227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7591955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1780072.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2862059.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1324423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2459475.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2769958.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2946093.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7077080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4822797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2191362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8777545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6157415.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3426081.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6201129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4147261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10939781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14441325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10108444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18959038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14401344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8896182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12176831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14245280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12714920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9133953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11963345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12325010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12351419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13316084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22366448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17488844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7449095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11958778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15840277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12972336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9023168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11131014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14902333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10163720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10457490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6518226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10056144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9005383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5266278.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362131.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3082309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5039561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892826.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3874917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5264206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6027341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4729221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12051396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14440576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9516622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12254402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16550116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9037286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11050482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10880640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12705248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12781897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11627030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12089096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9112190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10403292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16906946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17610244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11536881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12793866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11268331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10396305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14198234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24123696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22202594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14862288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16890648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10717073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15490168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14994788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18318336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18831008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8536283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5863248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3630273.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7009519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8202353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6043443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6712168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4082993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13891457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13156537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6056884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3291516.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7654430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7574022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5262425.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972977.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2327771.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10828705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754053.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4922535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2539363.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3837126.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3577781.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6631442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4914320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(893498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2541244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7474330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2191106.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2353977.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10022053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4114698.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5260432.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9592037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6426042.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6164131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5898366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4772692.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7744580.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15588383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10840067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13150987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5314266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10889839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23204594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14104130., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5555128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9162883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12711545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5940150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11286337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15431631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8772642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15940487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7215428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10980113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12103696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15465669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12441193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10570743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11901179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8993959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14850264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11997298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18777242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12043215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4415765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3794082.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3726683.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5188108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4244316.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6422423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5151430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3257602.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4216293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2913665.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7688424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10703281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9776814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9001326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11460541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10451955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10994077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10141992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11540003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13234350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10546652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10619653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11445379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9720134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11377044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5887058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11802442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12245476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15927347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9240507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9849334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12944296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12569203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12573070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9824833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32517266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17125588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9457986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15360181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11996277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8743979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8432164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8119963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15517885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8774777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13849753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14146353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7302007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13065430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8090610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2050296.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2684408.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3022033.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5937479.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13848962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3855194.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3456879.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5253801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6157519.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6345851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4151530.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1567772.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2877779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3063853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3506344.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3799770.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8381031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4163711.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(972586.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6568284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1798283.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3905067.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4475234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(819230.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7761197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4942053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2546392.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5914270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1206615.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11932295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8304777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9231313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15559973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21932874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3801761.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11789178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14961792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20852268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12062650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8502693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17879188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10560174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15690113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11579305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11668639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12154448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16190466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19266628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14331540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12523458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11575607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10806728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11433007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9957976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5614129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4273634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9383669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11089772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3439019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2423561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4167831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3767004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3809058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2740077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3387022.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3318603.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4765601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8805728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12852043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11535797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8145486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11859065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10754220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8851469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10350483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10362479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11940539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16280732., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8827304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9857734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8294365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11121982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11061416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15027316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9580429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12643411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13833615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11659818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21209248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6382399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30461932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11527375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10774435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13979200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13843136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5678210.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3600079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12992788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5543649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13520306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11851610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7985404.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13606655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8786472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1590211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7735251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2930499.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9075268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6897739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7715879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2906071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2431020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7507977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7118951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5293470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6879078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4933878.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6901772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4686127.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6021714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4869760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1939918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7707043.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5538541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386260.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3477049.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5144271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9887714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5049663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3217606.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2513661.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5480411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7536797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4417878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5605996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6387500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10452062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6970294.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11992662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6373719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15195335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12355167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12105920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11388319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17712208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16109205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7797549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14591924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11805151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12168163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4794704.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3801593.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5534100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3711883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9917598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9634693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12359561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8539416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9643896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10432592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20460096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3777154.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13716648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6220959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10442202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4204326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1884572.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4338839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3899098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4876740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3181406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3786524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4521537.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4167660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8277186.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13046213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10757171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11207053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8581702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9688133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9486737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15015741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12638198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9272377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15102764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15413808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9505259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9732698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13492650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10388773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12669533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11398358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21225994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11826150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15921557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9437920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21624128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13209238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11712906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9146439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3079961.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5152717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29940886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18083196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12710702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1389461.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7474329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6764461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9697350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8401057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6655206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5072920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1793558.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9087709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6758536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6023110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13326824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5813669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6981705.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3137755.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5404298.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5782965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6064028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6618379.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3544364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14374768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1927436.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3215090.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5680653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4746259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7628565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(691390.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5195414.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2824739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4626908.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2249715.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2755685.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4192758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5857990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5588038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6013168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4750117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5871838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8059839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7483823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6848313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12800738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8331093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14508338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12275432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10983561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13359352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2622285.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5863567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12214591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5193472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10854440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13567296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14540844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7049747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11187421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10452716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15647141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10646598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10416039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13625342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9588554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8938381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9085128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11046525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10599952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9602636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5950746.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4680662.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3739371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2699873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2438793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3284327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8338416.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9778996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1731547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11056608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9248498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8571019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12296733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9635484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9545698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15462657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8964637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14725477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18002612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10245669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11121776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10212638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14260827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10503955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4529896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15077922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13222173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10024108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14867851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10398735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(35909020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1657905.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11160711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14399821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10247345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15775242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12564971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14871414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17534378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5231422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15623873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7313367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7875568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14812449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6116112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4334800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8015501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6218976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5783314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7333343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6236666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5593980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5819684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6869746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6782013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10748115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5953599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5956599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4838831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2662898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1884142.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6764473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4123618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3540221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4817440.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6435028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3002724.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1408467.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4132523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2350527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7136043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1766900.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2781223.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3277435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5433508.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8232066.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6608670.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7496182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8835164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8845464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6469393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12200305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8481188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7678810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12083030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18235954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12938100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3517538.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13583548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10866426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13002700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17128012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7361033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15700265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22822058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13229706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12897213., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4666256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9111725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15689576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9670808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5614392.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8665996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5273088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18150278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5562712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4069573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3950561.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3265854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1865523.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2923640.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1548928.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3272178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2725782.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3349268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12860867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10029692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9496373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10668274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6677382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9931541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9933595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9425226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13896449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16505449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10431260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9790130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7464411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10868924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10597486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13049822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14030242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10461518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11987123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15025575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14858698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7467922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23464916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6283983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8708061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25140276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2734736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12219990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6355855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19681512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4598387.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8222326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8495288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12220883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3788426.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5569287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099273.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7186069.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21087716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12335383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7276208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6736856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6108682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6795954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10641243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6772232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4897777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6034016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5498299.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2725695.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1424605.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7797064.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4646850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1325677.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7847806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4118731.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1596163.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3880442.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6490726.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4628264.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2635143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8343133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3046757.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4404208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3354605.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2979996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4423745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2972509.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5929345.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4146842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14106947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15752988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9461230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6799094.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15355395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11002412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18556810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17676512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8441794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17556776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20654590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7182602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5144856.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10889521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12095977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11262426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2930646.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6902442.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14827503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10322436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12477865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16549710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12945697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14073701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11519159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6138526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3588838.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10139010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4637918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3191930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3144292.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2800587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4967564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099697.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3482251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3714413.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4223260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4757607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17171896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14223811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6782164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10165408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6499663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9856562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11166566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9131489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14101416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11701155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8688559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14650297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9064866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11569742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12841260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9339131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12585279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11720919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6855563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13925464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12879040., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13708326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14686262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9744557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2268800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9623685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12569273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10657854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14062744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18083184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8989092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3067608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6993800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8522846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7960199.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8247984.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9658268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4304774.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6379630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14350061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15615309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10694996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12287300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9940462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6600101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7648752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4810445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3827502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3007817.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12810371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15511732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4025141.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1341676.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3149652.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6419957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4856505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8899002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1365471.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7872310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4339808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4030254.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7820360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6347656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5442761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5337897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5569978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2316286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7762085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5555461.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8749698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9837953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18138244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13401019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8383711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12125450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7456010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6676532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19831194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10316273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23115674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15790377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7651387.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3082199.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11607821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6074771.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22837268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13077448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11114460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13173500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23443304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13446656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10034262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15675229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8969717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5215464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9120306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10312005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6541240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4876207.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3659328.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3455245.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3546714.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3189903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3562456.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3617599.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4237242.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5259270.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9996566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16358628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7389660.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9612619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11747924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8974895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9657970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7983772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16780404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11497814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12658114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10310163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9272499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13013897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13323662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10752922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10750389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10654147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11702900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14897458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10042847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12219816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18053024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12757266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21687082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14221209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14182683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23638786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26756488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8405079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16604726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5176991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1506094.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6598863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6849916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7931902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3509248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9596468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1365851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3288783.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10477137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4486433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2108610.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6175981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9330002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4279770.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6452991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3256410.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6369631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6003052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5724973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9301569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5509532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4636127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3110221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3643343.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1761737.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2874015.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2353641.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7234109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5716806., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1795754.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12030375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6786003.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7623745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5145608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4887276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5209756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2660125.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7092927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10815560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20495348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19233306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11515134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12830919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12049165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6018781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15124889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9196236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15516875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3479520.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7118298.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6392986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15161894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7280711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13849357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9454662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15402631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5687772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11023643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11497873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10404605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10442562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11215938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8363229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4285428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13237356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10659320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3310360.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349009.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3193150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1753384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2708920.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848103.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2161982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5921864.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11771342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9694181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10493903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10793886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11806090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7888990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16254552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12737718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12061338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11600068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3682195.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8708797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7234890.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13573672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9900007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9464849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8760294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11152581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19948408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10822645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13632674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13930037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12164729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15552128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8061116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18406202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22752158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10733185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12206376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19721788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8655154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15125410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5140653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14790665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7979076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3387094.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6721893.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7604888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2397964.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6008796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3088893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6717168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2705898.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3008801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5458172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7897287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9188708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6551722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6163451.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17670020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3333469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7525569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4460193.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5339315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4778597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4396284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2339422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1332737.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2270871.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3562780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5573438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1688180.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2375100.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3513661.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7313979.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4938501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3881274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4920671.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6364261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858785.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2814300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19295846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11312064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4225604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16213128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10266991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23749172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16513404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9005803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22141314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11726562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7300658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12273498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8507834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5781807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14074409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7034468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12825586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12880424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6726256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17177550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3988015.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12756161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9718586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8937278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11716344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4700766.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5886064.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4016927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5165839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5152736., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4348723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5309366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5974503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4227344.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4409704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5215513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2729407.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11344833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13827674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9311981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9931830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6169355.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7865632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14306712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8632012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11488857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13773641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10612927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18189104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8920797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10346756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9121364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14284309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13692261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9830481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15421376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9607863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5790023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14319624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29875932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15358944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6317945.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13614353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13804831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17005368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13098180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5185563.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8120328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4175637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8450939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7042958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1967806.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9589112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10617209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6560527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11666279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7298198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6108312.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4406356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2124360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6267322.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6654273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701870.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5745545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6473983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9912957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3879715.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2415178.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858961.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009275.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4549964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3947674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1279893.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822062.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7787852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2340910.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2870869.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2764303.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5040019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7562054.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5293110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6306333.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5343204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3366456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5207855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7849893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13513844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3882369.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13844500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16369355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15927975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18234910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14781690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9831070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7617568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5856549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7476336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14193754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15797626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6424855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5253537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9568094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13001407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10424173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14517801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11585733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21962802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9334840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11210937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9914733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10661396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10740718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10110417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3965881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4979861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3407800.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1873898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2728955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4409638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11019406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3352841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8071645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4139839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13028102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11035123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9317709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12699478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9534850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13491951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11056552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13975941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11101468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10546162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9849264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8210619.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13721555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10605712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9363512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10337972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15647721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11388125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10311635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16560708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7106894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9847262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1979905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18758564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7249271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12449911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6995760.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13267599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28066864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3613861.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7624980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15919472., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6492685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5416855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5404632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16473678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7643056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6969353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3684105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4307475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6338897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10443854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2929675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5566865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6469871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5700591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4161457.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5988242.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12379148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5427686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3564159.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1192550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10035000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4694846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14439242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5314696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4506255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3136956.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9135547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2458193.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1900627.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5204679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4660902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4397980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6364838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3243974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5030991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9181887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5523718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4632620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17547548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9552440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21559300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12966782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5026051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12059352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3555186.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9656731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11985451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14657177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11002964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11270205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9804964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11113268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11914924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12643396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5513220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9265877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3575087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11155479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15544269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5400844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9575576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18351978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11086250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13582982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11532881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3420673.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11712389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3475068.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3223955.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5004131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2818150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4307134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3061121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3116494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2895677.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12061870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10422074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9443925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15243066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10034293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8233463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11584278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11409336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11879235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13630718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14177624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18968202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9106843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9341202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11593325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4124484.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15865194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18789752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11972331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9639177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15269594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9038564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10050225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14742838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12679699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14226688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8868689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16937724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12408160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9175648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3768930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18277244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9715299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11049108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8362750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8506608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15291768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15246231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6465016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6618675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7857233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6254766.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18115340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5980275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7546961.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3305351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5074153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2425884.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10334022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5234585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4055175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2079966.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3877769.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4531560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1745824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5160185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11417427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2473159.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8123925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2375725.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4685112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8817973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6227691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6739314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4243547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7627213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3296660.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6205170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9375349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9730673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13829807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18519586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11831478., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12133999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11413083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17796706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9272705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10158894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13542744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13811543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13225663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7464832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9456505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19702000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8459003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10807417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5366034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5312020.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4901128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13112463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9386481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17812818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4600978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11181377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9483550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10559604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13197547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5378187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4916008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4512612.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4143524.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5156211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3658469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2770019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8172318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5012356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3102855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21117194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9706716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8675208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10921047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8411654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10383337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10355743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7885747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13883510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12505914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9554318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15058804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7414838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11821482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13146864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17976992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11973498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15177829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13533400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10594162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22790366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21026112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11438027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12434658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11652657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7006839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14119664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4821680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25990548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7771840.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5405943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13928199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10103812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5644789.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8201869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7702012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4447793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3008717.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5155775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10061045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4970850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7840633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5190204.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7088828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10749410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6129439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6223825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6033221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11210324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1422218.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6050798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2939333.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2174912.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12241638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4789949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6316972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3523960.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3730772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2842018.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5198606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3776252.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6502001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2896015.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8061934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5087923.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4772061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9018766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4259606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7118200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7901498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14315675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10668286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15458105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8594588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17312586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6374912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22809408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9556603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14453066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13145612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14143987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13085680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12525535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13184078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19374120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5382884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6410156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16185354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12052495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6644264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20883166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12168842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8990920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11346236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9352613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11025401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11275107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2868793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4045307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3944172.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3181824.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2862687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4429349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4053672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5547790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3092157.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3894619.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11508965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8145395.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6810768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14295171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8933470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5889517.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10673863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11657207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21161932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11860786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13446089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14124932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8010986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9250997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15471280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9226341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10686936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14471088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12111178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12222814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11662726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(30336748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14344705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11780845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14002725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11893945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9658940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12620612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21341292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9084183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7717546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15083447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5579683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8313712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1988792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13123657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8200178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5982436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6026054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5485916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5529527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2413523.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6652402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6828240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6396032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7391050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5806255.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6174661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6828467.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1129418.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2433893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5528028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1782781.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2379300.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3796582.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8781361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2824985.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2534045.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6587133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5155254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3667076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4261561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8310203.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7204600.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9919232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13811696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18070162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15276947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12351334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21592588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16753968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15210272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10118625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12121610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12278006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12677890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11267527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9815199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8510024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12608528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19190750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3161161.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10356911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12115217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8877871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13483080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10748609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4530150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13274004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12622197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14504335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12387324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4686545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4118837.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2095035.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2803356.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4136498.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4295047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4090056.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3028365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3620831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7453597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5409153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3370145.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11938683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11657273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7637700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10452274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15510470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12353913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11719932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14812262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8199540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12094714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10324018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11364556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11739094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18236576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9240824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12033377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11453175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19238158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17349554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13389901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15968565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18922590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9989275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12481731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10478485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17636040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14609297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3108492.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7116920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7613509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5646385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8348226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6780260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9891478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14365022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12757986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8736398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6883895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6103283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7877607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8304132.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12076489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4758818.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3442807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6958282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15377135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4750350.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8355489.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2233790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6002962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639147.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1819681.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1252578.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9304081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1201565.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2029435.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2824639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2185492.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7952541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6811139.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2051061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4673972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4317700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4147092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3926717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6666442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11173727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16413264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12917712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14275998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14079187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17066714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11733049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15557743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10247345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14838236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12538258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14921059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8373633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13068888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11211074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11463351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10886659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10528408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15460515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19028776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9620266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6527392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11725417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6641661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11293917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16570495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18977948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10143548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5525860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3558870.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2765778.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7025453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2718152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2182558.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067540.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2790679.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3692108.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9574920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9020464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9118769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9667531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12356827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5673266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10271352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8099024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13068032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11197218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10540864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13828572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7969284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5904963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9687884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13774505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11871446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12051589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10682202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10185869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20783358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13318697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12593351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11897056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12652156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13313080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9192928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4045669.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18528676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1992366.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9016823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3631162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1616381.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17050910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9557992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4238247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7960610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9745017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16028553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3213775.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7475686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7363192.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6849420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3538588.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5668815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13799557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16172338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4980162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5420341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5340772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14007808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3725722.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1396534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8208234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7870123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5395890.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4877100.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3845965.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3391382.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2480637.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2530358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1904158.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3095623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1144903.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7469950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6467560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10935625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5165682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14922596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9957966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12072299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15726140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11481703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13960248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7788433.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10294948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12413634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12161373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11347726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12259576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12957318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12256778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3499208., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11789242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5291674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12960369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11208903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13616383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10019772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7349500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10960756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12932694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9557977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11732383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10091823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064002.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3439605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822672.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3750484.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3277352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3465171.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6696245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7762559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3788783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3189000.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11935435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10041383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8699896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12405110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13635577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13780621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11302620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7299762.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11541460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8322042.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12020013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9212237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13589769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4705303.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8962995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11112486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13384386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17902358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14558326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10578690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12459453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19728634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9047980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17324614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13461285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10585824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18931760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14157308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7940551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13356603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9097727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6075332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11128919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8011859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20498592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7809068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6558616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6735500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19604638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4781231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9658626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10925420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7129834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2625604.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2277621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6586569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9322793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6183915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1316257.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4071544.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3662625.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2521386.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4127206.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7787757.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3794652.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4328961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7279766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3900007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3392800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6303801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5198329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5640070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6003330.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3217920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1154129.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2114429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2686921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4404361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8205727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24591940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5579344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13766750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12626713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7327761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13333034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14894244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10139025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15784083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14626287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20483506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15996692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12449429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11478199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13474365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5358935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10671581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10806002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7758260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4579189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19019366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16280231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10041849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13063621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12946611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10181303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13238585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159512.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4076351.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4170418.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2687344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6357619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4717672.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3982945.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3202499.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4650104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3608162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12470076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10998473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5627976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10391571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10627988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9978343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10627447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10487546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7820096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11770320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10081224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12901362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16277764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12471189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9323851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5105803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5597890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16170667., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6760818.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10683880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9878175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15848297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15005879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13828703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16608203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11640375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23262300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11288811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14520601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5243290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5656495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9777084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7065324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6027543.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461314.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2243141.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7788612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6672409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4360782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6381104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20430438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5822243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6165213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7040078.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5193059.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4124121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6262555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6579486.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5146644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8595071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6062507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6322208.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3756031.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7676644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2351766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3722135.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5412797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2032443.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267596.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8277860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2167743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4882364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6657483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(855295.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7784595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2091819.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4796345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3340424.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6252115.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7714783.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6724491.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12082894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9222120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16922028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22817046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10878635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10759750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21943214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5495434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12322235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12048481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10773659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14606996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13548822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11446560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11163732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9831146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11154103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10860422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9989032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9558244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18215624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3593271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7219551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9653229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13145820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12592936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6285258.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5951284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3025868.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3804110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5380727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3670047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5269350.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3378582.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3548078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3618825.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11089638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8917783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9986695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12442522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8660728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6518900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10180691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10223716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15100090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11466892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10399434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11304626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11803268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12170221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9262652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9741207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5187944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10651227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11693954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10718072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10704124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22113736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13503390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4796641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12309520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14079259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12904405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15931799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17130624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9273953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8685043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639813.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12882744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8741820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8121644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9042606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8002334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8719331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8692892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6132150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6414200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5971905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2912192.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5925909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3968829.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10236024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2250880.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2331278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4914028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5760369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5561016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3379404.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4234093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1455137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1870993.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587490.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4661875., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9782845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2407473.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5467455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4981502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7419902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6868421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2622094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5734755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2727820.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2485443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5786477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7462810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9441604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11868284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9408747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15138096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20760316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10809763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14376830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3692152.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9940102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12296555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6609215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13321549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23315170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9507594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11076591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16783334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12296675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7962441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12477162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10253260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11760778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12864192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11159216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9247028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10042496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13930772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10095860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6048220.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4054508.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3861042.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6737197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4056899.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5477079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6534962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3766911.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9281016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7855022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11355373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9991156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8909647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11169272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9229721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12273226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12698347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10077455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10077985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19197574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7705102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12259108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10810948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11587717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5628920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9969615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12212798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11268447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11645309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10538584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17254284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12993213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11356812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28649604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13415774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15993271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16611461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22360154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16380967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18770574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295511.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8966928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1950806.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6802705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14682719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9038297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12824231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13783909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7061823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8084055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6344371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6829644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7017431.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5583004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6949202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6635352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4478560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6382617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5745924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6812902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5193305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4222336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4079096.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1968448.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4118606.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4532831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1954408.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1737088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6101008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3180201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3894917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6595822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2683139.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4872969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2640739.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2701981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826496.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7388237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1844766.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6630672.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7602178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7317567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9003064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12106304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8413493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11071508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8746891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15142523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15605599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6814782.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5873300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11080081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11768331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9850139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11534367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16004510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11422564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353099.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11389208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14052273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4108637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11760491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14345504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10373877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6783207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8752167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2626846.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7408131., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3588532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400108.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3841901.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3345683.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2965426.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2387717.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541668.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4094320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4129469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3004274.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11018224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13837587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10147131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3958734.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8447595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8326805.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10464868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17917870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10544327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11661667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15436138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8432040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10376471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9412752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10784428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11518078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10182078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12414850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10978607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5474610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6793951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21109562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8243952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15612132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24613074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14142303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6876407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4532748.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16989836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15348486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2637982.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5615440.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4686996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7971870.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8124347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16915324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23893492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7106161.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3523869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10474485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7351093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6485544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5179420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5507841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7140259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6654696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4539931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6693131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5523893.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7503841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1402815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9251802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2826862.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7577766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5591279.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4162298.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4785249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4280268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6329950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8575947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5745506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713513.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5451883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7197574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2566431.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2804127.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2524962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4953951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4687815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7983772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17017750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10186992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23368594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14741611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12511490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15783839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14496274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13996220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17679072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19577016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11966877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11868467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3401866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11241329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16832776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5277599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5320620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10236980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14189779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19526802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11510139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21677520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7339490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11446434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15501497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10239231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9650954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2951352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4690937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4632217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4342870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3251610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4327759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2991984.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4773187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4746239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6077718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9410138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13538978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8101633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9961438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9492452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11578347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10625950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9731169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12817487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11459772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12843838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10048033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8562281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9520316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12318171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7208098.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11746558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10360324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14256076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10848710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32145524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11253005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13354159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20404244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16844952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13978920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12008701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13031220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15854739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15288628., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7239881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5197409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6478365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4573454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9020738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6546848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7269943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8538625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3342585.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7274019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1788525.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5841843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2840182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2445339.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6235067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6786005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4870833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5836915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7981109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6229209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3019539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2329503.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6474406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397794.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4245189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7421428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3437212.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13002731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7182056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4197056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2584180.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4789701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3929934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7974090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5260957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5300792.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7113271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1880608.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4276465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6993944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16638074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9287859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14964178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14346569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14013568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5622114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13151080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15859302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7730146.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12374952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10728579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11662093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5521583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5493362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14386964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17578422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19085440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9257133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9788901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8720937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9001561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19534192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6278599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13469516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11488508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6506078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9232590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5274421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4504173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6824417.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10253169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6057276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3532290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3199438.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3745803.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4439341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11847559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9390826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9131874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11018394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9245234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9451131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11238705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9579667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11404686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18997446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10032374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12560414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9556122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20131312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9638773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14398452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13862922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12787077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10743810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13581965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11503101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15608055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9986206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12553309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12963243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15342068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9566669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10709162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17505050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13145713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9511963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12212079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7054777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2226000.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7615202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1942201.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6734370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4238239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8233120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4034531.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5351437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11526034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5991096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6457425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6065007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8559744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2950841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5571772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4621687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2240633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4893962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6614741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2039357.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4988384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2701894.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4960233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5234762.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3587484.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4860933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2153932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4703881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3391586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6777242.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6596952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3107999.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6649824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5076454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7628991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5502097., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9773829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17097148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9842470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9892579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5409938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4699244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4744426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12790887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8279267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7453063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11877764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6745589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11353161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9287319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20730844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21249324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11419917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11709764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11657180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8398108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15657683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3427492.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11248181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12970766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5755132.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13732287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3922930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12923428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7622529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4634413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4946933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2968187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2810599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1834627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3710919.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3961691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4966933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5931498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11844356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8826533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9203915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12281344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11529824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8846554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10315510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13540706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12223363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11805519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11886903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13384731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11436067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14619199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10268065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8851128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5460912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10427506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10633894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10115470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18692286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23830998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5626303.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13320602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16432411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13706800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15973212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12995461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8551977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19521408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8817992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25933314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6891820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15345589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12175109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11205840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7321886.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8119698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6398269.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8007613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5958749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5751864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3132615.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8934991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3954139.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6239529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5116424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9365517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5893851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6789107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3145924.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5680495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5571553.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3438883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3598602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2742920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3064315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3871400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2784186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1888118.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7347618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3769060.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1806759.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8715660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11251863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5578421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6633053.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3960817.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8228927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22387162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4091535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10982167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15620655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11209255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18507174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8564410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11158510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8406798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11669601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15060897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3250311.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5906841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14472401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22885730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10521307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11182464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9556121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12625814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8552671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9867449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11895636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12557670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10427608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11667160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5292040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12523369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5625704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3374389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3501087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6891365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4150452.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3584868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4423387.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7693148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4121635.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2907702.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14820627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10066632., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8132936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10759943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8142418.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7552076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12076181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11545256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9116044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12234373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8554050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9905893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8210075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8938758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15324109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7268813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9909552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11015579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15278636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9730484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14580965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19072262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23195254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25232744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18171498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12380971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16418985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6384215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10220497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15810354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9962522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11954935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6729188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6482606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11476290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3844334.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6720169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8619011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10665259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5248639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5988209.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6397092.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12580495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4994159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12173659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5874140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7487797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3871025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5868534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3217370.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3674204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5361555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1680948.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5679510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2680255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1286378.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3755751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2092739.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3040996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4136544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5969468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6635010.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795220.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8363646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2458420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4241567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5993683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7788705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15882349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9733972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20033320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14298940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7449823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13260100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11747873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12037631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5614907.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15015767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2615681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11235915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5977521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11568411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22544872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11146326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3278857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20140598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9235878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12066363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9409557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7456025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11022055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12639184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10497689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10631807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9465607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7251690.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4645692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5130314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3229260.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2012100.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3684165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4056601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6055653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842491.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9295856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10220040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10899050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13589505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9435837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9075989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11072176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8482327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11177033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11190160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6524072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12014719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10199396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13411137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10901578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11484801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11353292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14819748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19548994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29153122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13479296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11187471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18821394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31154542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10006338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7020809.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10947206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23977460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7802354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8064939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6439040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9176769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4136206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9185448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6630748.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13230602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6033124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6965168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7774098.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11939952., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6323132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8826753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987980.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4069980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4901220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6243802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4525204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5010143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2314335.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5744766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3315840.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3552398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4825946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5117201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4143654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4759238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3895651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3110786.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5410968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6689874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3569966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915467.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5365961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8543297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4276822.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5102353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4448074.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9468759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13138002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5938196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9515457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14373510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21229292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15748544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11168507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20895632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11471921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11232833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10489843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13559803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5010723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8546355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15934637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9184510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10642275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17379560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13297467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19902966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9846951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7618320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4620403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6593455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12526563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11177739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11979679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2033934.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6204643.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4379035.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3760649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3038304.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3341722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3212217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2907388.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4563265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3107224.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10622959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10248686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4761042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12180003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8793108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12143691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10756155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11279072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12877635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13414495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9917069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8000681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16238384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10078064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9360238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9449874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11199404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11084368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11192335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11428908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11784588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14948884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11016720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7038328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13840497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14379873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13581227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15427080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12160204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1661673.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9843356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6573544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9997554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4962278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10876176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7280539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8950134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11331020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4576168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5827553.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13114756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13385994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4650626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6750601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2882680.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7249210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5041531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5548854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1200143.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3444997.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3136147.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12499390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4523782.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5536382.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1042187.1875, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2498140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4322268.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4341319.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4483734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3475215.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7773913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1992872.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2976248.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9102810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3218501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5498057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4513225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9474587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12711048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9033503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11135413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11711405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18987828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6836277.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21420774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3871891.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11542361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7623856.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6250975., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13762130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8621406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4988424.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11161123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10140948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11520059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4448147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10304161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10873281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1841746.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21866984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12632855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17543628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10938674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10452364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3927530.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6447663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4231178.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4991293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2777578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5511047.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4381525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4554697.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3506923.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7691982.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8922999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14522436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12122137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8040330.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10520340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11109609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10889490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18041368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9350864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14068625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4342912.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9068503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10394596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10007150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10902880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11230497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14056446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10084013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12206514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5038880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10129642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12073397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14471938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9946708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14794658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16546235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14845042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16874344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9486388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1841887.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24516998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11510404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9195944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4211941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2675372.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8800545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6705032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5223430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6505356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6449015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6034496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6003575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10016429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9644735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12553274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9424567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5571058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7109298.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3034912.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5877066.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3646575.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9733390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6330714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6946011.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4813696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3722132.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4236011.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4343925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4282841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3233929.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3872703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7462536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1454027.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4194793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11013906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2887251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5101123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8353597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21923484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9364826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11001802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14952362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18294806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14471089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12344963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2663988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11356398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14197923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11056061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15280472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6192864.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18199296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14328712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10106966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13479919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18813832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10620623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16162949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3967300.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14696549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12429599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5985142.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5449207.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9964968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13378428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3805028.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3161223.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712948.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4676803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4029312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2789178.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3352764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4160173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5255335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3749397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12011534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9261592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8674221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10654058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9671108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11983781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9036882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12119559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12875338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4772544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4056626.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9116858., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12532052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13126410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9957352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12210967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10778891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10605473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9911119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10186329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15027921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14243336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19828434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11277515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20003722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16757324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18324102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18567388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7096266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11922636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2802163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7362782.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8111630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7791855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7577565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7549043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2574748.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5659581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21376054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20327202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2574809.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3452068.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3965111.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5531658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13122416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5831249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7501317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3147099.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1327677.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1242467.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1546062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3954406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4249500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5284231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2504871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6250395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4351331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2551588.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4030806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2060908.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3466773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3195906.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7658605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9421339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5208481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9868925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6685173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12142657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5693858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13174230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11744314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4719130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12521515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16451060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8216321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11082423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10342932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12290320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11005500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8308250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12615240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7389954.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11499045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9273329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4207195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9976065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8944526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8057076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17125366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3090246.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16400533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12178221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5426847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13957442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4133157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4149218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4139179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4139419.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2827713.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2469017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5864353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3904263.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6141151.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4013760.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11885914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13239731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7187358.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10466010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10640092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3290398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11124568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8792044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10866291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12007988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17399784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9120000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11862667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12669647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15048413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11469651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9033110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11054967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10183468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12239918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9283585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16477116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13038863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1794396.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10092455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12209146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17689760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12290320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10095520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(33891012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8750782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7687534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3485572.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6830743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9218037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2501324.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9950195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10283356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9576046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5375602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2396870.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6299135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7522397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6879844.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7343573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6449237.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3986138.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6780797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8463115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3410998.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1922905.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14192312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3691435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5241088., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4074568.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1694251.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9589013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3560025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3741188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4180602.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2319666.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1733487.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8853574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3318510.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4249137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4525895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4848616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2902597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7973256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7822775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7460977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5530203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6472706.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14389664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13597556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10086461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14299449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14889084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9913739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10922367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9976105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10394296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14331538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5643568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12044799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12807396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13025839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13073088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11442705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10232613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6114806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454304.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8947595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10744396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13445460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21387540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13865670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1980403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2960083.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4029815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4156064.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4584707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2633264.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3065030.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5074168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5593088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3902402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10910992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8158769.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8141200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7344955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9728708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11074594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11846480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18179714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8616372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11410563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9811604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10467037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10411978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14286019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13038227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12248427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12160364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9581734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18272114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11920072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11846291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10919537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18067690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14638199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23421460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17063378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8002713.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5129023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7316040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(980375.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3373658.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15985567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9742059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4259610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5633283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795947.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11336110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6219227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6273025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5959525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9175692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3940353.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3412052.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4011486.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5680518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6679533.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6430924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5565364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7251076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6069289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4596505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4120930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2457979.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2869072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11237385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9428642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3340195.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4804487.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7846823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3512157.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5759730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2925713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4601096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7291955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4647677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7218765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10015334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18499328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11467081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14719363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16628529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20656784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2513671.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8847249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5641549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11693279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11159699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7391206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11983788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5764906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13421732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7837822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10403576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13316523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9043002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10659565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3841073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18690078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11705800., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8071776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5728723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13031073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10688242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10579767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3995984.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4382692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4277596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3588752.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5844135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3329570.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4957268.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4740238.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3546508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3916132.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10794083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12476585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8573321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10442023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9532646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9139289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14156384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10775282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15476463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11725875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18283522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13235260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10086787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9589470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8934566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10021868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9676703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10849673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15321838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16726373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12949115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20821044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14533780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13865714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16942688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8278348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6166530.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13785929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14902254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7294078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8582299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8861221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6560040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5694548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7211761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7815142.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10776348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5682721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8014476.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4280870.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12996154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5921210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2821431.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5781825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6724254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11850058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4917732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15396464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9413704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5273137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4759968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3660323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4706023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4768178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7775865.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2712933.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3319073.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4815353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2054889.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5644562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2378865.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7231787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2354055.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4431747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4357994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4535136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4054933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5626873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6324941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11019974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11781230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9872063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14147004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16607335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12364923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21476406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11894949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9808389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16792150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21246212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10126141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15418356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6469717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20872302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14740217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7419603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12339986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14525961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10580299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9845070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9547344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16294967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7070551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17063962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11365765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19793740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11083110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4139026.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5597186.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3966295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3161485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3459354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3614549.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6286682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3025720.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2908799.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11324602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11648655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8149281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11794245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10654355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8844597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9030873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9753625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16971982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11975966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11151663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17053456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6842830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9908419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5616151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11162952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10669890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11788181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9677102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11250353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13699075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11325834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17629248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14798197., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8866983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14179380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21281936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15052818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17856284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8508707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10689047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7441754.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2784428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7147371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1936431.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5998902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7756851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7006895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8367162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2143348.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7585448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6391809.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3664723.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5813628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4282930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4231596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8334504.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6288867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8986116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10143930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6997012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4586193.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3765499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1698956.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3607969.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3933744.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1583043.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1727182.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2393954.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5360751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2744090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2497689.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6787526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5217699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5435793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7273863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5279793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4690068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3893466.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8305413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17075542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10320987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7206008.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11731766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10312884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11784214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5740296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8632510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15304274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13506032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16660079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16595059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8383134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11520902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14078955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9592210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12125293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13468723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10144302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3884138.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12916977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9047574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4274796.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10002214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10260012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10764854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19589034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3601873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4612887.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6486162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3447091.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3643614.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3930456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2948901.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5641180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3854469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3725050.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6481514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10391793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15424219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11155197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9595266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6628869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12108010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10351259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12943720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17285590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12708465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9289114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8282264.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10977943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9639146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9684133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9524257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6058865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13384975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15672543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14958295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15241390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11647681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12598199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15980888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13107569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9347463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15780204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13396114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8977462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8616398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7461479.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3620302.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6679437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7557729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6275963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713182.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7210879.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12512705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7789521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5885260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7033612.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6036884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3845540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4467017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6098353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4490743.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5554411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2946022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6406517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2226298.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4463653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1343881.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4827207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4594943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3985194.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3072733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3606874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2579587.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4604470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3455683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4286953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2784967.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7048685.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9932530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6243890.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3190410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4052593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8122367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6075565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8684763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7041409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8986055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16412383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11549802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19602054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12197671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13995012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12203294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10785068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11955551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12989886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18698200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6479753.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16915408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10796181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19519134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4175605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2378796.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4404996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18704058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10266444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10992580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7207359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9552447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7449259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10557391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10093877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3004904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4054032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4235732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3351790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3082523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2545378.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4008724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3685388.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3882864.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9941656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9267174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8511260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10768566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12022548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7737071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7721370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11709151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11752317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12140720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9706903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7671375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9714637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9656475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10300144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9219158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15282814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18077734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13970617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20632006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11515217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34292780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8104578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9188928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24807332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13074675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13680398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11484369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15765719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17796378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8140761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7526638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2404295.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1653397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8785613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12026626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10941855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3522998.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3538946.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8403830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11503763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8133237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6084234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3554553.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6132731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6975805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2157883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6578509.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6054427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5225260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10655104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6473038.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4599867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3451000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7062973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6040162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6760638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5032183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2825346.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4771697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4891016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2234500.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12866915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2654562.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1770826.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3476469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7979119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5528140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5237837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7502057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6668107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17973402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11704760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20676776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14970417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7705384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10551491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12708036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11347490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9968667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13276688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10147413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2591626.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11594034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13735023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16683524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14206116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4601045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10319886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8807190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9521477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14605341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9145961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6440529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10133464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4701355.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9571361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3655032.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3149492.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732344.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3236224.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3463517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3558827.7500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3910102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3958636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3751891.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3380661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10707846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9312452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10140425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10448446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8955883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9244719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10474172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11032222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11516592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9635711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13303176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8503027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14240086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11922104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7784447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9775159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11458761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11607847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9216484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11228023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12923913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18261584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12985349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5702437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15368366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11868265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11936623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12190088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9721821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8323873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17708268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8726127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4380564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10438314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19022474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2278471.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22102526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16041879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11737936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10912013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5799551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4589820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7400692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6807656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3021266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5852980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2239459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7800597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1452879.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2457041.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8237507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3873800.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8483660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4189264.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2335864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5205836.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2914742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2638852.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6029308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(769884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2982585.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5867580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4909033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4720158.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3202343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5604354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3807683.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7630750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8643886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18272168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9503425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11942812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16697675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13692610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7125811.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8212004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7095964.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9999578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2908648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10956727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13092593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11177838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17495022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13733200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14803654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13825638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10093164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13706275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17749228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7751012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10153723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9220322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4460167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7509905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10255672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20635916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6988738.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2872636.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2666644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3135481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4549001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2605024.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3716963.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4362476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3969758.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2869163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11739157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10043272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9776034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10679990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8715972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10928740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11281278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9098112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12086375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12277163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9098062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10460420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7721636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12201451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7799509.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8914208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10305894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9387540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6097430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10150890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11703426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9823049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5244163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18795084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3307712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15670864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17103140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21691576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12184915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15445216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16797024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9296330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3701600.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4896640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20367940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6636303.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9110749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14955798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3279883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8375259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6805267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6159511.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6705827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4310758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19757906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6053054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5046291.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7066506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7505635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4820580.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5731165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1186245.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6313865.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4188149.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2185572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3917820.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2343512.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7275514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3254090.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3688712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3760614.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8264695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6195239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5297501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5475544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4275368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4733063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11583718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9515013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7159441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10854975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9332811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7634904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21452300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8772510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17944448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13848489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12349531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11243783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7356168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12740121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13607580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11443220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13850808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8827208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18367214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7902850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7868749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6198679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12234728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5536857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3509352.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9392308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7607097.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9674754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13226645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9764112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3364141.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3072714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3692926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3542911.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3409220.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3080121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5558274.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2113175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4698315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10080923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9262039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8298934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10955885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9422881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10541178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11111938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13269752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10970602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11145724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9136368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15889597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10909062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9175676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3089478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9387348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9889224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9844170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19818674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11444566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16235053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11705578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11698410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9664507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8414457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16098576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16846566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14404638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27901158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19975250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8729189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14385078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3540784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14997408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9410809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7476922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6150404.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6596589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8106571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9037929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2444244.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14073522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6538802.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5323979.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009704.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4180861.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4511990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7922974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7183525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6048277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4576592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1089794.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7997459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1496286.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4444241.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7502129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3736379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2278348.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7627545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2767100.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2096575.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2966911.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5537884.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(928943.8125, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3740173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7170613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8245088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2867024.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4516524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5332370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15436674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17411924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5793466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10694409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11787131., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14312687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11864526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20244202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3163880.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9975092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13655553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9645687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11533839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18892188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10699875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11441018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12919417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10605023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9754072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12607098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18602770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9778267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6092453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9395802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16676879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2966133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3840776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2919753.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3920828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3456468.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2423265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4780269.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3687083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4178267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9809324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9225258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9061610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16065986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7891231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7948012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7659098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9170526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14894125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11459613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15161512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8263223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10213375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9594537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8014722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8025863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10039570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11589272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9714289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8722297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9433932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10320591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13998201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9436742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13512545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12105887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9613054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11374981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15459985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3307840.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25033420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6706663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2263077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12552020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4038891.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2864400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7713003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15387332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6080072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5698694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6125330.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4688324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3980155.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10165742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7047215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7809870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6998114.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6074458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1509175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6273287.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4380608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1725516.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4202567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4404783.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2261550.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6502114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5579234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2590296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1770937.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2490072.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1975273.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6616982.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5081127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11909460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4837777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9706418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145445.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14493592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8027845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14080259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14784263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6096044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10957158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16721812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17801122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12647812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15940071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5067320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11324733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4273100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19118956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20219866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9758421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10818581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9094546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10765625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9143983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8646726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17661242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7326788.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14842176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10208540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9351104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11555764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3479444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3006945.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3418453.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3551370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6308435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3036546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4312569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3378539.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4907984.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10660542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13811588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9859635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16394532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8967185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4576474.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8233501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9050519., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11214514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11949598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15088338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8658495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11813113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9954362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18647086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9105897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12760068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11065560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10194317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10884808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12237808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13652786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12773363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13956319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12742691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17073454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11331783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11551548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15032433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10514501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10129519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3164755.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6763648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6533711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8807478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6582187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848662.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7878817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7061254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11878857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6000647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4625371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7542826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6198123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8322877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7682334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5811411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6494187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5029673.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1464592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7930223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4163909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11715434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9963685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2795387.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1781782.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1122916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(923785.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9458872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3658363.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4253884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7157855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4897660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3143933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4363124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4980209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5341245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6466447.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7280577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8796434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11112373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12897351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13005453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11067991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8274815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13940095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8251444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14179438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12944291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4692562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20024350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7248250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17345540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10850463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5583991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3914398.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5779302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8485731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10772717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7636746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4143865.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3867842.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3450044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9040000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11544071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3184931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3752560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2774533.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4229350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3936917.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6648276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4203790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3885791.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5096403.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21978624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10274127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10797332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14048847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14875759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7917091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7156585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9561239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11669522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13476522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16211988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8834915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8511748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11099191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12086055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9266577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8692650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10771306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10092756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10995266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8756698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5456315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11774884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14813111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15477398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15062538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12855640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8644519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12250462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14471414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17044008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8831179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11477975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2203624.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11075464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8779329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7542483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7697152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2206946.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8561551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6201295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6621322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2146637.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8073476.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2701681.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13551083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3542263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4497997., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3399868.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7582638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5232430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1499186.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2863988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6079226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2906299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3803483.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4231448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4215949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10172937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3317192.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3605081.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7367246.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2886200.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2171060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4317752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4358553.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3221953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(962097.8125, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6476948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9765520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7532061.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6172664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8009367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3793176.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14813101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12841731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15731656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10008121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11539232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12924687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11584879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11063392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7999993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10834284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9861496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10694094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11872850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13146030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5462857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9491295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16049113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10795837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8144101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9707059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5827952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6444269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15497123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3018227.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12347039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7586298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3773851.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2997794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3290737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4957291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3667886.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13626912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10510790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10310380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9338366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9300612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8714597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10262826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11359416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13166863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11501743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9472465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11686187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9602211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9453832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13680561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12509403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11240693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10649461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10766345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10197643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12858573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12010102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7719154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16005859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4658679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12251257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6413965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(32568274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13507832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14819181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7743374.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10575266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6273177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2791523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9088414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3522286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464069.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4674328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8407870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7978660.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22315274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6651873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7209454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6960040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2216668.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2724154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7403814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7779283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12669389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9857317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7129770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5913223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7827132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9569645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3304327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2699916.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5377191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4010169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6728228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4011508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4530702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3984939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5139004.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4655496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5220077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4612268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6970670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7238117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10840595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10956500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7550262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13003106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13555787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14356335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12463674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18311116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12047189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6044702.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11841235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16151446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11800439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12308573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13873590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9556208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5831712.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13906510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16267523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10077961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20751536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8583856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12142391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7695911.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9937112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12312653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6095611.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4210775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3645607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464312.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4523607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6632767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3811707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3453405.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3594823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5156509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13827128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7370565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5592953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11095541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9244381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7072075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10926054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11616401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21757444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14740787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11096783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12455653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9430008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9505831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10308510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9163523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4425657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12270165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11932986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13199862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4221636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20552562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11069324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13208448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16314867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11694386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15919094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11314521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13449219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8377668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7409091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3832088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113984.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5694353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9153416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14512285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3382812.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2137090.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8533957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6714640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12339696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7392969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13339286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12167116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7008980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4900265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6626034.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5039659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7024310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9069291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9143169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2806930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4636261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15849127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1839848.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3686510.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4860136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1034484.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5112185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3342948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6395410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7538033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978103.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2724063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2460824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4632317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6438536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3897557.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2632299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14711177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10208011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9450591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10967154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15999030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7357650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2180999.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12417610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12095642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12426525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11719231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10344128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5326746.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14762461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11097792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11173948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11026354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13404753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10105807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10345856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7010549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9021506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6469452.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9248995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14132993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8813555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9926000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11167452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3403759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4020748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3619000.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3895823.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3619160.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3405717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3874437.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3819926.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2127839.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4088419.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10750579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9163637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17452564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10702334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15145536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9018546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15798923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7002930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16498316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10802424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9252126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9468488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10480346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10162312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8796163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8114315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10258323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12451170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11665212., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9756723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14899161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5389913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18120182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8048950.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16685207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18268738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15934501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17101592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11002984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17433018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9126279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2059470.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8011747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8648495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6848357.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9496384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2381551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4107787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15285705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3126062.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6596679.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6342345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6329138.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7553108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6521739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6718415.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5823114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4001033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4677373.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4045293.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8628010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7638384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5965050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1716801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2939575.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4761978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1402665.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5555867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3990088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3878388.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5106029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5909580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2608035.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5127621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5329802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6901820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3104689.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3339998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7317712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12973639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11357530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4387622.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4702070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7682373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5358786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21842410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4355228.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9738531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11240887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21820492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15734114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8422953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10262384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6792980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4714368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14617567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10184454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12240080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9191152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5477166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11081837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4110002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2872381.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10118765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5727090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3169195.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3912128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3479179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435134.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4303952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3565518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4245354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3576310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3786927.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11152493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9816370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10079665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9570902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10011779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9675754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8688313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10600075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8506221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11306295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11592861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9954656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12176346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12381034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14331306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10226278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13415483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6440670.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17309814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13771636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8968875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9962814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13514717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15313406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20171022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13338006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19390406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25372138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13227248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18109456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3787586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7255221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1414429.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5024297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7676359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8017032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23124108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7296458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6444957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9736285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5956221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4206754.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14174035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20459222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4071358.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12557645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3684503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7384915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5415597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3573920.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113407.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9046677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5991408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6389364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3507969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3685638.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4129238.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3863591.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(843012.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1809702.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6531918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10202550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4669147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3105666.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4630608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5332206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2380328.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7424483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10311039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13935813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13278557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11483504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12314888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6514446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10552047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9177070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12128122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9561822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10609351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16233311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11704033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10802619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11415046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19376418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12275568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4771818.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10183388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10274684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8961272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12991904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18474018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10587892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9330447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6759134.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18373424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12668368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11687352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3747446.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5519764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7167334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3344930.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3760971.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3709234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2427310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2966191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3336611.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4289188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12552706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10708676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7999545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10641772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10821565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9832460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10833850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6928632.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8537099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5493442.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10768601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8873546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8701724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14025480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8987596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9773134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12145198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9814026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6452000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10447604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21295142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11836282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5072051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9694301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9763801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1551308.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10607307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12552191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9984422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15704650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6911409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7935089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8861071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10607283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5264861.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23168276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9114265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4169966.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4742211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4598987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15371626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12264790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10830628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6030734.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5677133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5998542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2068628.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6998301.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4982806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1002102.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2360681.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5317720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5183421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7401564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1049120.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2411979.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2808102.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2801314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3633795.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1807746.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3653251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5030772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3530079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3873403.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2090861.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2799681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8401968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9221355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6626338.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23857500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7601740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9165604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11213759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13855886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11672320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21907748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4736444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15896657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6253033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16432380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9840640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8590176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11646361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20466112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8997286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10075335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8343436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4417302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8721033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2500315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10409326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11013716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8201140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3275658.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9020702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12392326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2597032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5569978.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6707721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5346620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4179857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4022401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3343646.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3792853.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4433029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3352832.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8123281.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9602102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13453399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11089232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8506770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7426815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8440818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12067123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9326074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13202683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9932368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11096513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10093388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10181316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12046288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10258650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12913994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11116470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10950156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9855334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11987751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9465391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7650465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14922863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13191874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2293696.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5393859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8806335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9906871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18222314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8135862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14372280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10096688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7702095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10657516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8381994.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10877539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8578722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7001613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6060523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12501431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6402301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2766808.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4916969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11669815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5682822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2608777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6690922.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7099010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5502095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1427588.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6336050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9856490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9863104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4438028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10401815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2745345.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3794192.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4747497.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1832054.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2789830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4524806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2612884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6200848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6879793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3281076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8114338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7531724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9099527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4513084.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11486459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10540120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9456055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4070774.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13743651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5027662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16175939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12503122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10281680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8869409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16711220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11223495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7760994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13657736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9560162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23352966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9538285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7380923.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7896959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10704864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10295322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10311427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11157625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9465473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6288458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6847185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4315645.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435107.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3615109.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1575683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3211337.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3657113.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5014802.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3015869.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2845598.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3131345.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7763344.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8301420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11438850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10273883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9719298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9015599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15865104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13073217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19931424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12374915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12452081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9076539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7516702.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7955657.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13851386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9754402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12804996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13076092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13108124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6532333.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14037955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11483024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18566964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23208086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9770637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29931188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2831243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6113050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13486271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17958710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6111359.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8744761., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13163689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11979177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8081991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3344921.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17899044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6989369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9361661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11937521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6993427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6661029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7970130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9896064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6143512.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7695485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4895417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7508023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6113743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17635518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9583984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2718886.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4062170.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3206003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4645969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3071877.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3976326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4158925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3209083.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6470111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2565351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2402922.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7433485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2102253.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7502901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8003119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5420586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4397925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5631069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5912062.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7314283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12057259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4435083.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11792653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14456992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10969715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11271562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17126044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10595560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12878751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9084811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11322538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16213092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12198224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11125464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8904990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10252897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8957393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9327051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18714728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12150422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7874929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18464078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12446358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12765880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10357288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15339083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18533964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2412842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3293313.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5734437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3707435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3626562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3878891.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1529063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5451967.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3068547.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2704851.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13367040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9095216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10310795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9360052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12972762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14096370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16089809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5899215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13361670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12964631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9048034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10144252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10830317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10549872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11448715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11732550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9530733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10573856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11680489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9706245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11088692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20508044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10564152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14349457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19456954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7420902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2769700.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11683626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10322348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5142089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8187721.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8650939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6403896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8175197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11753686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9941038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8512097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7502542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8364582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6951914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7312466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5907561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4084458.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2796268.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6843962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3785134.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5904751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7658073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2122833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6115133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6023284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6124167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2034384.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2068896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1454028.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4688469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3618423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8658977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2756262.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4582321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7732265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2245354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4828493.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4574400.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174174.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3199635.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11407007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5864921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7185240.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12735525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8251560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12070507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12385325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10729152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14635309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15316459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10469188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12849788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10703581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6019196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18813204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14873980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10395004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4839245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7178616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11278216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22614160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12022314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8745100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3635149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6346581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4379676.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9348215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7480412.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10336977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9484556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4717616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5495504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10034924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6052702.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3909675.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2503723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1226116.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3775616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4399396.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3746152.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11129129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9060867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5108065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14662357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8893933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9821918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11083592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12476306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11513162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12582193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11321414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9632283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11530525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8926390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5551676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10430149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9547630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10576048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16200774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12364016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13091370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4263449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29012856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22031788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14951440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11113318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8732402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15661781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16686029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7212372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9681865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12170045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4792557.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7935434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8268502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13648083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6666321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12758175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6442463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4425758.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17383950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3504992.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5264884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2269913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6482406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5096916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6621441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5079856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6469724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3560126.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3458672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5342484.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1802763.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8772834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1542598.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3796500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2028528.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2200814.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4505830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3455232.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7069162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4428820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4260877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3801843.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4629409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3432839.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3496131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5623632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8399562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4813117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12697717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4758004.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13465437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12282212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5864772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18970444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8946796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8502363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10702454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14347990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12665858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12542105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11188691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10987766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2365542.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22367000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9090131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9951085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14765962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6378915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11568583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11333207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5483795.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9837860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9073411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18259490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6096922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5325800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3912652.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1641929.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2780811.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2541431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3000500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3893759.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3493591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4686183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8208931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8327070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8853880., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13516189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14172564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8928828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10405715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9285216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14856207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9642925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12515006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18348030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8761222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10382969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11516367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10066100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11156471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12436694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10295939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13974032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9878136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13941314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19015196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3753849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12158027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15962349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9091120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17362196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11426321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17036762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8606930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5229550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3203497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5161685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10304524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12835969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13895670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8974499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2121468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10309651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4141123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5217607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5521717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5286581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8543941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5588108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6640821.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5038129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6346961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5766137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3604513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4294000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1934254.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4584161.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1483966.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3233150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3733568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2997310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5706419.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3995085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4151341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3835894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10656202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2141653.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4059715.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5549619.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7494036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4441212.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3558021.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13016123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15415749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1085705.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10349551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20269710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15388325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9900934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14342683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8108115.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12462790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10267387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10559610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9463762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4937448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10555368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4288727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6954317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4778742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13626965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9233814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9356854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12684117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17248464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17407978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6154679.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11333047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10088816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4303717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2764022.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3858042.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5030250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3354738.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7702583.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2725822.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4105791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4506087.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9561646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11999155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8798554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5954072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8255594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8991262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8952832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10463760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18195160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7797477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11589008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10117068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10118881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9669247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8549133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10803420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9522398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14167846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11127075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6864501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14179114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11477826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20173362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10355799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19195970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17515808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9968295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12315029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9963458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12110803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12103932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8344658.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2611611.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16348577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6824035.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11636448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9941975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3200550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9918402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5190003.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11099918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7431540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7152599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6004858.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4922897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5745888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8203425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7607853.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7332119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5798934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4466554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3071610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3694841.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2716454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5244471.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5098162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7991676.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4681940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4251954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4720368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3534992.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2083012.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2934742.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4747796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6025462.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3389068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6474007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5304590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4214896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3640177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6396168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15567393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(902867.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11649423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10514507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15078172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4531287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5288873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6930362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2038731.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10196493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4472272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18898446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5063090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7540615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10094784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13614935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7003486.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10205361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9061487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7609124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4656553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10003548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5246541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14536345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19772710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12261100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3452568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1780487.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7898890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2804732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5561939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3013586.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3802790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3857694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4857081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10994356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5300530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8250343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15413542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7158612.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8189654.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11704924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13348159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9445474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13665463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14510978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18983368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7336923.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8340238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9624767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10053666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18669688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10869690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12142595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6358359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14785304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13175876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(858590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9700928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11470205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13403650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15594362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5793749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13625602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17925714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3252672.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4639359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9351443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9187113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15859915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9201474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6962397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4555911.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7071246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4901641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8744378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11589392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2279547.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12572481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3342206.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6597054.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2178060.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892985.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3626899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20736110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13198096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5069916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8722572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1683288.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2756682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2657244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1941398.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4529124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3742049.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2285985.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4160486.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3485960.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3064129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4511142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5024413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4394532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1558139.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2227785.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8520966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13668833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11630994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7823043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12409419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12125553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13140539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12878684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5006299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12010983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8985001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5649951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12999591., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8409046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9676615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15193464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21538796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11152418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9139620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12749910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7555090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6709401.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10559353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11086399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10447840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7106317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6191859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10980420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3619050.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6999959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3258126.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2495719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3384100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6553091.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2369698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3837219.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3279190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3765807.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7427815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8837416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15182298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18723338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13039707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8189107.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15263983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10313621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11350051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10790479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10348165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13576794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7195384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11370690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9987263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12459701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12677709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19368986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10359146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12470746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13153391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11645459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7999171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15695108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10871844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13724464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5489560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15103815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22967504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15648642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1487933.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10664956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7589010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5871678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4333076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8627669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14099306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8639202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8077016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11421578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8608159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5167399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21443702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2044270.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17816454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6923958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4460513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7000961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6573617.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10584607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8932463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2500683.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4941331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4196862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8435502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3133723.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5043521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2163459.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3876334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6162077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3033769.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2471956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4245866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1779979.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6594317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3273885.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6582089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4750455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3679164.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14019733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13394864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4395487.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5993272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8963404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10667149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8692534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18109514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8653136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11772276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11068162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11561305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8166445.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13268301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13702320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12926444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12164235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12253520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10541492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12739163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11090385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14957340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4787612.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13378968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9793659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13995363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3494154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3792998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4768644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4279100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4382959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1790693.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3352696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1883941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3130305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14681885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9582449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7460418.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14549001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9160778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8308650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10427477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10494359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10540159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12629370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2219266.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8068948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8739692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12747882., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14096329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10247596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11173566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14426019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15904652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12101048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5627864.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10809574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15260206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12693256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10465771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20096188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4219045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13505163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(34041944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8691444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9355257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8262080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4748672.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15063510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7706872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7133250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6242100.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1272352.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10174539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6792280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1365493.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6615561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3398472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12201639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14665916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4493690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16491149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3924067.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8563281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4713414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2901373.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2474189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104106.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1627461.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3946067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3092751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2133105.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2950966.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8341330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1841353.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1531418.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3189980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5978454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7580281.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3425872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7553800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3106133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5071503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6591331.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6820609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8066938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5021588.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10250873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15271800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9431848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5337188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14480142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10046984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13429088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11325107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11502686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20091038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8582601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5761109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12169291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7473339.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13488631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9950653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9331268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4346414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7804394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14491533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9714781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18809806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10995530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10184233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14423598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3727472.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5563559.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3578178.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3181561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3819893.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3635096.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2333783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4653743.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4806501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3367953.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10173058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8713763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8542630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11684842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8850260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9462845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11461872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8435507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7912346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11319514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8389744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8884476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3124334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9730824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10452067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9529325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10141566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10795064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9686757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9328195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14487548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4213797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10122061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15533467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15143696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8019140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13395829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12528659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16336167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4657291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1226823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2566387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7725659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17585646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24992806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8124650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8286544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7336820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7178771.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16304256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8702994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5478226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8050594.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8423177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4676488.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5032561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7241294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6104932.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5613098.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4291386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6782003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5100685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9231664., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9103408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6094114.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4888869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7560485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2711164.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2969211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3752806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4293181.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8196039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2870461.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2754160.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6065597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2831694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7566737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4755437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3496971.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7476746.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15033790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8413236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4837644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21075142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10134698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11611654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4178916.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4137675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19213282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10888207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10150455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12808490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4704454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11465084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11103603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14007694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9911023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4761918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10842918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10563666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19859110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12393718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7250380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17790164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22197460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17313618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6547739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826793.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5658510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2557328.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4388375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3195875.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3169189.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4022860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4416627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3927918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10866290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8911927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5711775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11837334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6913286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10362232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9857300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9702018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10677430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10880986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9829725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13694779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8181978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11863397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10288881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9331538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12299454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11042204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11113596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13303923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14641775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8749067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5252992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4798173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10187165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12874865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9961375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11229316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12128685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17351014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7304932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8288425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4754989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2188411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15983477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1520897.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10451767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7038690.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7735969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10753704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6315882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13866623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6392104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17602990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7087164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2181844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3630918.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1815295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6625476.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13603549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4428943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5201192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2627375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3884799.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6291147.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2689767.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5510898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1222031.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3590520.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3348424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4998259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4307404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4275303.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5018714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8416673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4807843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6316722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14116632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8400168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9434751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12346388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20848698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19876626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14086941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5218730.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10878192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10337899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19150394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12814164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11234109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7974272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10280643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11551945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4163982.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10467926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11264690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5114913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12740583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2928779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2550500.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16304446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6864438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4525427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13324405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998249.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3482904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8273587.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3052283.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4373847.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2697254.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3966293.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6120072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6328769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2109921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9939027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12922242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8769519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832403.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14268024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5600650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15053773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4122607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12016206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9989383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8075341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9773713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9197147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12270476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9201593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18326496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11451731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11994241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12635759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5633241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20795342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13424100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11460951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16113850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7865564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6740470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8639749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7871394.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12105110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8938744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7019918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6189277.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5604604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8871389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8140600.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9542665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13462222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6404391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3545786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7453872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435953.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2577288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6949424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2642978.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11454343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1578341.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2906103.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13874184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6498892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10832119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3931657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1142841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5575700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6267077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3556902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1786889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4724594.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1934696.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6187148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4290288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2364386.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4410625.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5320351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1853226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4315724.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6729046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4016467.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11425641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1083311.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12006640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20872142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7363614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9867599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12851343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10427092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7865121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10032331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10775573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13763340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9031945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13412928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10282603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8793925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12479916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11128770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14006893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8678542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12653275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5939103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8423895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4004222.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10771869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10871282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9288610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6200608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826990.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9287531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2852257.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2499627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2590509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3003524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11305858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2903365.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5672470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8917977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8369094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14462968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15411471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9153336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9713398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12408803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11508674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3487472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10649718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9660846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13327802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8188223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7714260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8876588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11475526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14942008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11338502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8555035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13303740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14962582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6978654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15468789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11311902., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11736384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8645644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22760168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16701984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10367251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6748282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4874332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5141644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13111406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6651750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2585688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159609.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6301926.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8180208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2469431.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3355464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11348534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1632727.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8812199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5580898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4876561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6611905.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3784182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20084936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4913714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8293031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2504325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2597668.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5531278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9785480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3312818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3827406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2051097.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4845091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1676882.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2469883.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3918290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4443115.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6470222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5634150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5845934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13765893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7586496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14593860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3408314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18455674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11210876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10645559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1930854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11828125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8997071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11786737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12037933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9906023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19753486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11032458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12963867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12079791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12795972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7198494.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13468051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10631209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12409128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8976745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4697470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3994688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8009815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6291523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11494383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7676166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3793978.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5762915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464107.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4839766.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3985288.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7140246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3410121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4639561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5727851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3118173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20799802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9980707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11394825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11272445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8606211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10533220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10826124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9316274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13891160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13450363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8948385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17242642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10281455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13564720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8589995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12257104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10483934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9404852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10378538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11704588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10860143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7647135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3131858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7098116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18579098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14036482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13121359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13039900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18923108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12477379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4632911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9454226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241240.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6568574.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8488177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10149565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6772897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9910578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4608962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9426710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8394734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6914030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6426703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13085598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6565462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10299238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6340268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4279312.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7710898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13716593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5934190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5331406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4599714.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2473690.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4345900.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4790938.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1943289.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4937861.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3717489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2373172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1964104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4282797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3951763.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826489.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1322469.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4420976., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10977892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5896172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3920278.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4599944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6864396.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18586660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9115035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10645785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20217822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11034276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12906485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5301030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267581.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14477750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19994616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9757925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21019038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10334846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11267751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13544753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9410660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9935996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9758702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6200986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9739008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10029064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11733703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13370648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12508763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12781877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5590282.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5346703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3820321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7468030.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2949598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3380502.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4218720.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3803366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4482806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3197181.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8250990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8701741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14050798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6284522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9911501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9759493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9197085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10377818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11676774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9281693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12852052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7617136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13062492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10299948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8764218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12634019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16204626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11405778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11282784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10593284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12494953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10103228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6914023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13723274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2961403.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16071196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5250395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14957272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18934756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10086637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7407882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5124162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11781631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5466508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7291513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18300880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6999470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6385707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12858781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22177334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8945365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(965688.3125, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10018955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5899287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5754441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3629176.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4308105.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5253935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6843160.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5050071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9612019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4399902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3834291.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4944928.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4367899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5140311.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1755527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4402842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2930293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3819390.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4657115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3297573.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7250653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1201048.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4555185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8156915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7157601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4078898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6096883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2005990.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10641788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8352218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10328013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19931612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4510172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12258600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16570613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8808726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2452298.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19366104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15899182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13411848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8382136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10999175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9634999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17937420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10682738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9760183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10081760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13495905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19461430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4600170.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10301782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7511627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10686478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16596964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3696924.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987453.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3169607.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6128488.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4198023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3982610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2927686.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3093833.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3424173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4794216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10747658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9500027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10787510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10762700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6878030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8447332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9867692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17503818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11127478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6839129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7513561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12541266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9093009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9801959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10428018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7852031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10534977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13360463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11413207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10869690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12426315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10204700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9434019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14223208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11226981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7846234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16077799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6737343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20838936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14742307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23823788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8059692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1870964.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5550892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8574286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8209352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3845772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11123598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2906871.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6274519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6936295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2377443.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7059462.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5166442.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6729412.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6676686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9432198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7061047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6686483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7142278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9040093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1543759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1604842.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1415140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5142703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6278060.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(901543.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5888788.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2952442.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(942617.3125, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3576075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6933484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3675321.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4123650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4812842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3159152.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2864892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6991777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6909206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11301971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10857883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10700734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9683143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10542203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11805354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11711636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13740621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12934959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4734122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17339734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11192495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14382682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11849686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13456540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10177460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19375078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18239200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9766934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9433228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4100818.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9671415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9908413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12306310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5744446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6250362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2835376.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3623531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3093105.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4215102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3888287.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1606266.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3875825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4974425.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6491202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9611514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8927023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8279921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13254746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10250613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9302474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13522068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8828508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10978196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11758685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9668896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13409230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8944177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11639556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12135139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7866670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13308580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10554493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14133039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11921685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5769277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12851114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3408640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1954648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14192978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10888511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6178400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13163237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16563980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10751872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8715717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7620783.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7511317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7348521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9784919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4884321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6448718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2776872., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7404540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9031599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6018282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7062823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6556561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10826452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21692850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7530474.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7927839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3745133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15878701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8543854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3245409.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3201216.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053731.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1057808.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5203483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5428588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5922916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2159280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3825703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3747263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3569022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3392608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1085437.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3325331.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1168284.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3509010.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11572909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5070746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7278903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5616501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6788363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13269480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10314236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11221631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13825736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10998707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12219078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10424305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10469762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4872096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9726952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10697906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3309349.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12767498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10496132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6915409.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7278529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13044986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5896170.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12821876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8982227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10031576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9291933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9258358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3665280.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13845654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10791443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3850521.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772270.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2816044.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3204215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3492837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2631423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4706703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3656152.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9216823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3248815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10438782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7995015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9438077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10178588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8857539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6451784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12530551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7618882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6891268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12856078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9727970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12697505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3827034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1986690.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14866260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8775655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10916015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13010563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9986533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11824375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10969708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12796548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10398844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16940518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11658319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2487123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22756396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13873375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13167107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31064606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7345891.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7310712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6876574.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(737001.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7074943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2148061.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2510263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4116000.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8328693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9039366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6220123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5863494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5961141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3906328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8530560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14399785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1641959.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4579513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7817753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14410119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4684013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4007026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9560548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8354343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3745999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4825417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16234382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1555561.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5994317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4401907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(704104.0625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4317116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(841953.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2476285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6801848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8896223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8669210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3193967.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5697033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6725017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11799523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14349432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8197406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4795256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9649334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19468848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11938723., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3625628.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17422142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15342350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10408436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6357128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10494178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8275811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15117442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11968468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13630137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10545704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14425265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9794632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18736252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10584756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8835479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11267853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10434088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10006752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7312116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2877837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3801132.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3861885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2532118.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2821627.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4127550.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3679134.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3886955.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2878877.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7483260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4981689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9174211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7407649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18159588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11826948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8689576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12395702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9764328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11578750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12148136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13958856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11416530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8054969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9998528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8874049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8370071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9981300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11902202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14138165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11486791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24413590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8707813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14192014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14642989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9513680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4602045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13345378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11957311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9090212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20664620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1416328.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7668286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8607915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13239573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3112370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4783500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8010268.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9510319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104164.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8796077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3887836.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7082513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2540933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2625832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6420103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7991350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9938230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4711112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8378423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5364748.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9959755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5227244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3683890.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6047519.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1409643.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4339425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5837614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13023432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3101248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2931437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5072116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7623336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953821.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3607698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3869755.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064709.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5397084.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4445597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6029238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5184771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7169228.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11163775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6334146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10939332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10277064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4585504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8928313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11530239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9323845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9751125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20212978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13404883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10200413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6075437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6036726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13090360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7078370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9656402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7014633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12827349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10244074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15642223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9458323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18568124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9767896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13653633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9460679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10040109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1029549.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2941218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3363472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3630543.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3279306.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3235272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3106645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5268896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4303889.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5349656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11366413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7131905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7491242.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7817691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11218139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5022751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15091091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9465120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10871911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7815928.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1616601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11691837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7306133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11278246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10127984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9705581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13374430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12265447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14845016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6706012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8213176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12399974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13674108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11335604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11120900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14673091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13759677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14003256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12964308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25902700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7695444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6702329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6428436.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5729846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2096976.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7151552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8499261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14799283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3338268.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5578470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5818592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5872373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4314130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2281349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6064609.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2890583.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13016589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6749841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5036927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2639931.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2389102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3326849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9106420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16140539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6465834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3495816.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6566358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(525451.5625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4298022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822254.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4918726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12252336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7555833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4045389.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8561308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3925562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2724694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313083.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8715986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6402810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14072914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16900346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10643224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8310915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11325895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12058471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2563712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6300328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14468616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5021921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20047410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5918813.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8323874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18857284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13320537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9259688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13416537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7663992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19925298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17137948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9103661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10836877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8792035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7159706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6102911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10492389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13590877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2587095.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3027741.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3178440.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3915512.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3882101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1493124.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3368427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4848976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9602151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8423696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5960682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10902700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9816551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9049761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10961606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15724040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16922436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10846103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11583666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11922953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12026338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9710467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13130966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9576405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8180384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11169605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11681536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14145385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11411228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8104951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5430648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10867492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18656684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12082596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16099392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3234133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15346599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9157693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15955657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7262656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7266763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9802598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3895351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14826040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6021366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5186228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8316761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6855754.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2631159.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4296638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7846511.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6185089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2309131.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7088835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5666089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5258590.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9346422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3943556.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3476129.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3693772.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4227156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6470776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3789155.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5317535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4892931.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2636627.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3047817.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2227872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2179365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4706681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3607257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4919438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7475704.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3901193.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5820379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8333968.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13375511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8665665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10606461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8617600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1453744.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10612416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24371092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10042294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11302167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17895554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9232406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14837122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15346461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13349158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10561955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9493951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9630069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7627227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9844108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6938302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7920068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9693326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2589999.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9498443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19198064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6786872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3440785.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1941058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6184556.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3243263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3852016.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5365369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3869471.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3760343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9122012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14768577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8361914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7720382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10101226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2548980.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8179610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17856384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7149291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10179158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7610292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8911822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15216491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7527659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9128136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11125950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9322855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10101166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11141644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10490044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8496711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(31493238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5219000.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14246460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12745126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19944486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14632965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13899772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9258869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23470424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7930802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2557776.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5181037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13117305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2039751.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4618537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6901016.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7088267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6317005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8349333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5566902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5584718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11376163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7026644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978169.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11177615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5382233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5968880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6742830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11760860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4623758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5854478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4324163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5102078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5423871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2001194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7556564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12492772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3403899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2069755.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2337354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7445459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3196001.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8024364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3751477.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3323232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5331648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7387022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2257097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14399778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13105482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10957635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13642116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13445713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10751015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14164357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8166910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10815538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13100376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10804080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8566795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8765839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11489473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10587165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5927354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11821544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11096425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22340008., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7032039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9431380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14842591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10626895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11675008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9535336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18588722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5880973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3956900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3897090.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2749779.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2686554.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6713883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3736859.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3469311.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3745644.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1783267.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2882443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7820916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3396677.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8824232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20218500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8035624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7549049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11836959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8732192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6825939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12036283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9338627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4439163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8011176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12736635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8239478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11056142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12048108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3472429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10116915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12787167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12439754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12721500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11020278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6222016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12375707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5697738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17595324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13125341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11076490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14622818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5002803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9763805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6839465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4011150.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16075299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9630993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9282486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8835901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13783558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19143504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6121719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2148102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2093085.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7175944.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5882286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7860542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5949775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7245926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7088774.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7123241.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2891030.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3305189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2940263.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4372114.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4127750.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8612949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4040760.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6907008.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14036446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5630053.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3511079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295769.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6213240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6330155.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4858334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2603481.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2526385.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13852388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461289.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5916864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1933131.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14285931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8451594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10368371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10885151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11776722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11739214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20133734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8874700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13881087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11044855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9072181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14484201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13352130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10247462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9617185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9945325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13618204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7706745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4096964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1925869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14173880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9975289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8193975.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10175122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6207716.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8708417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3580269.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2886694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4249690.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4051639.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3602405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2619000.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3118494.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3301824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3320535.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2933607.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12803291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5558337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11083324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6520816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8906351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8593304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9073559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11219264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16252241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9470702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10253439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3156158.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9971343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13774446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9601642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9508448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11158584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10733768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15327482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12594459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13854703., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3976068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6155735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13782338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14868336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2324102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12243273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14490677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18224296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17046948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8152486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2561398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24001184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7527573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7575067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12679099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4309285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4790788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23640968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6288463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2447960.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14610003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3690748.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13878076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4318293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10497691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12181116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4941714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10564766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1033855.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7732717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2736923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3886071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3821056.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10167696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2767190.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1640563.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8895876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4739023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4674026.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842824.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3864279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4740388.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2273108.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8570243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4471657.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5584959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2645687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10908304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6268592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11745817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8421000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10098191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8859704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17684952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12677416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8098845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12051971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10852182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6248558.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8063869.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10002168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11769791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3205213.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13884225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19591026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18451776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9130496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9174413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8733149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10398012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12266932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9960597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6641125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13059901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4526696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2788524.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222880.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3594527.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3290473.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400104.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6369364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3661414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2742790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2814111.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12105488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4823277.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14169447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8966115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8566694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8233480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10185530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15494686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11577926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11809727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9676801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8963378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8730985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11825707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17638402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10138980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12236919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10660130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12196164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13758706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10708790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7804392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9481622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14320879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15467795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10189578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8673993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8167813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11241003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20322188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6794253.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4121542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9405359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2553915.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8740866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5774497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5902181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13702832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7359203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14675202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5703331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6139448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6947439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1856323.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12003029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7497398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9823331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5725319.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9087431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8699884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6668315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4175968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1242583.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14515806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971895.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6592980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3996208.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4288755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1930169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5180097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1730130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6081768., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2873509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4348847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3970289.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8411940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4558153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5531495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5334756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10422657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9633239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12181911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6310274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21090994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11322141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11304931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14636989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15431020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15241499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19099632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10734756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9735319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12300030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9206483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11627605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22364968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12424887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11339711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11259324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10109834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13097397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9448278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10492084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10013646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17129108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8332563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7631347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4723669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400672.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2903260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6699100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4640676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2831666.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6037687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3135961.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4092080.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4180812.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3521017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9277196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9139835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7685814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10366070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8328370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8052773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9287839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9840156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18428888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14546793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11564421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9473935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8879668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9504502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12987031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8173639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12445717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11408157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16796746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11842497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2447178.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11901010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18455216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9738759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15824603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7822381.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10614327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19071826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10755589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8738237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6617362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2411063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2475507.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3580621.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7433862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6322489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9265308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7587251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21591706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6554269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6753379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10776390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6935085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7322676.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7703946.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6521532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4952457.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5403757.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10024505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2359259.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6643045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3857979.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6356236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6568424.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2590963.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3805203.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1072043.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2593527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5603411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2336113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4405279.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2692943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3900350.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4325802.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4070613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4882829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3540354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4137569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7881065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10226429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4355742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4560269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4383549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9770904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10061189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23235710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8575712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9879654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2887454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13270535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10084488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11378889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4827058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8542914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9749654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9408518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19781492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14561643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14561396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8787024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13832550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17606566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8926444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10077755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11950309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15548319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3379580.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1631507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5920830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6754848., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3598634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4032921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5401882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6277612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4258271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8858586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9081415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8725205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7487278.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9687220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8611187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7678718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6332498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10645595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11305356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10934152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9517338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9541750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14648842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9980389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8908552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8384224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10543272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14760349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12316343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15876833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14044797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15947928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9535063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4795325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13658850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1934569.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12377329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7890144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4946641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17768708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4352378.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7871854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4765768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7478097.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7051926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8079411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8260326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14835533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9347108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10445836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8930555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9257415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14720152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6715633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2039821.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4642814.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9940372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4975211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9672179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6942186.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3778830.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3937000.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1913842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4036810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2476166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3450257.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2353588.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5296928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5012718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9567219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4494685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7511017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7971717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(729430.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4254853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8027180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4340133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4977737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5880977.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5765189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2686582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11266131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4140971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10753650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10722425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5143870.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9121617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7222909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7470677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4020114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14515364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15841428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4486078.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8489703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17806622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9837039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13399072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12475049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12647819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9930960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10349453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9899896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8667949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9587024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10367635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7416849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3291807.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3943611.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4732411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3146768.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3561945.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3883281.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2743399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2181536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2846437.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3534424.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9780742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12986003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7786733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11478598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8152289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7790082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13190128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12289565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11725182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12961833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8848160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10664785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6748520.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8781477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14830819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10747204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9609978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8826788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11078876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14510117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9917710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10185934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8827652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10837856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27654928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15516190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7730483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12477131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13939368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16884074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3677631.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7538376.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6759001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11088225., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1666728.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9687241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1349590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3635885.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2395381.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8973588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10491980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5694600.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029151.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6613913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1508950.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6781548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5659469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12456311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2372994.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7081093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10503703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3078968.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1702298.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3624489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6340605.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3015115.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2831397.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4362033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9373034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3231264.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7460003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1206679.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3724777.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6074588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7302631.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7621370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4795093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1578798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5773427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9579091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8916576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7303494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11131568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19138874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13828172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3993352.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6867558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5788366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7265300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12643341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10024479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11330467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8912189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11292145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10225704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1966381.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10838186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13267612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11562661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18603972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12294144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10664782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13325729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9394077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10510436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19854326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7610128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2668255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1581588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2612966.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5040972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3530395.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3473652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3973402.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11456994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6218759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14311608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8397323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8692145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8731325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11013815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5667859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10670913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12638127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17449526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8495140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8996324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9235757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9840972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12413652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12653188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11197427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10861379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11569088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10023499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8908535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16412922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(29131718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21496800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13947387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13919304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13968727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14905985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11143227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18309750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5330587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10722070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6036268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6169883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20965192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6625643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4086497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6318531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2512825.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7672540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6123689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5288601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8483485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4439652.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3947244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6411624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2013875.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7294273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5263737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7078092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1355248.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3606669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3863596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2263462.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6119176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4078337.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2468844.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5145825.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4371931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5312118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3337359.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6883637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7315346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3991896.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3900055.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4666741.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5199018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4843837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4787079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3789090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1017638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8557673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11280298., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4831310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11702584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18853576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7897597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4547392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3545413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9755816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14647957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6451711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17102504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8730485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11636484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7211026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18993022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6828888.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13233300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3835175.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8272253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7733497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10002914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9557419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10323792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11198597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19231954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1126890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3049913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2858754.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3652390.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4000614.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2514522.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3265986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3049714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4327002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16010410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7578508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7041504.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13972126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9585642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9816009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12594620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9353669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9819035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11784548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14357344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8986239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15819305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12164790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2121587.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9827189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9272174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13505862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13479613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12809550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10060682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12513710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17161144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11501551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2438051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4637124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14625879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11213905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15360117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2251279.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10686316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8192136.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1722689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13996978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9264364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5649915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2970246.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5396241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9468986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7482293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6107384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8524898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7750613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6888083.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14084234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6915667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5631222.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7276735.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4107940.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7378368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1151718.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4440425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3158309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2765057.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3030866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3118812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4401021.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6034430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2150877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6702976.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2884256.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4475391.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4101001.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4922735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4194810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5000517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2653655.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5373052.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10437384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15036375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10542229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9515375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9048514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14321994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14663524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8769395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1778500.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12456345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10066069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13583455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5620437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14371073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12351209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4017553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16955698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11465358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19644372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11465620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3892687.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11150229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13039756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4053227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4534040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13800398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17721658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3840107.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1552168.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2823061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2977814.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6986818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1443939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3127023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3676128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6251032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3763660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2448348.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8458158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8033963.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9996492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8512980., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12884628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11517617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11799315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11493150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8091741.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18292844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9088906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10115450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9207993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11968707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10860185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11445102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14472913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13424091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9338735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10243457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16425912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10334556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6281905.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13457516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6139768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11464746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19498956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8158333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4326694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5146767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6600184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10689892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2200898.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6347402.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3718798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8779706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5633804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2530642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5555226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13147968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7361944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5512789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6708161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8869857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9472979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4505394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2148233.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5982930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10554532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5491618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5204112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6327570.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1111166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6716535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14391077., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# transform_1 = transforms.Compose([transforms.Resize([512,512]),transforms.ToTensor()\"\"\",transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\"\"\"]) \n",
    "\n",
    "transform_1 = transforms.Compose([transforms.Resize([512,512]),\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "\n",
    "reg_net=regNet_2D()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(reg_net.parameters(), lr=1e-4)\n",
    "loss = nn.MSELoss()# MSELoss可换为\n",
    "for epoch in range(1000):\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs = data\n",
    "        # source_image = plt.imread(inputs[0])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        source_image = Image.open(inputs[0]).convert('RGB')\n",
    "        # image = transform_1(source_image).unsqueeze(0)\n",
    "        # width, height = source_image.size\n",
    "        source_image1 = transform_1(source_image)\n",
    "        # image_tensor = source_image1.to(device, torch.float)\n",
    "        # source_image1 = torch.from_numpy(source_image).float()\n",
    "        # source_image1 = source_image1.type(torch.FloatTensor)\n",
    "        image_tensor= source_image1.unsqueeze(0)\n",
    "        \n",
    "        image_tensor = Variable(image_tensor)\n",
    "        \n",
    "        \n",
    "        \n",
    "        target_image = Image.open(target_image_array[i]).convert('RGB')\n",
    "        # image = transform_1(target_image).unsqueeze(0)\n",
    "        target_image1 = transform_1(target_image)\n",
    "        target_image_tensor= target_image1.unsqueeze(0)\n",
    "        target_image_tensor = Variable(target_image_tensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        x_1,x_2,y_1,y_2 = reg_net(image_tensor,target_image_tensor)\n",
    "        # plt.imshow(image)\n",
    "        # plt.imshow(target_image)\n",
    "        source_image_landmark = source_image_landmarks[i]\n",
    "        current = pd.read_csv(source_image_landmark)\n",
    "        X = current['X']\n",
    "        Y = current['Y']\n",
    "        # X = X.transpose()\n",
    "        X = torch.FloatTensor(X[:70])\n",
    "        X = X.unsqueeze(0)\n",
    "        \n",
    "        Y = torch.FloatTensor(Y[:70])\n",
    "        Y = Y.unsqueeze(0)\n",
    "        loss_1 = loss(x_1, X)\n",
    "        loss_2 = loss(x_2, Y)\n",
    "        \n",
    "        ######\n",
    "        target_image_landmark = target_image_landmarks[i]\n",
    "        current = pd.read_csv(target_image_landmark)\n",
    "        X = current['X']\n",
    "        Y = current['Y']\n",
    "        \n",
    "        X = torch.FloatTensor(X[:70])\n",
    "        X = X.unsqueeze(0)\n",
    "        \n",
    "        Y = torch.FloatTensor(Y[:70])\n",
    "        Y = Y.unsqueeze(0)\n",
    "        \n",
    "        loss_3 = loss(y_1, X)\n",
    "        loss_4 = loss(y_2, Y)\n",
    "        \n",
    "        \n",
    "        loss_all = loss_1+loss_2+loss_3+loss_4\n",
    "        loss_all.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        print(\"The loss is \",loss_all)\n",
    "        \n",
    "    \n",
    "print(x_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(reg_net.state_dict(), 'own_model/the_second_time.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try not to resize the image, because it will make the generate point unaccurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1134.2659 1186.49   1179.3153 1403.1086 1232.6267 1240.4095 1468.4692\n",
      " 1626.2773 1862.6123 2040.5278 2187.1963 2257.1946 2471.5688 2425.101\n",
      " 2297.1738 2365.9883 2337.297  2564.627  2225.9385 2480.4785 2675.8235\n",
      " 2597.0254 2667.5862 2396.2942 2352.0361 2478.2612 2589.7754 3094.5645\n",
      " 2950.181  3170.504  3100.8677 3236.8384 3308.0037 2997.2463 3163.3086\n",
      " 3101.289  3116.9722 3026.0828 2685.1282 2824.912  3087.8765 3057.0044\n",
      " 3207.4436 3764.5498 3750.8472 4088.746  4129.185  4347.517  3996.0928\n",
      " 3890.2974 3962.9146 3970.9224 3412.7688 3552.6074 3988.1704 3830.9238\n",
      " 4208.3545 4557.8853 4424.1475 4630.445  4504.8076 4450.7275 4811.3228\n",
      " 4583.5933 4514.804  4415.1387 4794.7896 4663.634  4798.3467 4812.2617]\n",
      "[ 605.31195  721.97595  698.0919   840.7353   820.3527   922.2014\n",
      "  799.8411   914.784    971.7434   983.1253  1126.0927  1057.1976\n",
      " 1095.0386   823.45184 1133.3922  1163.753   1340.2828  1348.3396\n",
      " 1351.6841  1455.4174  1724.4346  1853.5126  1858.0126  1809.2465\n",
      " 1653.5288  1454.7227  1681.9807  1577.4218  1591.305   1762.1267\n",
      " 1984.6918  1456.4647  1538.3143  1367.4575  1821.6245  2063.8352\n",
      " 2113.4895  2142.8542  1801.4102  1839.6548  1899.5436  2066.895\n",
      " 2025.0336  1853.3691  2161.7893  2590.363   2669.9854  2675.8726\n",
      " 2380.1978  2209.6602  2191.433   2377.561   2636.7012  2526.6113\n",
      " 2411.0012  2588.9858  2815.5464  2477.0222  2190.8508  2423.9448\n",
      " 2064.1487  2192.2405  2155.5505  2423.8662  2656.3774  2656.895\n",
      " 2370.7322  2346.7942  2609.1936  2646.3184 ]\n",
      "[ 558.6817   731.79016  777.7138   811.4948   860.16876  925.8938\n",
      "  800.67267 1095.0167  1054.6288  1056.9457  1212.0391   961.84174\n",
      " 1196.8823   756.18317 1146.3925   943.29297 1064.6588  1211.7\n",
      " 1395.4312  1584.1371  1869.3495  1849.295   1878.6278  2034.7499\n",
      " 1986.86    1680.0774  1915.0928  1447.6787  1479.0557  1651.6969\n",
      " 1748.1619  1414.0247  1461.3789  1570.0542  1786.4022  2244.4905\n",
      " 2085.5056  2231.0127  2184.8206  1651.6671  1871.1609  1952.7072\n",
      " 2052.985   1832.8713  2262.0212  2524.3013  2622.6655  2744.1616\n",
      " 2518.0244  2360.1624  2327.7314  2408.642   2733.535   2564.0244\n",
      " 2348.9814  2481.6726  2832.9136  2798.2507  2246.556   2176.2546\n",
      " 1925.2682  2337.7944  2172.0637  2480.8743  2425.33    2469.0527\n",
      " 2302.0078  2431.302   2535.5803  2544.012  ]\n",
      "[1090.603  1298.7556 1127.47   1439.3756 1271.4412 1447.866  1620.6713\n",
      " 1774.1244 2148.2983 2401.4216 2419.868  2421.3381 2732.8044 2664.6694\n",
      " 2770.8215 3036.0264 2944.2534 3096.8103 2718.2874 2953.2888 3016.7715\n",
      " 2991.0813 2762.7925 2468.6794 2409.9475 2595.6003 2530.6362 3161.8716\n",
      " 3188.374  3183.313  3263.0315 3369.29   3427.5864 3173.8186 3021.7595\n",
      " 3147.498  3168.8413 3246.7344 2727.6353 3227.057  3472.7734 3283.206\n",
      " 3695.3267 4045.7214 4058.434  4517.123  4495.6514 4715.456  4396.144\n",
      " 4463.551  4569.087  4134.299  3885.6265 3985.3313 3955.895  3773.0713\n",
      " 4671.607  4914.495  4713.7686 4800.882  4629.8887 4617.532  4886.1807\n",
      " 4855.8735 4777.917  4843.461  4973.9673 5189.7344 5252.776  5028.735 ]\n"
     ]
    }
   ],
   "source": [
    "x_1_tocsv = x_1.detach().numpy()\n",
    "x_1_tocsv = x_1_tocsv[0]\n",
    "print(x_1_tocsv)\n",
    "\n",
    "x_2_tocsv = x_2.detach().numpy()\n",
    "x_2_tocsv = x_2_tocsv[0]\n",
    "print(x_2_tocsv)\n",
    "\n",
    "y_2_tocsv = y_2.detach().numpy()\n",
    "y_2_tocsv = y_2_tocsv[0]\n",
    "print(y_2_tocsv)\n",
    "\n",
    "y_1_tocsv = y_1.detach().numpy()\n",
    "y_1_tocsv = y_1_tocsv[0]\n",
    "print(y_1_tocsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(data={\"X\": x_1_tocsv.astype(int), \"Y\": x_2_tocsv.astype(int)})\n",
    "df.to_csv('result/testOutput.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "len1 = len(source_image_array)\n",
    "print(len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACMCAYAAAB1cn5wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvWmwJcl1mPedzFru9vZeZrp7pmefAQYz2AYLAXETCIi0zKAoMmQz+F+//FO2bMmyRFmUzHCEHQ7ZEQ6FFeGwyBADskUESBASSRAgsWMG6+zT3dPd0+vrfv22u9aSmf5RlXXz1ns9GPDHCMs7Ed3vbpV18uTJs+cpcc5xBEdwBEdwBD95oP5TI3AER3AER3AE/2ngSAEcwREcwRH8hMKRAjiCIziCI/gJhSMFcARHcARH8BMKRwrgCI7gCI7gJxSOFMARHMERHMFPKLztCkBEflFEXhWR8yLy377d9z+CIziCIziCCuTtPAcgIhp4Dfg4cBV4FvgN59xLbxsSR3AER3AERwC8/R7AB4HzzrnXnXM58PvAr7zNOBzBERzBERwBEL3N9zsNXAneXwU+FP5ARP4u8HcB+v3++5944nEAQj9F6r+u9b79u/bvQ3grfo9z1cX+eqn/d29ytbzp2ILU37q39PvDcRI5SIO3Au17fT+6vdm17e8q3Grkvu84B0drX/Vm+IRzD0f6fuv8Zr+9G12MsWit7spXd+PLu1Hhr8KfIX0loG84/7/KHgDYH01YHvTuupfejGfeyr1+kDW6277+QeZz2P0OWw9X/2tbwHf7bTjWD4LLYfBW5nW3tX6zccPrv/nNb205546/yU+Bt18BfF9Z7Jz7V8C/Anjmmfe7L375i3TiCk0nYOuQlRVQDkSE0lkiqZbS4PBhLYtDHKSiccGdp5OMtJs0BPZfFc5SsUQ1XmEdrr5RpDXaWY8jiDT3EREM89cYi4jGBve0zqHEETvBSfU76xw4h1IxhStQNSVEpJmf/1vWcwUw1pKqRVLaAJc2Xn7u4gAUzhkmkxnLve4Ck9kgHBji7pxDKYVYh5WKrgrd4J/WY/j7ODdXka7GU7tqoQ0VY2sHpVeGzhEhKFrj+LGUNLQJ5+Zp45zDIEhIXzcfJ1wr5xxKBBNcq0Qoa7z87/w4DQ04CMpBrioe08x5wENkASU13Q/StUaoEkQizdWGih7WVfSO3Zwufl6HCTob0MrV1/o5aQeKimbhdVZo1tXfM+SJ0tma/ywooYMO8DCAPkAbj4u/v3Is0EYTrGew1uH1rqaNdQ60atYlpHNI33Acg0MHosavcTjn8Ls4WOg2fd5sTn6tgIa+7Tn5ddAs7svw/h4fiyN1qqGvHytcEz+X8LMQNy8TI5Ve5i3A2x0CugrcF7w/A1x/swvSSC+8F5FmATwBYqlIL1SEjkShlEKLQvTiFMVBt5cuCAS/2EoplKqVilRCDzUXDP6a0pgGF2BB+IutrrNigeqfiKtZQzU4OFd9JiIYW6DrzemZwTOYajjRYus7KbU4JyWqoUvDoDVuGiFyoRCqlFOv32/mH9I2/NtcL5XwF5FAUFuUOESpBUHZvt45Vymymn7K1QLH31cEx6KF7XH19FHBl6qZm2oESzVnhwvp64VUa45eEHgBYWthGklUGQyBMvPrZKxt+KvBsf5N7KQZKxRqi0p3/nlo4ZXiFtbKjwtQiMOoSijUVyzSuP7EyiJe2uNQK14/JxGpXgfXN/eyScV/tVBZGA/BKUFr3fBdsz5ON3OxtuLO0IhRjoX3DW2C9WiEIlCKa9YjFwERtFIL629wWKq1VkiAy5xCKuQfWKRvvZdtPU7Iq/5acQfXmnqcCGlobP06izS8EtLH3y8W3Rg+7fv5/S4yN4DaCk1EsNZSOtvw2mGGm4hgVEXHtwpvtwJ4FnhURB4UkQT4L4FPv9kFikWChYuqWgsVWlAANpBM4hYJG+nKq/DM4QBt1cIiOrHNPb1LJg7iKJrjUuMR1VaNkkpy+IXyDF8tkp0L2ZZQ88qrLfC84hERcArBVv/cfAzr5ni2N0u42fzGQeaCIGQ6Px9chX+EHNhEkzxrmN46aXAJaQxzAeutPZFKUKp6E3g6WFcpEn9hm3eb+3v8nLd+7cLcjHELuLSvb8ZwwXoGeJaVD4HYau7NnGohFK6Fat3DOYcLlW99/YIiPERJesvTWDv/nb8nCdpWyt3P5LC5xag5TVqCCBb3j27th+oz6Kii4d1QeBrcAa/mgEKrr9NKER3GSws0YoFXPH7+dewq4aotJAGdQ4tdRMimMxB7wLtSwX0bRRcK4wqRBdo45w7QtVHe/prwOyqBW4prrlXWgZK7yiqsbfaSxxNgPJs2c2qHT9t4a6WIa1444J14mWId2lb0e6vwtioA51wJ/FfAfwReBj7pnHvxTa8JF78180Z7OsCpBQZQDrSzaBuModSC0LSNn1WFNBDTCGEP1ea3KGcPMK9n9NC9rMbTjcDRthIyWlXr6zencQdXSag2pBWYlJV1pUQaay4OrIWQJosWy9xiimqBa+qIp0JQ4nCuCpe0N3PolTQeUjgt5+gmaXO/6BALKhzPb8RwDb0nUK1d5aW54Ee25sjwvtbN3eRKiCiMhHRQxHXow1vMthaq7Tn6sb0FHUyusexCodfQtxboSuYhpupf7X1Z21i8pXENvQDKsjxgofr7i4NIKg/Ih/yqz4sq7MZBvp/zn8JZ23gWAgshCie10vdrGeBtA/o5md+3CUfURoCqLXDlaoEZ7DkVsLBXYn4sPI3rtXNSC/vQE6h/VwQTnNgEq8wC30RIEDZSDLq9RtGF4zTrFbxuh9z8nbRd9Nia78PXqEbIh/tMpPKqvfFgFGBd69qD9/Vr7Ner3+lC/ZlGFpSTh0Yhu8M/b8LdMl/TA2HGN4G3/RyAc+6PnXOPOeceds799g9yralj+p4Wfp5WALENEzeWmlK40Erwm8VbHzUDV+6xaRzkxoJyPjShDoRd/GYzsvhZY51ycDGcCywvUQcWFebf96NqExhZ9GycVMpjIa7sY+n1u/nrOryBNLxVWRp2IckUCjhv4YRuc0PvIKfgN/bXv/LKgTm018evicE1Cq1iYFvnE2rPIKCPCl97RRLQNwTl6rVX0oThtLeWvNAPhSDV2jdrWIcu/GvvAYRx2GYeBEaEVF6iVMSZX68WhWvkPUbRC+vlhZzHyeAQ63C2mk/pbBACOgjeQ23T3FvuUY34YV6nF87h+xA87zZbRwIPys3x9rTRwf44YDXXQtRShYq8p+L3n/ccHNBTOaCb96FHU+Fgm3CKBz9OWxmEITepNuRCmMrv3XCt/XvPZ1IrfK/Ewr3o94JCQC3SuBHQLTzauQrlAFFVjoVDeG7B8JmP5T+3IW5yMP/x/eCH/iSw2PnKeKHUFk7Kzf/6hIsEi9223BuLqQlDVF94y085MKJQ4tDONhZxm1F86AcCRgv+CvOklXPzhZFDcGovfHgPobISqxj8IWExLzyZM4cXmJ42YUimEfbOLdA3xDvESbXnXCN56fyUD33kiUPp0ga/Ji74XkSjauvOtqyfMIF7GG6Rnd/LWz5iXbPR2xtaB3kQcZXVJm5xDasEW3IQ+eD+ytkFod22DD1OYciw+WdNg8vWTpVHcsEYfh6xqMYq9O58mz/aIU0JfuOtZecqJRDmrxbm4w7yUhgC0q5O3geJ5bvSxt3ltcytd3HzZOibWe4hvWEu4H2eDOZy4TDvSLVpVn/nlY9SqilEuJsHezdcQkHuPQGxDoJ9FPJZGE5s5lnznQ+NGmeqvKVb/I1/7WVPuPZ+SE9bbat9+f3WqQ0/9AqgHRdzwiKxmRNmZsvKBRe3oOnDa8MN6RnFxz5jN49XR94aU9JYWoeFo9qKQVxlWdg67u8Fv1JqoSLnsHhoyBxt8Imr0i5q+ANCJvzH3Kr1YIONJ3WirS1UFoSlvz/zDeQV2gOPdBuXNqRtOFYjHAMF5edDHccvnV1QOgvjWFdZ6yF9CSonlDSb581c34XN07aifGWQBUN+wFoLBYo4wM7XvLHA6mvaQircuCEux1d1QxNvYXrhWDbW5TxB3ObddpK5scrre3i8Go+mFbpqIKCvNB9VODhY2EciAq1EcHtt2gI1XHPq8drLFNJX1XkP/9pJVWnlr/U5GB8WdVKFDQ+z4hucWDQSfALeVzj5cdrXhXNr1i7Eu8WL4TiNgrPzUGttHmAF8tq78AnbNu8u4BEYjgt0C947JQ0uP9QhoL8KtBe2caHDz4G0TuyGgjyMHYfXhIzjoXFrnUPVVS+OOl54iKUQumEh6JrpTB0K8GV4uhVDPcAsdwEfm46cNOWuDdTK0KrFcRrhFVgalbWgiFFE9qCAa+aj5haOB6Fy851z4BIiJQtWWCOAhAWXNMuKas0CWgt14rCmSUQrhxJOj6oapsHDzTdyRRMaoaBaawngjD0g+MKN3cRfgU5t0S3cy83n5GkThnf8GOFfH7N2rbBAc02rhNcx9/S8MRIhSFCh5q8Vd/D60LjxeHocNNKEew5THE4qgynkP1/tAvMS1GYv2YPG0ALf3cX6VDX/HQg7tvaBUeBa9/A4RPX1Klj/cC7NGC1J6ZgrIlXPI27tpQNrxDwf1ZYzYeloRJXMD/ORoXFnFRgpm+ttHTKMxTV5qipfubjfmvVU8/cwV4oqXEto9pJYt2A0fz/4kVAAbab1lQOHWZ1eo3qB3Q5xNItrW9UrQdjAJ3UNDh88D6sFJmiu3hK29hQ3tyKubsK3XtxcuI/HUUu0kCQOE2eHWSwheOulkLkLr3yCNkhoty3/A2MHyVJfPVOIO3D/tiWWm7raSAk7OzOg2qCRKsDJXCFQbdq2ByMO0jQ+gI+r/zUJ4VbOoU1Hz+zKuIb5UXNPxFt4C9UiHpeaTm3lGAqfQlyVa5FDEvoeD7+hSzP/zC56EsqpJm/Trp4J8VqwCt2iV1RIcB4hjNGHyoiDlStz763GMwj7mBZd2uDLhNvf+ZJLmAu+9jgHrNxDeNGv9/cTS+IOr2DxsW0/PyM0ub3DLP+w2gnmuQvv2XjPrI1PWym1xxVHk9vz83FU/ONzWOF1TiK++a0STXXe5vnnJ0GoTuN0h+ne3ONs8287SnCYp+29z2mRN3nPw5LJd4MfCQWwwGyHfA5zzRg7qTbmIdpUELIsAyAKknlVHO4g58VOGqsjhL4znDnhOLFkuXej5PRxS6/XYz+PFvCKEDCV9m9voBAvdQjTw5whmlrzuiZdiTSW2KF0atUjN9ZPnTz2FsNdlU7NaH/62c9V41nH+moHgNQIysBkPAYCRavmSVcni1b2grUY4iOBRRcqiEDhh1Z726Kuygal8oJ82WCNjwmSaocJCS9UoFonn1N4s60jbp7Qfe7Z7y1sUJ/UpqbtQhgvwLstYMK/CiGxtfeq1IG8iB+jCdkcgqyrcfHnJQRQ1h0Qig0ureIGv3Ywp29zpsQtrmXbIPPXH+aF+svulqC8m+D1c4280dfM59BhDlWMQFOA4CvjnPiDn4sQWtoHFUDEaDoDkyBS4uofaIRpljS/MzrCiMWUBc+8v8fFqyMuXAJiw//xv3yRP/7MJXAKcZbV5Q6mdAu5sTZNDuNh/73ntV6UVOvkXOO9vRV4W5vB/aDwzDPvd899/au1lSYkdanVxDh6eq5xx8T0KaoqAyVgIKppUCpFZA/Wh3sIN2Doxhph7j5TC6y7WCchCIKtretSKTJj6VfSriqtq8corUHr+SE3cTQVMW1LNYPq5G/tzYQVHnebC9BYkv59Zh2Jmp/MVCLzOTm3EFc9TFA5gUwciSvQ0gNTkitHYn18WWEQjN0l0iuIFOA0FUuWC2MX4hq3t5BqjPYahRbPwucoBIMBDELqwImidGWVLA9pcIhigWo9fOme90Bq/6gO2S3S97AQXdsqG4ujF3incDC8FgrK8HchHqHVZ9TdreLD5jYtHZ1YyB1VEUOdV1hY6wDC+HlbcJc4rBM6zntKQhx4wovW7iJNmkNWIrjKTZgn7FncS2G4wxty7bEdkFuhU3/oPY/w9O1BCzzAR+b7QQW/e7O95JWhqc6Dcv7SkAceXEOJYjS2LPVqngY2rzlcpDh1T461mlJSlK2MzVhpECgooXRoHeHEYNE450jqctO74YJWjYcNVYirKCGJZb6XalnleUir9JvOuWcODrYIP/QewDwOOOf2nq4+tKoS1gNXNAuqXZWnyvEWtJ3/Vg4PBcCiu+pPvDrnmJVFE6s7zLoJP6sslPkG0c4wQFWKyTkKv4AKtNaN0G9wCRKyDS6uqv+3tSC3QiWsQ8FxyNzE0SgMj0+nTuDmqk5uh+Oo+b395rRlwZ9/5lN88u//evXeCds3J0CCoQCVkGUxSEJWaMAiynDzjQ32R7r2JAxKKYpcuLVvKZzlyrUY7eB7395i6hzOVHjnfo6tmH8Y8hAHV2/lFLXCiQSmZYnFYAPh70N/h1ms4lg4gu/DPrZOfLa9Ry8kD3PBPb2cQN/V49TWZShU2zwDB2PMC4cHZV7MEH5m1cG4cDMngU5c4ZACiFRmUR0uCa87TMj6cfy/CCFlniNwUuVTjCzy32EGQ5O4tG4h7OhDOZ5n2/du07fBBxrh7+kbGkttOrQVpNS4hOERJyyeSpZFvKrPHMZW1v3DDy6xu6Uw5Q5f/uLlJowpYvn2976LcQpremglDO/cQVSHSASs4eaNfRwpe8Me2ARM1OQRSmsWyjkPrFPo7dfGSRrNeSV2VTucksOrvd4Mfug9gGe/8VVgvig+BOKxbicqHbUFH2yusP+OMQakElYwD7O0XVNrbVNXDvOQSbN5rcXWidCFmuRWaWl4jzDh2DBfLZR9ItRba8baKsbO3H32C+yTeyFd2qvox4EqZurx9IKvjYuILMSNAYZbM5aO9UDB5vWYe04axrml1zEYYl55+Q7HTi6TRB3ubOUYM+KJx9ZxbsJwLPT7EUrg4vkJK2t9VlY9kaqNeO3GHqdPdxGXEgsMJzH9LoyzGa+9qOktWx5+tLKAm7LVQ/7CvMdQ1LK4/WwWzj2E6+zmfWI8bXy4oT1OOIanb/sEZ4jbQj8a8cJifiLU37vJgdTJTSscuk4LrSqY87uv1PFjAQt08d+1LWrXmnu7vNrPJXeGSOnmlPQCXepEtVJqXmbp6dIay+MlLArnxjq3dkEBe2w8/4bzCukbCuySOjwk815R1Gs0mczo9zrk5Yybt1KW+wlLq0XDM1vbU9Y3uk3llHGaW1sZN6/lPP2eLnmZkk1nLA1idrZHDCcGIeWB+xP2dgUnEybjmDjqMlgxiMpJ4y6WPba3ElbXNYU1fPYPLvFrv/ZQs+c8nobKG4AqhKnq/e9aa4oYnFUH+keFXQSiHxcPwIOP/zWHlWSRGWC+GayAlKqRvGG9vyiFBJZEU6Ncj1Md8LDNCcjSVNn6ZmN5y0SpusZXNSeKnZKmfE6k6svhlKYis1qoHhE33wz+3EFYUqga4V+X49Xz9WWYHhpF2KJXE85hLkwWDo0ElSSuKBYO20RYSoTesS5WLCU5J+/JEG2JJWZWKKYzOPvQGrduZBxfsZw+VfLQo+vsjUBEM53uMp3EFEZx38MJ6xsRokru7I1BRuyNck7du4Y1XbZ3HKOpY//2Pt/6zi16kcLp22zeuo6zcYNXqMD8wa/qwBQ4VJMWaVz/u/CSq/95gRzyDcyb1C2sd8BHnqf8OB4/g2vK8dwhlTph25Hw3rB4FiXsLRUmBsOafS94mzLjuySvfTVS2xvxL8O95PFqlKaq+ZOqF41R4NVXQ5eaJ73w97iZes94Wlb0qWhjWszq916zvwPl4Zv2eTo0B7Ba4Uo/G41gVX2Kfm4lAtDrdSplG3W575TQX1lsJ7KxUZ3MjRAsCSjHoJdy7PgSm7cg0iWT6R57E1g/NmB5eZn1jT7DUcRgxWFEc/wejeqMsKVDlGVWWpwbsLrSxckMZ7q8+733YKQOsQk4V6+zmze99AcZpZnC/DxH04MpoGFzuO1Ns1gH4YdeASwIzeD9goUTWFVNqZmumrD549zNeOHYtqoHbqp+asb57vNbGIHCRWhtcKqDwTGaJVgSrCSUVmGl4HuvJojEzb2r7VIrIQfOGby3YXzTtnozjvYN++OiLms0i4fFgBKhkDmuPmQTnkpuJ1CFWrHVn52/Gi0ksv2hEYdqLH8VxX40IsCoLkocu7szNm9Oee3FIcNxwdQMGReG4dCxt5uztZnz6DsHGAp6KSTWsNLPef1cxNqxJbr9knyqGe1ETGcFs5HDlQ5xPdaWByhl0VoYrFiS1NJd7fD4O4+jNLzv3cf4mY+cZpYJkyJlexcuvj5vSAcwzVWVS8GB2EVLXKDKSMwtWV+D3vxreCjsTRR4V67Vvybknfqf5z0JWgFUJ8vn63UYNArDx+frcI0v17VS4TK/vuJlcaq5hx/Hz6X5W8/VYBlPqlU9LNzpSyI9hHvJW5OOmq+VUJ2Md03i2CtZh10Yyxsw4VxEhEhqL8aXLrNYZeQ9h/Dktw4UTdgV1rp5FVATz/eywZoD5w28cVcJ0vr7VijL4+HEMcsziiJiZ2/G0iDn+EnNrU3HvSdPsj7Q7O/PuH1nm7y0RD2LEsXFc1cpS8tSP6bbU2jR7O6NENHsTkDZZSQa8ejDa0Q1XY1VtZxKaHqPBXPyStHT18uqUObNOaS67gdRAj/0CuCwEJUintdNN0w431Q2iJnNK2IUX/9awa3NKp6npDqcFbmqqdln/8PrXLqY8corlkF6mi99+SbokhtbJSaHc+cs3Z7ljc0Rpc157huXMLbLu9+ZY0q4cbOkKHM0Gofm4oXqPj6Ol1vB2XKhQmewrFjuR42V6xM5QmX5REFSqAkj2UWrJexB0ihB7+oDj5yZ27OuTvRaUeDMoSdEZ0b4xnNvIC5lbS1hdaXPu55cZ3nQI5Z1Lr52nr39CRvHUzY2YiIlQAz0yGSCkYTTj04wps9wXLLUzyCJ6HYU3aUuayfSKr6N49LFgt39KYlOcM6x0s/ZuzMjyypbdyaK5569geSGtJtglebC1byy4hz0IlN3Xq0a+fkWEY1gqFsKRHW32DC0s0CvWig5qRKnXnmHpcHNZmReVuhp3Ai8YGwddCZteHHhnoIrDWU59y7bay1YxEbcvj1mnFdNAJ3MK7kARjtjEM2t7Ukzp8Kaei4JvX5Cli3OpZm/q+YS1X1xIuaJYj++94yiKrFyICZd1bBXc/XjeGHeBt/91ONy2AGnppySuVXrT6yHeRucWYj1X710eeHAWvtsyUKjuzrXpqw5gIMTB9aQxilYuP9UymC1Q4Ti5MmYW7fAsEdWKO5/oMferYx8ahGr+eD7H2eQCEUeIa5ga9exuprgnGFtBUQPuXYuwUjepCIi7dACuOLA2vjurd6IWazumSvOeQTENWv6VuGHXgF4CDcgUs6rc4KFbQ6+1Ez26guv8NnPnuML35jy+b98ng98UHPiZF5b145xMeTKjRmiNO/54ClW1vusr5U8/FjORz98ipiIkxsJoyHkVmGM5b6TKYnAh37qYcRZnCREuuDEyRRjq2qXoozQicFIQlR3qIylXLDcq5in4s6dlEjZAxumXeY2r15QBxb4gJCqBVR4wnbh9zIPMYDfRIrtK7fpaHj/e+5HiUUTobsak1uslFhK7n/kFGdOrlGWJZFOUCjOv6QYTyEbdXCM6NChnMFST7CS0utkTGZTlK0SyDtbKVu3hnz9a6+wupwiKEQlRJJw5h6N7kS8cT3h9hsR73rqFJ0lzSAZsX684NEzXSazZN77x1uEYhfoEiYSw15JPv7dpq0Xcu1DXv6190B96V8Txmutz/z+B3dhxbvCLK+Fmk7JsqxSBsBwMiXLIxwKJVF9+tuwcmyJTqLY3c0XQjkCrKwNyErF2lpKbquQSyQKhcY4R2lzIl3c1RuRYH6VF1zTzOMv86oxbWk8kAO0cYvj+AKEhm+dm5/fCXBpJ3L9Gt3FcWr2uz/EJQ5EKe578IF5uKT91ynGRigdZG6MuKo5n8+1+HlUvxUuXJxh7AwVGV54ZRPBMC0LNAUnj+c8/70xSysKrXrc/wgs92OsyrEW/uNnr7PUtRhlKMcZs/2EL3x+k6uXIS8HLK0nVUjLh7Ccw7hqT+bzIyYNbQC29xfbk0iNp2MeSvSVh/BjdhL4QCb/EAuucT3dPH763Ndv8s53PckvfPxJPvh0l7/+c081TOOorJ3rV1Y5fTJhc9twYj3lxFLJvSdTkKr9g3GWsrCsbzje/Q7h8usWjeMP/ugcu3szImUxpsQWEUopkthgJeb3/9/v0u3N2N+dUpQRIrZy8Wpm+8rXbuFc1ZlzfSPHYiBIjoWiw0plOTUtBmpXsF2J4hnag5Nqk1jnmhAFwAvf3eb3/p9vz2OKKDCaUiKWz2xU8VnngJIZEZcvDsljRzmpmHB9JeG1Vw0gbN6yvPhixn3vgDSZ0e9Zdm5pXn55SDKY4VzKaGq4s6UZjuDaloOyYO2Y4cTxLr/2G09QGM00N/MDTDhimyPJlFJDtzPlzh3YmWgGvYJpOcPpkue/lfDyi5bbW2DyFFCLeY27CLvmexbj91CF3IyzzaG/dsikej0XWGHXy+b7tqUa3rOuBEuShEleoCi5tbXP/ignzy1axai42pSTTHPrtmOaORIxiAi9lc4cHxcxNlXiNNUFIhGxEoa7itks5fnv3MaKBbFcekOBU+wPs0WPRBbnFs6lQb/2Guf5iIMl1Y3QdotKUWDhFLep+yiF7Utg/j70kDx+MD8vAnU+QFX99S/e2MOqCTkFhdEYiRvjbmYUxipKBxcvzxhEgrPC6+fASRUSK0rFnW3FtduavUmCkgIjjrMPLUGk0Vrz2GMnuL0549b1kq9+/QZbOwmPP7mOdZrZbIZIF5qwVsbH/8Z9jGcxr7xgGKz1WFub8td//hSDZdjZ3Of4ibkXudgoUujGh6yHg+WVMZNp1To6z/P52sE85yTSGDo/CPzQVwE99/V5FVDDsEoOhC48OKAsQSKLNRoVxcQ2n1dnyJzRHIrJVOj3LJPc0I2EK9cyzt7Xw9bMOp4WdNKYrR04vVZ14x+XEWmcoSQhZx/KPi+/MOahh5dYWirIJinhWXeUAAAgAElEQVRpL2OWaa5eH3Lj4pTjJ3o89mSX2AmXLu1z9r4e332lx9NPTZukTgjeogorR3xCDFphCFn86yE8YWtdFRpzdHEyRXRGZLuVlSExMKJ0Edguome8+lrJ6QdT7AzifkaqezgKxKbkBooSBt0d9rbX6Cw7rlzYY2mtw+ljHW7eGbFxPMbmKV/68i3i7oxiavnIz26A7aIl4vbODoOVDr24S1GCkoKO1A+YseDEUtqEK1ccZx8QXGlBKba3HceP7bG13WN5JUGpGSIFX/pSwYc/0qHDPJHmleJhBlG7+sfHzX3dvA/HhHznz2n49VkoD615qmTeq0ab+e+trsMrMi9r/cLnv8ZP/exHSSOhAGaZEIswGhf0BxFxXIUFIgujccygLxRSsLsf0+tBJ3aIKRumaLyRcJ41zzhrUTols1O6LprzjBLaJ45DPvIJ28bLbnXebCuUu4Gns4/jz9u0qyasVaqDnm9o1Xr6JmhmDInsGhiHi2Zs3xGOHUtwooCCvZFjbTADFyOueopZIZUXY0Vx+dIOqysbZEaIyYk7DmcTOl3Y2ynor0YspyV705h+t0QBN2+NWDu+QSw5168rztxjmFhFrBznX5vy4NmYXqqZ5AmdtGCYCUudmKIA0ZDZEUtRD+uCCEY9J2+QJfagBzrJY7KhYfXYXMSHXT/9WFZo+pcl8mNUBRTWCQPN0fN2fLUoS/78C2P+9E+fBwQlU3DVYQzCOnfn45+WQacE59jf7yAinDndr4S/c2zvOYqiTz5LWF5OKmYClvSE7dsJ+8MpsVvi2lXhne9ZoT8o2Lxpyd2Q0liuXS+452TKh3/2JI892W+snwfPLlO6hPe+qyDL5ycIw39+TlBtnNJbqTJ/EIWH9mv/z4cWHFBahYscqBmiOyi7SlZGlGWClRyhqoC4vLnNv/7X53jui5/n0lc/z4Wv/DHZeMC/+TefwxQWUVPSGGIFpemxvJYh2YwnHu9x7IThxZe2WDs+YzhRpPGUjRNLvO9DGzz93jMU+RJoRV5YnI3pxV2ub85II3j9XC18bP0UNQdffnbI9t4tFAZUhpJ9okTYGWrW1xOMgc1Nzc6O46c/soRynQM0uXzVIJKgbIR1wvlLMaVUT8AyMq+ACatM2tVazcnb4PMw7DGe5BQuajayUSwaHALKOG7ujLGuyvds3pqwliYk2uBciVDSTwrieMbymiWK8mb9xcFSr8BJRuwcx5dy+jqDYoYSN09Ge4uaIPdl68aISqFMQdctPgW23WzP811myoZ37ubVHGattsORIR/7kIuEvw/uHdmDe8DTG+aVcOfPXyWyq0Q6Q+KCy1d2ObEh7E0LLBZtLauDhOl0mcLklJJQOMjdPoVSbE9iBkvHKYywuq6IkpiSGCca60qSJMEUETt7HWYZKFLEQJxscP3KPqUtyYuCAqEbxTilefShJTppD8GSqAm3dhVxlPH8927wp1+4RKIsS9EAbIEVmIlt5uRqJR02pgsVQC8xpMvzvkE+X2PMvKOscnMv/wcx6n+kPAAP3jIOm6vBouVjSs3MVqGH0+vFAlG89WZF0EGvoNde3+SRR05jKSnzhMvXNnn4wVUcBcpFRDbBisWqiDyH6I//He4f/lP4F/+Aq+/5DXpLsD6YIJFCS4essOwPS5aXFWlUVftHxiwID1GKl88bHntoHg9tW2Ewt/6Fau6hhdqmjzgFKgKbs7OXsLxWIGiG45xuVxGpBFNmKCnREiMCrz73NV7fXuZvfOKdjPKESAxpbBjZKZPNnGOn1jFW2NsvGe469oe7PPXUGtZClmkipRnlM9aXxhg6vPpSzvF7YgYrA7SyKJkirsMkt+xsRpw+bciZkY0H7Lz0ScrO0zzx9EPN3F+9qDmxUnLu6mXe954ziFGUakrKMplYlIu5fmNENkl58KGYnTtgHCTpmI2VFEuENTlKzXjpFcs73mEYTjbQZky61CNqJd0a2r0Jfb1HsdCIq34dnrXY2d+jv3IMSkFJiSkj4rTk298Z8cy7ew2v7u8aVlbnj1UM68J9QUBJZRW2H1fp7x3iBnMF5pWAVfUjDFunZsPrDvvb3k8el6Y5nOOAIvx+3oCrJgos9usJD/55YdbGxecklAiZiUkihytLkATHLpH0GI4LStcligq0FsaZZqWvGe7B+npBZgsS6TDMIRvloFJuXNvm4cdXKXPNoJ+xtx9TFI441jhK4lhjraWbKoYjQSnoLU9JXcz2tmFtI8ZR8uILhqee7HLu4jaPPLBCXgjdxPG91/Z45+PrRBQ45lrRe0R+rf3atT2AUPlF7TLnwPP0v/HnHiLd+fHxAOCgdaEDYRkeHKk2qENHhukIjq8XYDRXNzNc3fvDKCiKAtVSfoVbR1zJLE9QccGZM716vQbgBKdLJq5kkjn2x1Oyv/dPSF96Afnvfod7To258NKQ8+erpml37ljeuJxxci0h1ZYr12jCSn4e3/7mFs5annhImj70yiwqKqgPtyB1Em6xxvyAxSQxYMFWCcPV1YyyqOrx+x1FNosZZzCaQpH3uXAt5sblO5x58sP80seeIrMOU8yw5YRxWZLaFf7wj/6AW7c0k2zGn3/u69x3b8q7njpJmSd8+tMvMRxP6cQTjg86XLqocXmfY6cUvd6ArgZnply/3IfS8J1nL1AUU9CaCy8b4ijn+CM/Rff4ExgVc+HyDEfEow9mrBwree+77kObGJQlYo2Mgs3rFitjuumA0w+MuHFzk8EGpH1YX+5jKRju5mQuYTRNOX48xdLjU7/3RywPEhTCzU2zUErpLVMniwei2kKt3bO92ai+fFE0r19I0C4n0TmjfcCNKbOcDz41j+ErB2urSWMp+8cTWjV/FKeyc+HQfv7tYR6guMWzBkDTH0nk7jyj7MGKJai8zcYqbV0bjnWYR9r2ZENvoN1bK+xt1H7+gaetL4HMxuPqcJqdEWkh0iUxPUoM/X6EswVRXJAkCWlkUBripGAyi8nGPa5fU2zdmhJ3UqK44PSZjar8OjaMpymiLGmisbbEOYO1JVprtAiKApPNuH1doWTCsbUUGFO6hF53zL/837/A2Qc6ZKakmyp2R44nH0/48l9cZFYahpM5nZUk80OHHG61h/S78kayoPjbHpuvjPMHVN8q/Eh4AHezVDy0taWy4HTOC6/BIw9FPP+9PZwesLbe55WXrnH2vpR3P9Hn2o0u995bNuWDU5OjGFA46ETwqU9/i5PHzlDaDkWxx8c/tsEbb8Tcf79i86bh3m/8B8x//z9Q/pPfIvrbvwJAbjKyfEpHr5LElRDOy4JZoel0IXURsKgIEIdVed1kKrCMgtig71PjtfzcQlUYOwM7INJ5M64RhxBjbEYcwaUrBVrBYLDM6kqOswoRjbicf/+pV/nVv/0Y1oJWHa5dL9ASc+LegiyPieMRNzZT4t4EZSK6HYFYUCZmOCu5fSVnY73k+L3r7NyE/lqVh0m7IAYuvVGwee0mu7fHfPzXH2C802F5CV59bcyjT6TEqiArunTjIXvjJXpdmBVgMweRIG5ENulz6eodHnx0hU4c00ksm1tjtja3ePDhB/nON6/x2NNVWEmphJde3uPs/ass9wp01CeJtsEOqGwey4Vre5y+L+Xl58fce3qF65e3efixk2xuDXno7ABlR5RunQQLdeOvKpZcHJqz8VDKCC09PvPp5/jEL76XJOnzh596mb6+xs//5z+z0BtoQYEseHBB/oeD3S1D3mlb2m3voDkncJewioedfU3JHquDLonoxioPe/N4r/tue7HtFYX5l7ZX2+5LdLe93R7XiqI0U8YmYqWToIxjUhR00i5KMiwJphTyPCft2arOXhUoely7kvF//sv/lb//j/8elohsZplOp9x7skfhHDZXSFziTEyvA8OhQWvFeDxmZbWPsYIzhmwG6xsaTcb1WxOObQxIdWW4CF0mZYFSoCQGKcDEXL+xwwOn+82cvCfp96ov7ohNa31UVIUIncPAQtVjO78Vek9vtRfQj4QCCOGwjRJ+bp1j86Zj845w7ERKEoPJ4bnv7HD2oWXiSJGNZqSdDCLDzpbho8+s4ERAYu7s7DC8OuTUU/dRmCkvf/XzzDof5T1PrZFPZvS6BmMc/U7Mje2U3p/8LoP/6Xfgn/0Wxd/8BWK9jCMjNimlriofklqAGEzdlqKD2AJRCZiST33qS/ytv/XX8IrBz6cR/EHYwTen0hZ29zWrKzMc8QJ9xEEpCaYEq4cot0SkZtwZzxgkSwyzGf2oT7frKBlx+WLEIw9OmE36dHsFznVRFDgXM5454l6OKfuMJjskskq6lNGlJDMxTqVM9nfp9le5fG7IqQeXWO7sMi0VqVrm9TdAx3dIZIOhnCeePMLZhycYepR5TpLAOLOkukMvmlLaiNwKUQRFEZHNdihna6wd22MyS+jGXcZ6TLaXsL4Us7df0F/epysr7M0i6DiWXY6xEU5laBUhosmLIXf2FPeuLoMqOXcxYjic4OIZT71jGa0KtO2yP4T92R7lZJ/Nm5YPfeAMonN8+aMVqr5D6KrvFPMDOhMLXQSheqRjbhK++aXL/LWfvhe0qaIfTh8ebpH5BrZUj7RsQgR3aQbn+cFJfY2TJjGdUT9Duj5h234yFbAg5BHLtZ0p92xoxPYoVYayEaVVpMEDWe7WOC3cj2F4SFkoRbBim7BWc8/62r39CatLvaqXk3+kqSwqHxEhs0KKBRSZiYjiHENMypicDsoa/vxzL/Pzv3AC7DGUOAwJFsf2dkmcKISIJILJuCTtRlW4LymZjoVeL6pyIpFlPC2rg2xxySDtsj8tWNbCKNeUYpmNS/qDMRuDPiUplEN2p8scW7LYQpGVDkn30KwSUVYzd2Zu1HkFLxrlIxPhuZ8w5KeEwhqmow5Lg6yJenha51I/wIp5ccOPXTO4dpMmD7bV6fP1S2BdxNKqsL035sZmwbXtq/zCL67SSTQ2E1bWu1w4PyYba06d2eArz475wpeGiDWM99e5XfT4g0++yJXXc06942d45n1rvPTSy6wMOkRJnztbe1idksYZvd/+HeIXXiD6L36T8e9+lrJwOElB5ShyUkr2RiWaFGcjTAliq+Z1//f/9UmsKH7lV/8aVllKPW8XEba0loAOTgsXXt3ECaysGEZ5coAuTuCNC1fp6Iye6hJJgRCx2ktxMmW5m5J2ZuAyvvvsNR59AHAx3a5CbIpytjpEJYa97T1U2WcyhI3lVZaXBE2Hc69r0Jr9fYuOS8oi5/6He2ggw/K9b9/k9i04fXrKsZUN1tYdj917ls4SXLyQsHl9izt3DLtDizIdtnZGbJsuRWGYziyzcVVKPtxX7I2vYqRLP+mQlQVMc3o6JlJTOh1DrJfI1JhuB7pKsFqhlEarpBY6Q5J4iZX+gBu7I6zSLK+CoccjD64Ti2VWdLEqY2k55/SJLmcfvI9HnzrOpZsGnAYnWBFAuLnZ48I5+Mzn3yDHcH1/yoWLY7qqwEqOFXjplet0VM57PnwWdEJZ6uZgGjponR0YYGFuoayfc9x+ilw7QQh16CQQ/k4gqS3wdtuFcJyFMJZT3LvaQ5sUpyK++ZVdvva1V9EyZW9imnMXUDUva+NyqPVuXYVT3QxOmLdgDq9dWe5V12IpSapSbiuU7OGU5vLVhOu3LXF9ovm1868iGrR1KOeYZgpnFONpyruefoLd28fYH2m2tiOGw4KssHQ6CXGs0RpKZ0j7irwwOCfoSEg7ClOUFKUlm8HSUlVarG0H4yyrXUcRZaSpZdC19LuKTrJBiePLfzlEScJaf8bv/dvfx8WQdgoiO2A4sty+U58MV7pKYl8sKcty4VTyV750geE4bmjjT5P70+KxTOn0s+r5GD6XU5+niJk/V8Ow+BCh7wc/9B5AuxlcmAxqDkHYqnePAOcuJbzxxpBT9/Uop5ooKUgTzSSDydixvKLJ8ozjxxJuXJvQH0Tc2Yw4cY/mgbOWSeE4/+KUsw/3mOQTKBXHT3Z54Vv7rN0j3HtPHx1PGO0uIQ46n/v39H7zN9B5TvGup5g9+0U6ne7CwSBrLUQps6lh0HFYm5CVOZ24cv0yA5GUXLye8eCZHrFUjbWQxYZnVhSf+rdf4pd+/Rl6UbKQABIR8sIwnXXoLWXkRQFWyE0fV05IopheT5PbGdvblu1bQtKNUHqHteUNVpdtcw+xhpdenPD4U9XGdMYSa4UFrOtw9Y09ok5GN+kznXS475Qmzy1FqSjMLoN0leFsj2y2zPKqYK2h2y3ZvOmIow69DszcCFUO6C07EMuNy2NOnRkwySd04qpOPpIEU8QUZogrFefPb/L0M/cxG8YsL0+YZjGDpZytO1NOrK8AtupZT3Uy1zqDE8V4FLM3FFZW4OrV69x76hgqKrh0ruD1N7b45f/sPl59peDM2QGj8YQvf/nbfOznP0p/xTHZF27fHtLrx9y+Oaa/rBl0VrFmBlrQWnPjxi3uO3svRVYymY5YXlljsAzZxBIpR1mWDJZSZhl0OzMiOhjJmie1Oamf/uXmIb+qpE9wyjXNDJs4ups3ECNYfxeM4cH/rn3QMGxW+MqFMQ8/MCCJE4aTCb1ewt4tWNoogC556Ugjw/PPZ7z/6bixXsMyWo+Dxy/MRTQnzrWqGsoptXCCvemzBWQSU+aKwm7hZgO6/QStC0yZkqYFd/Y0S/2cvT3NoBeT5wZrIIqFsjTgIpwzTLIZg24PrRWFhdu3tjl1Zh2xULqsKvnsTPjLP3mBn/7EBykKAwacRGhxOGWrHj2mytD0ezAeZTz37GVOHF/i3lMnSJcc2TSqFMZgxu2bXZ54HAomGGL29y3LnZTb2xPSqMvySoFoiCXizpZw+1bJ4++wPP/CFo8/dZJYbJPo9eEdYy1OaRww2ncMlkAp5hU/dUPKdjO4+C0mgX+kFIBtbZAmey71wyqc48tf3QElpN1l1pYriyGO4+pRpqYibDaDK2+c4/F3Psr21oyl5crqOHNG8aU/u8rPfmKNl7474czZE8TpPju3E06fUYx2NZ1BRpo4ChdXAW6E8pN/RP+3/xl7/80/oP+bfwfsrDm45Q98OBTjIfQGY2bTPoNOjKjqVHJhEkw55tvf2efDH9po5t881L6OD1bz1ohzKGvQStU9URRGlVgs2C6zIqebJFy/DDeuv8j7f+phrIWy6JBlBZ3liOe/cY1nPnAM9IySLuOdgu6SEOs+VvbJ8hRTOorSIUUXreEvv/gd3vnkk5x6YB8zS0l6GlW3vsBMsDbic39ymZ/66BlWVwcUBu5sb9NP1tneHbOy2mNtxVFiKbKI2cyQdCyzCcRdS2RTZjnM8i1WVjdI4+oshSJGx2AN7O3tIabD8XuqpHSaDNi+M2J9Y4CiqKwh5kISKnd6Z7vDhfN73H92hfV7Jty+OkI4ztJAGO1BsjRiZ6fgzJk1ytLhVE6aaIY7EYUpuXFth/e9b5WiNAz3O4xHjrNnckrmi+xPWO8NU1aWLVffEKbFbY6vrbKxVq3nX/zFVX7mp88iqqQUR9Q+WescSBVesmIxJiVVJTkTYunhqMKJyukFwStUwvawPjAi0jzi1IPfS5WFKWjJubk9o9vtMh3O2Dixwc6W5ebVHZ5670Y1tqlCmErP++D7sIO/T1if7uvS/ef+HEXY4dT/DqqQ2WiSg9IsDTTiDJOp0OvlzGYdIsm5dGnGZJbx0NnjiLIYJywtVYGj0Y6PlVmSboTJHUnfUmS6UUK2LCmtoigyllf6lIVjtHWbpRNrRDE4q8EI0ywj6biqbNfA8VXHKIsZDksUJWkakRXgbISSCXGcUmYKYocpFevrM0RF5M6xv6VJIjBOsbEOozH0ehmg5s+AEIe1kDAX/p6+pm60t7mpOX6PWaga8kLf1KUE1CGyVCU/HiEgD2GFgzQn7+oDEW5+WvDxx+7hnntOsr6W4kTY252QxoDeZ/3kFFdC0tvh6pUxEu1T5DDaHVdPy+IWDz54H+NRH2SZXg+6nWVO3R9TZAnLq5rRvqLI+9hZgqbLeOwYf+Jj7P7X/5TBP/8fmf7eHzQnjhvh76qe6P0vfJrkPT/Hyp9+FqVylINbWxHoMbt7KZP9KwtzPuzpSQqwZWVFjWYZWRGjdIGxits3C5QuiZOEwuVs74555iOPoBFibdkfTUkHlsgK7/7QPQiGSTFgvAvnXt3FmZSydJR2mSjJmIw13V5EqXP29uETv/xOLl3c4871DSSJsEaYTBXZUPPiS9cZD+Hjv3SWXnfA7j7s7RYs9frMMugtO6wtub1TcmdrxnAy4rVXL5OVsL0X008Vcc9wYvVOlWdIJgzHMZs3RhTWIQIvvnCTpXVFlE4AxfZtMDOLLTsU3CZ3cZM4DQWRQlPmQ3RUcuJEyc5ml6S3xCwriLolayfAkDDoLbN5M2NvtyRNhJ1bEZgx3TTigUePce3aNldvlFy/uc/pM1lVYkn9kB8RdnZSLI6VpYLxRLG8ITz28Ak21qq1+96zM37u587ymc98F2s6jO90Gc5c0zTNK/tLz/4ZucopZYoVx34xA7WM1M3ihIRSIv7d//fnddx8LvwbnmnizFJFoIPTt+LgpfPbXL+S8JUvX0UrwcqA5e4G2nZYP7mKFsvG8YIn392vG9sVbO9kSCAyGiElVbOyebO1xb9+D1SVToIXOy6w/AGiKAM1ZalnsM5SOuj2FM4qiEZ0UsUjjy5z/5njZMYgESRxgWNCnufoqETFlVWc5yVxV8iy6l6DJQEpUBKxs71Pp5MwmUywRjh26gSrSxGJE+KoxDih24vQKsUWEInl9lDIMkh7mihJKExUVQclI0qTUrqSzoohih1pt+DOfoYtIkZ7cOyYQjq7dHvwwvdm7N/JAcW3v3mVq9eyqoOBmYdumkoz5t6sVop0Za95TolQ927yMkbAC3+4yyMGD4EfGQXgQQBENd3wfBmVt0L29uHUA2PSVHH2wYjB8grnXthhf7vL898Zkxcw6K3xy7/6HspyRpIk6BRMWfLJ373K2Uczhnsj4qTqNDkcT3jhO7ts783YugOrqx3ycsKtrSmFKaHosrK6ytK/+IckL73A8v/8W1XVhd8Qf/gZ4vd+EP2Hf0z8j34L9fx34R//oyZmevxYSUTM2vGIj338PdUcXfVcTz/O4gEcy/Pffg3nEra3NGkKo6nC6QlZrnn1+YxL5yZcv6oZ7t+quyhqXjsnlNZR5iny6U/Tee8zFJ/+M2bDGZ2O4t0fOIOTiPFsynQ8IXJdytJhs5itayVKYH8HPvJzCXF3l/0tzVf+8hrf+cZV0iXHk+94nE63y2ik2R+PKAtDvx8zHJV0B5BNFUknptMv6fcH9PsD3vfBh+h0LGurQ/Is5qXvDSlZ5uq1jHwaoyTn2PE+SSKcfy3n4YfvIRtF9AdrjCeKe890sJFiOhtRjo5z/rs3eOHVnKlNUNZWVpEYXn9jysl7Onzg/Su8+to2r1+csr6ecM/pBK0i4u4E4/ZYOQadTsp0YhgPE3o9cKpL0oVBT5hlfZa7A+Jk0d32nSVX17MqeSuWfrdgpW/Y2gQtwjee2+bpD/QQa/ibv/w0V67d4fbOFibrMDYljqrd8rnzOcP441y5ZMgLza2blstXLFculnzjudeqG7qCyJX8nV//WNUJFZpOsq5OLOIcFy5MuXa9BFs2+2NrV+NQPPnYKifun/AzH70PcY7I5Qy6Bct9w2vf3UTIEFKUdIAxiMGJ5Z//b7/PZKbI8zlT+lbOEdI85c1Zu2DAiAiFo7J0fdfLoH2BAMoJ/WSFa9dzbl5VgGZvzzKdRUTSZziL2NzM6fSgP3B0Y8VkFjGbCNYIOk7QkSKKFFHsyEuL1jlIwWwGOhJUYjh2fK2mkWZlbcYgzVGuoNOxlM4SJxbj4Nbmnf+fuzeNkTQ57/x+Ee+dd2bdR9/d0z3dMz3Tc3CGhyiRWh5LDiWDhoX1h7Vs2JYNw7Zs2CsIskQOKa1swBBgYwHZhgHD/iBoJUugeAwpkiI5JIec4Vw9fd9315mV9/GeEeEPb1Z19XAo0cKuoXUAiaqMysz3qIwnIp7nfxAUJMKzQBtcdwg6RQiJERnSG2CUR7ma5/bJJj4jSuLKKsNI0ag4WCSsXa/iehF7j7gEVZfuloOJxjjOtkT9w4u93aS+7fjWCMo79w3YYf9uw3Bz9dh8n/Xztn+jJoAd1CSTL9m7+pSAYbiKI3y6/RCBplyEqb1lphoO+w9Ms/cwXLl4n5W1IVG/wqOPSYyCqZrDBz/0NNE4ZmnJZt8hC51ZqChgbiFnnc5PJzg2+AULm4A0sinWYGNFo7/4Bbr7H4EXX0QbQ6Jye0L7915Enj2H+NznMV98EXPyJHzh8zvXJACNzbAbcm8lZy3v+OvCQ2JaeafhiWcOI0nYu2xj6YSCDx4+cWSwwp+wcesr3L/d4kO/WAMMApuv/st/wfUbPZIExO99DnnmDN6Ln2O6YqOFg0NGluaBWkiXzmjE1Izh3to9FvcXmFkeU646JLFAqzKlisOePfs4/vheeq18XRjHY9LI5d7NIjNTFrFu41hFvEBj2zZRHGNUgTAO6ffGZBmkI49SsUyUwPGTZRIyjLbJpMAh4NaNFuEoZHHZZTweEY4CwizEdaG9YeM50B93WV+NOPLYAo8eKaMU9GKXZlcCPvv3uqytOLTaNkePFVlcNGgsrl9PuXevTaosVm5NMexY3LsTo6wMJx/zVMqSu7faRCMoViVrGx2qNZv2MOMnb3YYKQ8l7B2o5XZAU4SMk4T6TEJiFCorcf50k1R4DMKETNnMzk4j3RFJaOgMfPo9j421TaZnbeYXPdrNMUki8dwiBw/EHDt++KHqaSwcUiZM5205iEmhOhOGcskDY5GZFIRhrAwzjZR2V6BxsHexgs2ux74ji9xb0UhMbkxCzlGZm/L57f/ms/i+Tavz8Cpzt7fBbjLadhETwJ0UkXfXLiS7VNuNctsAACAASURBVDuNwbVj9i+5pFmH0aiPSqDfzdjajOh1I2bnNVGkiEPJMATf11iOz046xY0olxXFQh5UlXGxLIdMp5R8l1JBUaomlKqaMPLYLcHc6RkkHkmisW3J7FwdYyQ6U7i2RpuMoNTHEPOjH1ygvaHyz84Mva5EWmqy8FNYtsb1DINxrgA8s1cw6HsII9EmARsOPHYCYWkuXoqQ8mFAwLvbboXjB7fLPFRrlGKyy0L91Gt/VvsHPwHsRhXs1r95N6QN8mC6d+8sylhcPrfK6dfWmZ9PObScsDhnaDdjHDGkUKxTrxapzybcvrlFUd6n3YlpTIVsbpRZX7O59FaPb3z9Zbr9jHBo4XuAiLl+SfPmjzapzRoSPeLG1S2m5ywuP/pRyjfPYX71UwghcK18cOkvfB7zxEn0F19E/+oLiLffQHzmhYeuwSKjUXdYXvJyxqVKYBcELBOGs29cz5+/B/ICoN3xqE0V2Ej3sdl7nKOPznLnHhPoYcR//M9+i+c+MIVbDEle/CLZY08Q/t7vs9X3sQ3cuB7jeBAEKZa2qAZFpPHYt7yHdAhR6OBKRaHgMjUjSGLF/oM2hUDiuRmdHhTLBYJSxtEnNKmGa+dj/FJKFA3JMpez71whHEKvLfBcQb8N3R5IC4RIidMIMsH+R2DUGzGOYW5hho1mmyQ2bKxHlKoRJccnViMuXLqKBo4fn+PIUQ/L0Wx1x5TsDEvZNGoO9+9JED520KXaUGS6yP69GpsxlnBY2ttgYzXk1CnFzRtbnHrGY2m2hJYJ62sJzS3wgzLtDpQLBSqVEkpZnH5thOO59FqwtWm4f89FiFyK+fz5NptNj27HodUytNs+lt3l5JNT3LrVJIlsPN8nSqCzKbh0/h7dLbh06SInnzyUpwTbhsWFKpmKkdrir785IMryQR+GHlokfO2vLjAeBTRHIf3Q4fW3+jS7irU1xc3LCs8JUEpx5wbcuesjjA2Zz1RN7UAPf0oOPNG8/N2bLC1INClSpGgSLBwEBlsbYoYszOaIpu2aQ3dkY4RFalxe+9Ft7t3bhIlPxjZkUWkmKaCHx+/ute/26vbw/iKNss/cjCbTGZubQ/yiIkucPE8vFPUKVANFyct9JaTUJKFLlAgGQ7BtcCyFMmPKgcYQo4zP2Tc1WWpTLkdE4wI/OXONRLo4uo8iw/MFrjs5F6nBtlHCJlUBadQg04Jf+sXHqdXqub6WFkzN6AlwI1elzVJDllqEY43GRughngPFQoxtucSxRqgMW5Q4cswiSeyH1ILf3bbTytttW3ZkO0Zsp/vyVNvP5qm8u/2DLwK/lxTEbhXG3UiYr790k49+6hjtjS3u35c8caqBkBpLahxj82dfucjHP3GcXjfl3sWXed9HnwNSVu7XsWSGG7g06nD79jrhYJrjj9uMwiSHbOkCxWqHaFynXID79w3V2ZDxSOJjU//+VxGfz1f54jMvPETT3u1q5Ojc42sHK/3VryE+9yLmiy/Cr+QTg+EByikvZkoso0DInQG3m5K/0hpjuy6CiCRpUAwgzkYoU6BcFAh7iNAlfAfeuRFzcMHDiA6loMj160OmpssIUkq1hCSqIa0BBafM7Tsh1UpAoQD94YBGvUinYxgr8GRCrW5hZEwWlsnUGMexCeOYqaqkuRng+5KfvHqVD3z4EZBDBl0HL8iolYsMxjCM7kGyh2g8Jsp8epv3GcVdPviBo4wjC79k6G7aVKa7vP7KgKef20tQHGGM4dpFxZETHhsris3NITEBd290eOLkXg4fi/njP77KkyceYc9+n+lpKBYzuu0RCI/pmkUsHN76UZNKpUaiMjwZsLbR58O/VKHbgU5njfmlWQa9FKMd0jTlrZ/c5tP/9mE81yIcCrRRlIqGTsdQm4IsHTAcNZCAsBJO//gOJ57eSxJ6GAmN6YRwqCgUA7q9hMWZAYhSrkuUuXz35escO3mYai1hHLex9BRSJnR6Ca02TNUCHtlns9KC2brAFopMSNabmqWZNF/Vo9DGotl1KNUFr37/Cvv2LjK/WMbzwCNDKYPYxvYLiTEZNvIBmAIYhQ69vmB+Pt+Rtbpjqo0CRsdcvujwyOExRS9HoqXaRVspUluMx0Msq4LnZUgZMY4LuI7k9q0Ohw6WEMIgdY53fzeHZ7fcCcBg4FIuJzmHxhg2W4KgEJGmAUI7+KUUC5csBmFr1OQDtNbY0sr5GlpSn5i3NweCehk8YdFJFUUnISMlMB5vv2nx1DOKQZprY/mOyzjWCGOjMwXSIhoaimWDRuRy6I7LuJcRFCXSDrGMj3ANOlQYx0FnAiMyssRhqpKy2RY4bp6nNyYPAEaAyWxUBHMLuTR4kiS4rjuJIQ/7XOwGw7zbKY1J6k0IgSf/FaGAhBD/B/ACsGmMeWzS1wD+DNgP3AZ+zRjTEfmU9D8DnwLGwL9vjHl78p5fB3538rF/YIz5v/6uk9tGAb0X0/Ch5yL/ZxtjyLbJLWy7C3m89LULfPqTR7GslFgHNDdhZmEL11TIBGRG0m5LBv0h+w+UuXZ+i6AiWF0xnHyqypVzLY4cXSDTGQYbk4RMTwfY5gHzllPPIM6ew5w8iX7njZ1r2K05Dvy02t9TzyLOnMWcPIl5542Hrs28x/u3j+fsmhFf/cldyvXDPHJU0R9ZeH4PnQV876/voxzNxz9xIEc79EOU0YwHsLnW5YMfnqbddqg2MprrfbSqUW0IyByaWyMq9QKVisWd222iqMH8nML2NKXAQcuQOHJIQ5t6A5SK8+2tSBG6gLZiEB4qg9T0aK0UqUzHFIsWLj6dXkwcS6ZmFLY0DAYBRiTUy7nS6OqqZnHZp7kOs4tjkqSAZSV0uxHSgmJZsbZm8eoP7jIzO4syFeK4x9079zj19HE6vS7JWFKuVmi1Wjz33BR7lz0sOUTFHpY3IEmraBOxtV6hGMCrr9/j8KEFanXF3JzHtWsRfiGj6Jc4e+Ym+w8cYGouxg8EZ99eI/B8HnuswjgU2CLA8nOEmZAKlSR0WzGlWg3fA+n3MarC1nqM5WVsrqbsOVCguxEjXImQCZW6j8SiFIARLlfOQ7N1g4XZg0zNCV79wS2OP36AcjFjnNj4PkhL06hqPDtF4SFMOklDuFy7FrKwx+HSmRGVakC9Iel0RwS2z4GDFkoptno2KhmgVJU9Syndkc24Y7i32uSZ5yooAhzSnRpCeytE2jU8L2EYKeZrAkOum2MJC01CpAo4dkqr47Cx2mHv/gK26xD2baIkYc+Ci6WSh8cBD8b2zoQgU3qhjVGKzXWXekPSaOS6Vq1NRakhMcrOZV2sXF5BylwTypK5nHvV1oRCYohwcIiUxLIybCFQyiceQa0yItEOltHcWRsyNVslHEBQBoGNtAxJJLHtjExZoEDYAlvCm69f4slTj1IOIhLhkMZgCUOsNDoTOL6h5IHULkYqNrYE9++vsHfPPEHgkCQarcGIjJmaxtbyPXk9u+/LQwRCeE81258XBvrzpID+T+CT7+r7beA7xpgjwHcmzwH+MXBk8vgN4H+BnQnj88BzwPuAzwsh6j/Hsd+zafmwzrie5LxyvZQHzkxSSFIU//iFfViWjTKSb3/rBkvz4Kq8oOJoSMY2i3U4sL/CeCA4dqJCtTjNVEPy7ZeucOLpAj/+/n3O/fg0l893OP/OmDh7MPtqAXzhRcwTeX5/u3CTohH6gZPPtn7RQ/T5SYqIL3z+PdNa0oD91Zewn3yWwZ9+4yGDdL7yEpx6lqlXX0XrAb1RBwuQokjJt/nYp2f5lU/P07xwmYJvU6sHzDaqWLbg/R/aw2BkkYmUQduiUSlTr+eDuVyGUhF+/MPb2CJm73KNE8djgpKFLRw6bbhxNeDGdZs7ayMuXFH88LUt1jcdrl8vsNFKuXLJ4/5tKDiam28PKVUEt6+OSGJBpBSO45AlDkns0+kEOC40imP6I8V47BKOFcoYKjUYjjOkGdHvuixMwUtfvc3rr2ZcOjOgP1QUKgVmZ33WN7Z45NhRVlfbJElMr90jToZsbba4cKHNO+cyvv1Nyc3bHTJmsGzFK99bw7IjEhnzwQ8vUm8IfvzKdcIxTC9EzDYCyiXDB3/xIHv3CQoF2NqKeOrpRfpDRXeYcvnSiEtX72JUShjGaJEwGvnM76nhV0ZkGaioQjiCct3m+qWUmbpPqeTS7HQBxcJiiXHbEA4drl8fc+/2iD0H4PFTh5jev85sHT7xwjyze7sUKzZLe6HdbtGYBulYfPnrN7l/9YdIYzh3bQuLhEiHFAKb55/3efSooTZls7ynyr4DHleuCcapi8ks5mcL7F1K6CY9KqUh03vg6Wfm+dHLGzg64Ut/cZde1yOJNTNTNWZriooPc1XNrRUPJR1avYDESGxRIjD5rqBYGtFeXcVkmmhgk2VgGUWSwd0tyZnL0c73fHtcbI/rHALtUPWgUXI4dDDD9yWn39JIrZidEZRtiKIE17MmQTBHi2UqouxoynaG0Llkgy8KhKmmYNv4WNhG8sp3L1GoaN6+cpcodul3fPYuBuhUYjuCTnuYI68ygSAlCjOMSVEq53ZkKZx65hC2hHFm48p8crB9C5O6lMsOGIv+WBAakCYhKEiefXKe6XrGaKio1iRSSPqdhFb/YetOyJUERJ4SeEjO46EUmnhg4/luHsjf1X6uFJAQYj/wtV07gCvALxlj1oQQC8DLxpijQoj/bfL7n+5+3fbDGPOfTPofet3Pan+XFMS7b5aRueuPjcYYBcLljbc7FPwZlpehuQVTdWjUE9I0xXEcWkOb6WI2uVCXH722yuHD09y8fZ8D+/ZRm7EYDsAoSM0Ik1kEvqJRKYJOfubsvA3L27YhTCcn6j4M6fmpCeHyDRfbMqQmJRo5nDwpkE+cRJ49R2vPMTo/OYtKHdq9mFO/9j78y2cJj57AvfQ23/je25w8/DyZiJHSw2RjGssKmZX5wctnOXXyJNLNVwx+QSG0wHEM5662OLKvSqVio7C5ew+GA0W/F+F5HpaVY5Rt22Y0Cnnf8xJpLFodqDdiAkokqaHVbNGYm6bbNwwHECa3WVzYD6kgMSMsLCxfc/FMkwOHFvF9hxvXt5idr2AbweKCw5kLPQ4fLWPZGbZwSeKMWzcFrf4N9u9bYGuzTFCCN9+8g8DD9WzanQ7F0oS5SQ7vMwLiuMex4/tYvTekVKwwjlo8eWovX/vq13nhVz/DN75yBddLcOw2U9UFPvnpw5QLiu4AKmWDMDbXr7XYt79CJjySeIxlFzh/7iZ7Fw6ytByRKR8lFEls4RhQVgYYBl1BeSpfqdiOotOKmJrxSVXCd755hg//wnO4hQFbaxUa07C5OaJayR3CgkIRvwD9JpQbUJAJUth8+5WED37AJ0wjSp7PzZs9KtUqAAuzMZYSvH0xZG62yuwMfPtbt3juI4v0mh7Li3Dn/joHl+ZY2cyYX3CwTMKte1AsjIkiH2l8phbh1R9c5xc+chjBGCcrEJkQz7ZYa2Ysz9hkysaYFGk7CLKdoPPnf/EKn/nV95EmRZJUIJwUKTIcJ6C7BaMRHDwCqYpobXYoleYpFSOGkaZWsBEmHyvv5hJsczpWVzzCKGN94x7vf+4AvvjpXUQqcuLcVk9QK2cIO1/4GW1hWSHGyNy21Sh+/Pot3v++PTjaQ9sW7bbAq2ZoDSqbELatDCm8fFtqWYwGGbZjIbShUFKk2iMeG/yCoWRldGOD41pkiZVzj4RGK6h4hs1OyGw9AKEBRSoMW00HxxFoLYkThWuHLNQfyJq/Oz78VOyY3Pts1+pfC37uFNDftwg8Z4xZA5j8nJ30LwG7wez3J30/q/+nmhDiN4QQbwoh3mw2t97z4Nv/8HcLSkllck0MIzA43LwS89TTdRoVqFeHlEsZjWqKMODaDlLDTEntELWSFJ59pkaS3OWJJ5eYmR4yaoLRmtOnz3LxzD0unL7HVEkiJlvYbb2S3ZrqcpfH6vb57sZnP3S9u2Z1g0QGcGivoL1uoxRcuqQwX3gRdfIkG7/5u9y6HhOHTabLikv/9DcZHz3B5n/6G6yuhnzkA88ztQSW45EOWuAOsBKFUvCJT+znO9/9Gn/+l39KqSzY2hQUSxaOZzNVnaJaiTl9OuUv/uXbVOurzE2N+OD7Cxw/bvPECYdnTiXMzSjunXuF+zd9hHBoNMas37dJTEw/7FCZmmY4yq+9HAj2zh9AKcUoAs8t4gY+np9D/4qFMSpO2X8EZmoucZbS7sOTj7msb4yQQvLXX7+HyhJqVYv2vXX6LcFa8w7nz2+QqgylU9JsTKM6z8baFuNhSJpmOEFKpz3kVz77BOHApz8YE8VDTpxY5urlHvXaI5w/3eLYsQPMzM7S75ewywX+1z9+m5QEN4DNtT5pmvLIoRqO8Gi2Q7pbHhbw7NP7WZ4HTcSon4G26LQ7jOMBaWIYj2Lm5mwuvn2Nd35ym7e+dpqCWyRRQ6JuwMc/tUy/LzDWiHIFtElwdBGDTbVaxLZAK4VfhlZ3i9feaaMRHN7vs3pjBIwZRRH1cpVyEc683mJjy+P6Sv49alQTHBnyCx9eZjgImZmF1Y0ejfo84yyi0oi5ez2iF7nUKy79LZ+/+caXsP2YK+e3OHliP+MoZqtpIW2Nb+ff3ukpARpsmWJsD0tnufKucRAGfvXfeZ5Ml+g3BeXyGFc4pHHAeBQSVDp4QZfWJsShz77ZKaYKCk8H2BS5fqO7Mw52S3Fvs5htBMvLCX4QM1U7wDun2/QTa2cMbTfLGIaZi+s73F8LOP3OBu22Racd8v0fbrCx6WKpvKj7+KlDIB2wEnr9DMsDF0kcWjgTEIeFSyASlAKEolyzKBUNlYpNFHuk4wRDgo4EmZH4rj3ZiQhsV5GEFkmYMUxt5uoeYxUhUEgtcYzNwrTG9zM2ViWDXp9rF2LurbkTnSb90PU9AIDIBzXGbemYST1g+179vO3vuwPoGmNqu/7eMcbUhRAvAf+9MeaVSf93gN8CPgp4xpg/mPT/HjA2xvzR33bcd+8Ads/0wrCjfSJMvnUU5DNiisATLhASiwyPgGbTYrqRIcQDuvy7FQqRgjSVWFaeGnFEitYOeXIp21FlfCiFIx4+H6kfFtmKRK7LAuyIfUXGYEuPLNR4Qbqz8nntbZtHT0rKXsSFKyG9Xpk9eyxm5oaceSOjMVdECAvLSkjSAYszs9y99g6RnsX1C5x8tERiJPfWI2xdYOrVL1P6w8+x8V/8t1j/1j/FKUAYZVhKkWU2tfmIgnJILBup8jz02rpmbs6n1x8AZaqVfOczHgUYldDtaerTEHgOmbIwekg4KLG+2kTYKXuPFLFUlUJRkKYCpVJcv0M49gmCMuubikpFk2Q9jLawrYBSySIKXTxbM04kOoVrV1d44tk6jhJkKkCbkC9/vctg1CeNBEHJIfCL9HstZmanCaMYSxYQQtNstkkjKFcC/MBCWg5GuzSmLA7sL3H3aowpdJmZrnDmnRU21jdZWlggRaFMl//g330SiYU0KVq49AaGYrnH2z/Z4oknD2NEwnf++hKfeeEQb51eYWnpKKMxYHVIY5crV+7zoV86glKSy++Mefp5jWX76NTGCSKSxMeWIC0FSDY3BH55TNgpMLUInY2I2pxPlsJ4kOAXXBwLcHtcePkWtT1PsmcPJFm+Ui1XU9453ebEiTkUMOyB0eC6cONSn7n9Bt9zIfUp1xMCz+H0O+scPTHNy9++xeEjsxw+UiVRmnCkqVViMl1GA7YBR+aLnW0/AI2bO3rJhF7o5ogZe42tFUFj2SFNbNJxFW0Uly9c5NHHHqUU2EhPE4UC1xO4MgcmXLoCl6++wmc/8wEQ2c54fvdYEgYiI/CkoTt2qRayXLLkRkylIum0JY4YU5+dplwG6ca4xqM77mNbPkK4ZCrFKId+7z6YZWyvxexMkSz0sQJIkx62JVCmSBJZOH6Uy0FkVi4T7Vucfes0R088QRY7eC54QUK75VKr5yig1npGbdrmnbcucvyJx3CkxHEyMmOTxmMqBYmwXITJsw7a5No+QtokKuPS+Q327J/HsiyqheQ94+LuNI8RkCJ29IC2AST/usXgNiapHyY/Nyf994E9u163DKz+Lf0/VzOCh4Su9EQgS5sHQXx7hW3IVRATDM0tlywrgkmZmUqR26QT8XAg335kxgFbI0SC1ApjbKQwaJG7Iw13Mey2z2k3kiE/F7mj1qckeLuuI9W5+JQwHmSKl19vIVIHJSXX7llUpiUFL+He/ZRxFKP1XdZbAjstU2nYpEnCoT0ZVy5fwJIFwjEsHH6SPUcqzC+W+co3NnAtxb4Fw/JyRPGffw5x5izT/9MfETR6KLFOpWJRqgmcb32J4InnGX75rxgPEsYhtFoCx8sYDVuYrIxrD2h1M1avW6hkhOsbVu6sIbKAJHaw3ZTbt6AxI3n8iQaPPdbge1+/hrYMqJgsU9gixVZ1SFyGHUHRM/T7kkDO0Kg2qJUCXvrLFS5euI5SKaXCiFIV3v++WURSwLIcfCcjMy5pPGZxscGRowsEnk8cD1Bacuz4DO2tDtMNC9uzKJfLKGuTOOkSJS16vT5x3GLldpPLl29jCl3u3gy5cS3j0KHDVKpT+MWAwIGTx4/xwx/ZDMaCTEi644jAN2Smxqn3HcbxwHYNzz1/DCM1R08sEVQ0S8uwZ6nG4p5ibmQfKFypePwpg3FKdLpJXjdKPMp2jGvHWMLitZdXyLKI9oaPcDO+9VeXqc85dJvg2eAVHKQNSWKIhjZTh4/RbMNoDJJxHuyMxfLMHGffjjj9xl38QohRsNFsUZ5xaMy4lKsBxekYjcVWS/LYkzNEI5fGjM3BQ1Xu3onpbdhsbY3pjnLDo9tXtjh7acQPXumjhMvaqsNQ2Xzpz94Bkac/q4URrhVjdJVSeRZXlXFMFafQp1CwOHB0D5ZtY3kZYRLR3MxIYsM4kly9MWbfYcVnf+V9INKdcbS9o95d6FQYfJEHOE9EJAJSPBYWKpQqDlP1AvP7a6QpbK4rXvmbLS5fXsUWFSzh4jigYwfXj1henqc7uMPZNzOarRQZJKze6RAlRbDzoGtbGZb0kXg5Es1zGQ8NR449gVY2gQ+pNoxGLn7BkGlIFVTqLuPQ8OjJEzRKinIQMhgoxoMIyy7kvgI6fcC7MAolNUrHCEtTnytieRrLU6xvWjv3BHbl/yfxaxvw4k52AwiRiwj+v0B2/n0ngK8Avz75/deBL+/q//dE3p4HepMU0TeBjwsh6pPi78cnfX9ne/cKe3vHkhNu9E4QHioLzDajTpLGCf1wQPOuxExs+JR8MIFsa5NsF5SVBGliLHJVPSlzyKU2AmsyvRTFgwq9nrxu+8upRR7gNWonN2cm6nzaGDIMtpAIYXAszWtnuuyZm+HuluSd84r9+0NKXp8ksWlM+xScKs8/t4dnHoMwg4U5n30HIoz0eObpZ9i7x8V2IBlCwS2BkvzyP5qj8ydfRj/2PK//zr8g+twXSU88zuh3vkg6dLDlHN12QhQqpv7oDxBnz2P/d18EKWh3hly8tEGUZPiFKSpTI4JSmbu3EvYe9fGCMloFfOAX9nPjRoeXvvk6rVWbmZkKm5swTBVr6wmffOFpVm9njFMf27WwvYBEOzhlD9eHTtuhWo7wCgahQZPwjz41y6mnFrGchDhycIRhGMFgBJnIiLXFt761TmOqgoVFrzsmjroszc9x+PAily62KZUKXLqygi0F0lIcO/I4rldkduYwaZyx90AD2004fnw/jx+bIwzHbDXXee21tzh+4hEKJYESNo5bIotHtJoaSZfBhuDN1y9DGqGN4sLZHhpNUPG4e3fE2v0Snj9iZXXMRnPMaDRk7/4yr/3wNCurMbbtoUIoFVxcG+I0ZpB5ZECrO2bfIzMUXJ/xcIBRgulFi3FPkcYw6MOF0xvoBAb9mCwqsm+PT60woNcb4xRsun3Yaqf4FVhc9qmV5xgPbApVWFyYYs8+IAswWc7lULFBWjnXxJEgUoeoJ3A9wyjUVKo+KvG5fmWL2vQ0tmOYmp/ipZdusLbeot/M+Ow/Ob4zFhNVZBBZrG+OWVtP+NL/fYMkAVSZ9Y0tCn6NW9cHrK8J4kGBxkyCaxuUdlneW8CgeOvMmDsrHhq944iWoncgz7t/KgyuB+gUDDSbEZ2W5MbtW6g0T9tEccpTz80T+IuEUYSwE4wYc+VSCxuPjdaAhfkpDh8rM1UvQ+KyOF+kUVR0Nm0CKyNDEIUJWRJRnlKMYs3q/S6WLXCtDA20tvpEUUq/HRInhjRKsV2F72iEMHT6kkESUG94OLZPd7NFrO2JquwkrgkBKpd7wBj2zhYw2mHYgTjJ0HISZwSEeluOfKKrtMsCcvuRx5ifPwX0d04AQog/BV4Fjgoh7gsh/kPgfwA+JoS4Bnxs8hzg68BN4DrwvwP/2eQE28DvA29MHl+c9P3cbTvnZcjxwpl8wD7UxhDYKcj8C5JpsGyP06+47DmokDKeyM2q7YuCyfsyHijpbTc9CfTabPvGPjBj3j6XHaLWru2YtCeG5NuvkwItzE6NQQiBNoIoi5mZmSJMYX5xk2pJceHCkKmZgP5IY/uw/6imN3AI9ZjX37iN6wmaa4Jmb51KLWTYd6nVQTohmTWkNt0Ha0Tpn/8+3qXzvP8bf8L44y/Q/2d/QOEPf5fwz79MFucaKe2OxeZvfpH40ePoP/hDMhzOn73Bcx+YYX6mwnAMWy3Byj04cNAmNgNGXbhybYOLlyK6wxYf+YVnKNYEN6938OwIgUVQrNHqdlhY8ojiIZ1ul1gJlIbm1oBmN6XWgJuXLAY9QSoh0hGuUySKYuKkQKYtzl2IkK5Gm5hbN8cYy/DBDy2RpZrZ2QaFwKJUq9Pvj2g2O5RKgvWNFh/52BFaWz2yVNPutihXfVZW7lGfLtLtdhmMEs6e3cSrDnA9Gy1SKpU6nVYbx05IYsPduz28YsqZc3dpVY9RGgAAIABJREFUDwvM7DVoMc3KakR3qFlcrHL3egBOzJWrDksHEuKwTFCwKQdFKtWAJIaTTz7L3KyFNDZCQiGQOA7EiUN3sILNCChgrCEb7YRHjlcZdiPmZvfTa7ncuXeFcj3i8NEGW5swHI7AVXTakEQp9+926DQt0iwmiz2azZRzp0/nmvdCkoYw6MSsrhjeOXOBREdsrvbpDRI212D1jkem4diTS2y0BOVagWIlZnPVR9gjSlWPOAJPlGg3e+zbu0yhmFKedhmkLu2OoDVMUQLu3gDbTCHsEU9/5CAyGGN7mtn5aYRI2HNIUK4ZilWwHR8tBMVCBFaKL12efKLGwnKbDJ/b97x80WQJjBQ7nrlqhwgl0ZbAEhJXZhw5YLNvSfPB5xa5eq3H/FzMgcM+lXJEUBuTJT7NdYvOlmL/0YAk03iyjuNpMiUYhQrpDFEO9COoTvl0Bi5BkIMkkC7SSjHSsLw4TeDBOM6VXuuVMo7jEFQKOa9BuWSpIVEuUkpSpRmPY9odQ2aNKVbqCDvbkfnWk+sSQpDu8kFQSlGZspB2jNEyB7dgsGwzuQMCJjyhXEQklw7XQhJn6Xuyhn9W+wdPBNtWA9UTogPAenOT+Zm87rwb+7qNhQXJd755ho98/GTOyjXbKSPzkIz0u6/dSLGjqZKjD0R+ZDMR/UL8VP5t9ycIISbU2/xY25+X/9FD64SNzYjAA0kJhWD1VsjCvgJn31nlyfc1qJXHrKz6hCOHXqvJk88vYDGgP6igVMKFc7c4+shRqtMZV863Wdwzy0wDfvDyBQ4/ukj5uz/E+8LvEH3+RbLPfIrS089SuHqRdHkfplJj8Nufw/m1zzIcwtradZaWlmjUIYkCXD+juTUmGlSYXQLL7WERsL5qQGi6zYCDj2gUiihMuHu7TWNqgcV5G2kBFrSaMa5r4wUwHGbo1OKtN67xkY8/QuBK+j1BsQrR0OAHIudmxHndZTRMcYspjinklsYaWi2I0yHTMyWam3D7zoA7dzfBAs8OKBYDut0uS3vnuHTxOtVahTTReG5AoSC5d3+DudllPvChBt/59lWS2DDsGyr1gCRLMJnA8zz27PcoehXOnV3j8OE5+oMmx44sgzFUahFaSWbnCqQKXAf6/TEXzm1QrwccPFLH9gTd1pDGdIBSNu0Nh5mlEJF6pEnCxfMhRx6pU66P2WgOce0Z0iSXqLZsiOOUO1cjUhFy5PAsSmv8ckoUGizhc+t6zN1b7/CLn3iCe1cT9h2t0NlUZKmFETA9r4hji2ikKQSSdisGEYIsMTWd+yOXa5rmmk+trllf1Szvs1hbHbJnj0uKg1YhnqXp9l2iUUJzw6JYKlAsaRrzmlvnBhw6XmdtLWRhGW5c1HQ6A/YftZhtzKBSWLsH5bkRUa9IUI3wXZ9h31AsC2w3ZXMjplYuUS3mftWen+L7ihtXBQcesVhZMZQr4BVCrl9OmZ4tUi76FIJ4R03U5CIVuLvWr9t4eD1ZuOWyCIaNjsNUQxHGmjTyUfQpuRWMnfCD713lmWcfI/Bhcz1hbs7FDUIGfR8hBZaISDMX383h5FpZVEspo9AiSwXFsmA8SslSQeBJHFcwTgyVgkJgoU2CkIJuT5ImmtmZiT8zD+JGZvQOUxojcY3h5m2ozxvioU2WhiwsODuxzd4tnTFp2zukbW0lYf71o4D+P2+SB25CCzOzE/GoB2JwD+udaz76ycdzvfJtxUGT1wkiJXeMLbZVDNM0RU4kc7eD//bn5Cv3B0F/d/AHdo4tt4O/Ng9V53eayeVfvcClVCtQCCQlL2Zz5Qq1KfjoLy9SLfoYJIuLBQaDHs88X2bQEWR4SCdkPHZ55gOzzM310WnEo8emOffW92h1Up754CFUZjP+2Kdof/8M4cc+RZII3njhP6J74CgA7sUzVP/HL9LqdDj96rdYnDtMo5zLLI/DEYIYL9AU6k3iNOHKaWhuZlRrHksLin1HutiezO+KKLJ33xy3b9/Ec0cgMqKhoVy1GI46RFmIKz3qUzaf/NQBbDfKB6Y3IFVD2p0IQ8q3v32bcxchSxRTNQdpFYgThTBDXDtjZk6xuOzQasLCEoTjEct7FliaX8JxYXV9DWk73L21yuEjj6KUIk0Uw+GYdqtHISiRZmOMiYkThWW72IFi774KywvzTE3b+AXB6v2QwdhQn3IxwiKKQu7c72AHEqVK+EULx1WoFKQMOXNuncefPMDREw1sN2PUdpmbqRHGYT4JehmWyQXISkWf5T0uSg4Bh7mZWa5eXmV6OqXbHSJliBskzC0XOfSow2AImUnoND3iKCUKYXbGY//Bk3z/O7c59lgu9e2XNEEpplLNdc4lUJ+W3L3bYX7JozZVI4slljsiSSThwGfQWeHtN+8TeDajgUJnMBp6OCZk2MoDU+C5XLuUcegRn/q0wg0y7l6HYazobrUpVTUSyd4DRZ56dh5UnXEEo3jIMIVoYDMah1y50KLd0ty920YrGLYlU7MWQSHB6JxvYggRxubwEQFGsbSomSpb+JbDoyemmJvyKQVjXnll80GgJOf4CANbgxzVtz3ahBA5+x+BERLftwgjB0v7FEsG1yly43qGkA6PnzrEOBwwHHdYWJxYTQ4DGpWUcjGiUADHhcwYHKFwnJReX1IqKDCCMFJkqcCyBEExIlUCkRnC2GEwVvT6NuOhjWUJikWP9pa1k7HYTg/vxBUDhlxLqDYlqfqGuWlBpsQO69dmF9Jw1zXvyEPnhh3/alNA/5Ca4WHdEJjQos2DGVWI3QbYGqOzB++XAt/SP7Xyd103zz3KB2mdXJc9X0ls970XFnf7HN5tipGoB8fd7ut3bWaqGX/5J3/O17/8Y771N29x4MQSWsHVy3Dt6ggoItA89VSRKI1xCnDzksL3HBpTYFsOUVah7DucPXOH+sxROi2HMDSYrEyxbCOFRZq4dJuGpf/yv6L/o7Nc/M9/i8GhE5z9J/81ruvy0Rc+jnRgnAX8zXfbdNtF3n6rR+DVaNSKBK7gkZOCaq1A0YdW18UPavzk9XXSUICVEBRsPHuOOHPo9TU/+sE5et0Iy64TD6Fci3BsjdYerWZEqz0iSy16XR+clNWNjI9+9AgnjlsoYTFOFL6EV75/CSyHft/GYJHGHv1+G2Xg/mqPcNhhdtZnNI7Zf2Af040ZPvzhw9y6cYdiuUCtXqJatSiUijQaDRZmprl0vsOBfQcZjyM+9ssn6LV8hoMxluXQ3OxQqVtoFTE3t8Bms8WTpw5TqRqysWRhD/Q7AqUtnEKbXifmQx86iGWBUi6eZXPl6j0yRji2TzSEctEmTQMQMVk6ZmZBUigUUMbi7JkeTzwzh5YOC/M+a6sOl99pEyeCwK4zPZfRbLZApjhuAWmnFGsKlQo+/aklxpFHe+0titWIUtVjdW2L5oYmHuQG6IWiRa+vWb0b0W0N2LyvKZQMN2+u0RvBU+9foFQzGGPjBR62gHHsU2sUQSvWVxKefLaAdAzlqsC2HPbutzlybJpumFuZjiOP8Tjl9p0W1y5exwraFIolKpURqxtNvEDy9LNL2Eoyv1TDDlqsrm9y9eIW/b6NthSrawZBhdsrKbGISfSk6GkyBgNJHMGdOxlXrymeer7B2n2XVCui0CFDg3BprkraYxcm6V2DTWY0scjNgSwBjpeAhHY7RJmMA4/YRJHAEj7VWoGrF29huzaFEmSxodnS2EKy1bImtcYMyxMUfAdpCQyCck0T+BYIi2JFMegUsKXG9jVaZ9iOxHYsYp1hSOh0Y1xP7hC2dtRkd8WrbfWCtRXoDiRbLYkwOScgn/gmNpC74uFDjnLivTMbf1v7NyYFlGNf9QOEzSTk7xjDGLNTQNrGxFrkOURH7yJoCTA6Rkjvoa3UYKypFB0yk5EKiWMeyKoK9LuM2H+awm5MBsLOj2seJoIp8eAf5WqHuysZC3tcbDVA2y4bXcFCJc/h/fD7EYcOlpiagY1OzPKcx7VbfdbXXVyvw2PHF3ADGLYjqtM+mQlJwoB4CK1uAsbm4FGDNiHtVoCRPaYbguFIcv2S4plnJJHyaG8GrNwZcfJYEa/UIzZlPCcjinJ9lwtnOzz9dJ3VtYSFaRfpQSLGtNclru0zCntE0ZiZmQXGA7h2Y5OjR2vML7hYGax1OzhWjbX7isOPGaRy0AZcJ8Ey0BqkpOMi1Vk4/eZ9skiw78AS+/aEoCVjqUkTQ9IvUJge4Oky/a7CKUd892+aNOqzIAP6vZC1lTannlnmxq0VatUZmlvrFPwqa+srHNq7n3q1wPwirK4lnL1wn1LZxbcb3FtZxbYThFVgbrrOVnsTyzbMTNeZXyowbI859ugMr/x4hY99ZB7XsnAKAyxRQCtJtyOoT0OS5UStXj/fAU5Nx2Qazp8XPPuYxdXrNvv2CTqjEZfPjzh1qsL6hs/hw0MyU0KIFNs4rDU7+F6BUT/AdWCUxIx6hiOPelw8u8VjT0mGowoCm9tvvsHBZ08hZEbBD9jayLi3soXnwez0PHdujTj5XJFxD0bjlLOnb/PJTx+h1xpj+4V8PPghPgpphwz7Zd54c5Mnnl5CKgun2MEyNkKWcd2Iqxe6zC03qFVdrl0YQlqi5sH0ozkb1yDJIo1fdNnaWmVudhEVQnM4xHNK1Btw62LGo48aEq3odn0a0yECQaodRj0L19OUChlZpokTn053jOWllKuCsl0gYYRtqmx2m/h+hVE3o1EPcPzcbKlc7DIc19hqZoRhwmPHLRIiwlEVO+iyeqOGNoZoLDj4+BaWKKFMxqDlU29IUj2k6Hi0BymNconeEGxLowkp+BKJxXAsCYoSyyR0ew6OCzo1uYicA7btkZLhSAdpQZjGZKFHEBjGUYoUDvVKitAPDIt2YomReNqQKodRIggKMBhqbly7zLNPHc5fovSOpagAMgFy8lm74en/v0kBPSBKPfD+1RPMqyAPttt5921TmB2Y1C6g/0McApmDM7c/wxhDuSBzGVcELmZCQMlz3+ZnBH5hII5y+JqYSAJv5/jE/8PdmwRJlpx3fj93f1vsS+577dVrVXV3dWMhCGIIAiTIBoiROAeZRlfpIDOZDjLTYUzobsh0lDQH6SLTRaaTNLSh2GgQ4ICkAAJooNFrVXXtS26Ve2Zk7PFWdx1ebFldHIJmMhuCblaWWZERHu/5c/+W//d9/48+9cP4vQgBxCwtgmVCkC4mMdz64DHbx5rHuwEr5xSFChw2NDNzih//9AY337vN5Rdc8jmXtr8PskO5EmJ0mxwZvKyh1dVcuKC5ffcWSZKghKJQVExUsxCVONp2efG5KlDGkhmaxxFXr8Kf/l8/R4gS+7sJUeDgeJDzDLPzinYPcuUI6UEUBzgmS5T4RDFsrQcsLs0Rxz7FCrz8aoGMFdBtxey061QnPYqVHstnY2yRYFkQ+iASSaQdqsUc5ekAJQ0vvzTBMy8ukCk2OWpI/MDll3+zT8ZRXP/5R3SOHLphh1pzD89SfP3ri2SzglKxy9JShmdfXGTtUZ1MJkPr6JAk1jQbPf7lf3qO6bmYTOGITrxHLzjk/MUqr7y2wObWBldeOoeQkk6ryer6KmGYEPQsNtZqPLjf4vzFKX780/tceWmBUslgJCRxgU8+2cAIgRA+Co1JLEwima6kDXQer1kc7ObYWV+j1k6J4h7v9XCE4fJLsxwceDzeusVxvcjDB3VUZIEIcO0yXi5hc3MdrwCIiLkFj8QkFCsVLAQ6EHiZBknORgmbw12DJiBb0kxNzTI9PcXkTMyVqzmSKODmp/eYnzd8/RvnUQa6PcnRYUQ7rGG6GTIyS6czged5fOV3lqmWehzsHSCjCtLtcHzU5O7NhHwxhyDGNj6T03kmZ6FpH+MHEUoaek2LT2+scuvGOtXKPKEPzW4bEonnQqMGE7OCBJs7N0OqFTBJhiAx3Ph4H9dLqB1IgsQBS+G4UKlkyLpFslaGg5qFSUo0uzG5fBHHiZmedsh6EswRnW5AoyvI5WHhtKI6I1hdddnfLZHJQv1Isre/y9SMTlNCowKdtoPUeSanfLrdHo4q0A1dpgs2xvhIATqRIG0coQi1Q+TH+F2BFA6Wk8YCwiRisuQgbIGxEpSQRDrCIkHh4mQieh2BMBqTQL0pESLtISC0GaWi9wPBkRII3cYWIVHc5dWXz43QByVPwj8mzSASQgy7rf1Dxj96BQCfLbwa4PkwXkXL0K2qtRyEECgt+zwZT8HE+oyEDHg0GLWVHLSx033PYRynG+fiMAIczz5JRzH2M837H8FDT/O2hJRkCilny/KMzcqCopgPWZyJcUXCVPU8c+cXcPIhUrlMVStIJImxMHEOX4BlDHPLBoHH668v89Mf/JReJMk7IZGvOLr3KXOLNsdNTUKXdhOWz9ocNeBf/he/BQpWlmyMBElAnPSYmSvw87+9SyWfY+vxLlHocuf2Md22oFyFz3+pjOcFlKseUdwlTiT5qQKNRsREqcz2Vou4l+XWzU2iMK2kd52YRMZ0wy6J9jk+spG0iGKHSqlNY0dTcV1++JfX+K3fWqHXNXzxD19mouISxTlOn5pn/ZEHRvHCiy6lguL+o1V2d3Y4e0Zz9WqV1789z7nzc1x6sczqo5gg0nzwwQNazUn2DxWYHg/vt/Eyijt37jMzdZbf++olyuUK2UwRP2gzN7/IzCyECcSh4s6dY+qtLlEEnuPz4gvTNGtt/NAD08GyJMIKuXkrQpuY+SWX6vQhv//NZ9nb9uh0DJ6bY795wO07xwRRDy87y9bjGvNTFeqtmNC4OF6MSTwWlxfI5I7RoUs2B54lsLMRn9zqkikIttYcHj0sUXSgOmFTP3bpdkJmZ6EyEbO7ZbG7E2EL+PKXLrC3F+PIhDCBlQWPs8uGaimPl0+IjCaX8zEixAA/+2mXcrVMs53giDKHexaFYhbLTmE1KxEUJyPsXIfZORtX2niWoNU5ZOXUPAvzK8QhZL0uxZJHuWxx99N1DnabHO5G1I5gbsUlwtDpBuj4iNnFIq6nkN4uOgaJRbuT0GgfoOwmO3sJbiYmNB2O98G2BSLJYSmb3VqPzY0slpNgqzz1ZsC1Dx5SrsaUZmKmpwLCqMP6w5jnXpjl+o3bnH6uh6VcMl4aR1hbbZPLW/hBE9fVNAIXKSXlbEASQcVNEYWs1cHJeRihefAgJIkjEAlol2YYo5SCwKB12pu43tJYwgdj42YMluMSxz7NpsX+cUqhYVSqDAZVzwD1IygW8ggDlVL+hLx4moAfyKxBgsrB7t6/V56emO/Xfud/wPEk1w70+2aOv86oK1ipMGi4PaiOG+HzQ4EuxTCXOYWUrOF7BilVSmjApLxCnPQAhhlAfQbS8Q4+6ctpTu4AipIm5fT+DPsh8IXXzlPKnEzdMv0vufSi5AuvTuMq+PDdd7n9acRP/nodT1o4KsbVIYoYjxhpQiLton7wt1gXrnDvf/xTrl/bJX/tPsXPv0zmh+8gASOO8Gwol3PEuodMEq6/+b8jX3iRnf/1e2xtSZrNiD/6/XNAzMpClUI25Jlns1y84OFYPpi0FaKQAZNFxUxOcO3DNTqBQmnoNR0cN+Tq1SWyTkxGgY4tmi0XR1kc1SxmpiS9bpF8JiQmz5lnivQ0vPrbl1E2lLIejg17tQ45C9rdgFNnQVhHfPzBFoWCx7f+8Aw6ERwcGH7647t0/A6PHh6grIT1R8dIU2B56RJrd7f5ym/P8NIrc2yur7Ewe5Z2r8H21gbXbj7kuRcXaXcP6Pk+ewdruGKK29drJJHPhdMlytkingURAUJJpCvI5zoYCkjLx28Znn3eJp+ziJOEjJUjjiLmV6A6ZTE1mXB+boWXXiqxMGv40qs2s/OSRIRo4RL6EZ4DGddiYgbu3tRMTtrEOrUa/UaGCxdL2FKRy2V55XPL9EJYfVSj106oVLPUayBJmFswLC7Y2LadVvNi6IUKR2m2DqCrJSZx0l7DUiDI4NgRnQa89so07bZhdlbRqnnMzGaZWxCUiob33j3m9mOXnVXJ5pom6OWJdUwvsMm5kywvFpidPaaa62BLD2Ms8jmHi89lCZMeXs4jiCBfbBNHgkLB5dqHPnMzEml6+O2ptJBrP2Jvp0t1Ik+3XsJ1PaKehStyzJ9uc/daHaN6xKFhumozP5PhvZ9sE8YG2xHYcoWNhzFbq4eARCmXU2ezVAoBX/ziWSzjolTAzmYd5UDGmUGh8KwCG4/amASC0GGn1iU0mgerhjCQSBx0pNnfbHHhvIBYUChpHM+gJASRRHk2wiQpNJe1CRMHkyRpAoQUZDIZFuZgumqQRGAMQicoPSKXnJ6E4yZsHzgcH4zk3LgRPE6DM0xE6f99dnb21xOs/AbEAMb7ATxJ3WBEqsH61NpDrD0tV0+DuAkGR4vPLGBsdAoZSYlEkBiQRhP1AylCK5J+YOm4YZPPahKjKDpppeCTVBTj16WHKgeUFAOEirh/LePXD5D6mqOYhhy7TvPEa+KJeQb3pSVgJD9/V/Cl//JlxPXr6EuX6b3/Cc5LV7BvXSO5dInNH77PzJzDzmNYXIDafsTsDHD5Fbh+g/C5S8gbH6H6BW0wKsk3pGtsM7zctMfB//MOvPFmyoj6rde5f99h/tw+taMcM9MWGpfdzUPuPjiifWzzzf9omY3HPc4u5mnHBhNLkh4IK8bJKkwk8DwDiQ/9Mvm9I4tfvn+H3//GErc/jrhwGfx6mVwGsi4cx11yTpbNRwfMLk2RJBDrhKM9RUiHTjNH3tNMzUse3g/ZPmiwt5mQz4fMzC2zufMASYZOq8fElE0cO3ztq3Osr8Hz58HJw/ZOzPIc1Bs+UuXJZntoY5EYBdIQdTq4BU0UlvH9HpVchmYbsvkO3XqOWjvCwmZ6+RhHlFC0iZM8QSxQdgixy95+m0ymg+1OIxB8/P51XnzpGdpth+lZUgI0pbhxo8vz5wpsHfYoVBP2txSuZ2Pw8ds2kxMupZkOic4BIQVpiHGotwT7+0eUihPkK5r6viSTgzju0WxkKFfAsqF2EFMsW0xWanSCIjlXc+d2zFTR4ajbYflciSSAvNcjTEIe3O1y9pk8GZmhG/vcvRGycrpKsxtQnXRJTAfPtek0HYzWTBVjam0HIffJZCa49ekxC+cqvPfjn/Hlr34ZIQK2N7rMLlSJY0MYaKanFIcHsL3T5szZDNWcwOiYh+sOhRJc+3ibS1fmyU/EPF49opibYXK6B7gEnTaOlwUp2Ns9ojo5jWWnVOUyKpFzInZrikJe4tkhQeKggFBDvbVB3ltGWYDSRKGEKKFYSjN9ktCQK6Rp45bjEyYxJiqShBD2WmRch9gVKXleLFDKZ3ejxsqFCWwjhgknCQZHQKITjppdlKlSKacsBEqPy4yU7ywZN2D7sYDBmfz/rR/Af8jxNDZQeLoygL5XwEhgCQOBMbiDwi8MyogTnzcCYgRWv8wsMoN0T4MFxAkcHKetAQuuAK0/a8WPRd7HPZU0G9ik3obWJOKzbKDjn3nq6/25pRkVjwwC0uPCf6DcAsB65y9Q/92b9P7Vm6g/+Ta/+G//Z37nR/8H4Xe+i/nWN9jcTFhY8Lhzt4VrF3juQgxvvw1vfgfe/O+5/cy3aR0HvHxVoGyD0Fa6ek8oBEiVgrpyFfq9EMRH7wMOPikj6a3bdc6fK2PZCWESkrMcMDEGQaAjjMmRlTHt0JCxQ7TwcGSM1hEaF6MVsfTx21nKRfjgo2NOnctwdKBYXkkIA8H2TotTK5MoBYoIYxIs5REksLtTJ1+UlIt5dg8kvZ5hZkbw8YfQ7jzk1dfO8v3vf8KpM2dZWztkdfWIr33teY4OHtLtzfIf//MSP/rRXV7/+jPUWmmaXjZviI1GaUOzLShkM9h2iEGw+vCAM2fz3H8U8+yZLL0YHCvEGEm3lyfrJQRa4VnQ6YVkMg7KBGjhIIkIYwdt9TjcTze0kJJKQbK+YdFsdblyJUNGhkTEvP3OJhOlGWZXYqYmprBsTRBEeHnIKZtW0GXjUY9Tp6oUMhEmtjloK9qtY7pNw+xymW5bYEyLKC5wbjnm9nrIMytZ/uqvfF79ogtGclTbo9ORhNpw5bkMbb/Arev7vHC5StFNSHSPXuCwttnj3IU8W+sxZ1YMN251eOGZGWIJO4/rzC0opM6glEDj0+jkcFywZI8ksvHshJ1DRf0wolDxWZnJ4UtFkkSsPwjxcjELi9W0QM3ROCZEGof9XptKocBxXRD6Kevo8hlYX4WzZ2K2tmIWZuHuQ5/TpwrkVMJeI6RSzoCIcbAwJqZr3NTrN5I4Nri2Txg7WKSMrp0gJuvZtNtd8pkC9VZMpaRBJEit/g5+MIM2FkIokjhBoLGUGTvzI+5TbVJYutZoo6wqpdxn2YafJvvGGYiHsYFfkwvoN0MBGJNGvrX5O4XlQPgbwAgbocN+5a0ZZu8MxkDwf8a1Qg4pJkKtsFTa6sKkVWRY/c8lRiOl7LdfO2nRjwtHgECnBFaQams1fi1SgNEYnkJMR6qwhtrdpI3rbdXPNDphEcCNO4ZabZeXXp7DJsTL2MTGYe3+PsvnCjz8+GNOvfIyu5se2PvMzszg6npqleg0jrGxG7I863HcskgUPLi1Q2VmgtrhFp97ZR5Ees96lIiQKoA/fwfeeCvtddxvd6llgjCSW3dicrkcNz75K+bPPseZlWnixGJ395DlZYtmp0y91uK58w6rqz5GwKllh9t3E5571iU2MY/XNblsjpmZkP2GolTQ9AKbTjvGUoYkFlSqFu1Ol2pZoLRNvd0hky3y9r9d54/+ZBolmsQ6y8YjQ5TEHB95XP08PLqf429+/BMuP3cJp9gDPYdt93jpxSwG2F3fY25uhg+u1/nc1TztZojrKZSjEdrh/Q9qvPRqnijKUK+HVCYkjoIotrBpoJTC6BxChSREKPLsH3SZnlAcHLs4XkQ+Z7OzHzE33aPbLVLbi3BKbRAOrcPrVp+/AAAgAElEQVQMUzOwt9chnykQJhFT0xIjJFlXs7fuM7uSw+/B3naIlelRrmboNBxsBwp52NzscvGsh9aSWAbUW4Jex6FYgP39gHLRRdmwvamxvQ5LywXCADIeKTOpaFI/LtKoxdh5i2LBEAeCXMlgAkFiumxtHnPm3DRJYHPtk8fMLWbYfNzlmRemyeUEInbw/Zh8wUInMY5KqHddhBXiqh6Rdim4Hp0Iul2fXgdmpqHZiEh0gUoVUD1UnHpV5TLYfUZe3yh2D2KW5xzQgkhEGGHjN0FlA3Qi2T+oUbBnyE/GeMpi/zBkZtIQa5dOL6GQU0QhHB3ETE9GJMKiVvNZmPXY3guZn7KH500YaIuIsJMh8kMmqyn8MpAFTwprgJ2aZHt/m5lKkcW5PMZoerHBb0Q8WH3Mq1fPfFY+pEIDI0/Kh4HcGRh+oezLuL4nAWD9U1EAgzTQ8cUcH+OWPIzapQ1SMCMDDpwQ1uPY/5NzhoDWDrYcZPcIIqMRpCRzg3mefBjpdwuENPiJxlOjFnsDDyES5qkewIn76VsE8IRSG6teFuJktN8I+OR6l0uXE/7s327w1W+epyLzGBnQ6NkUsxGNhkuhCO2epuv3mP7ZD4n+8/8Kow3Z/+1/Ifzjf87GKrS7HS4/m4c+A6QQ4oTiHdQ8DBSgFie7kw2uZzCkBr73F4T/6k2s/+ENxLdfH7IWDryZyIDdT7pd3zC4BZuD7Q4Ts0Uy+Zh3f3Kb5ZUZJooTSFcxUQUEPLi3y/K5MiQesQ5BShwMH7+3xhe+dJ5Ex4Q64vAQSnlFrqCw45hax0W4hoPdiNk5h6OjLpsPsiyeiZlZCKkfu2yurfPiC2eIrUPatQmq1TSjS0lDFAqufXSXVz9/EcuEPHocsba2ztzsSr8xTcj+xhZaHPGV3/0cnQ5IB+r1Hrlchlp9h0pxEun47K0VmFrxuf5ek3PnJDNzeaLIo9VO8HLweLOFY5UJogZzM3mKeUUvidFhSkimACV9erLH/kaFRCeUq4rQ1+SKEs/TrG8cMVMpUcpJ6pFF3u0RR4qDI4dSNT1DljQ8etxkbqHE49U6iwtlslkIej5CeThOj9Uba8w/f5aMsHj351u89tsT2CKLMjGRsLCNRgmf/VqA5VRQAlzXEIZgeX3hGKepjdNVATphrwGOa8jYMbZtY7SFjjsIJ8fGWpeFeYXtKIIEMiZGqHTfJQIso0AqGg1BIW84PBZks2mzlsDvcu3mpyzPv4KmzcLyJKv3NihVJliYz1FvtHCzLlEUUipk+ODdfa5+fgpHBTSaGbLFtLOu1KOeA6KfJJIogaXh0VaHxYUMzbrNZDkZyqMBXDp+Rj/6YJ2XXllmfcsnaAU0WnVe+txKeoaMwJECLSR2chJhGJd7n6WFHntf/6fut4T8dTuC/eNXAB/8cliENSBZg5Owy4ATSKT/6cMtMmX0lGIooFJmB3OCVgJASUmi0+rBWILQgjDQKEeRGBBGY9kSZXQ/XpDWCAy+X4p0QyZJgqMsEvrpqDoZXqcWILTBRo7oooVFYuJUy5MGcuK+4hooMkihJJ2AkKngFTpBofjLv94giWFy3uNgK+DCc3OcPmURmhBXeBwdJpSrCX/7s8e47gIvv2RYW4u5cD6DdeUV5PUb6bpcvoT5+P0hFjmwJIY0GyKFvmBUcZ0IINFYyhrCYqK/9v2HMlRe4spV5PUbmMuXSD76VTqPlP0yeIkxOsVCB89Xwv6hSxIEzMz2n500fPjBAVcuL9JLNG7mCJcKMT02HhWYmgtpHTqUJ8AksL37iJWlKSwni697uFaMTsps34fyNLg5A8rw6ScJL11NePTQ5syZNsdNGyEdOh2f6UoGywqQUqG1S2TAtTRGS7otKOYj/uzPdvjat6fBWCShoNVQHB50OfVsxNYjwdRkkTAMmZl3+OhXO8zNT1CdkgS+Re34gGp5Cj9M0LEgCQWT82marecKXJXQbOeoHYQExiHr+iwteBAFdBJBznHwTZPr79V5/vI0197f4ZUvnub27T1sOcHskqDXM0zPRoShRc4KgDytI8hPt/jVLxo06yFXXzvD7l4bofKcOmXY3/UpVzMEcUCl5BNHJba2m/hdhXJcth9ssbA8T64YsTyXJVJNLFHkwcMjZioTKGsQkwvxsoq4q9Gii5PJI5O0GjvUMWHD4t7DQ55/eRKlOmzcynDqYkTku8QSAt9QLcfESY92z6OaGxh3gii0kVZAr+vS6kVMVmKELXCxCAOLRLbxO3kQcNxo0qjlOPdsQM6Sw1RxIxyOG7C5sc2l5yeIEkEYgZt1iHqQqAYCj5wFiAiJw9FxQqmUwWgfrTz2d0OUpVmcFMR9w0gIQdIXxNokSGORqAi/49HzIybKLkqFaJPKrFAnQxK3J7N8RJ/hU/VNQzlmBCY6RSIGcUFIE04E/4QgoHEPAEbWsJGjxdL9haBfzSu0wMi+oIdhEHjwefpzJP18f2BI35xOmG6QKAaJ6Vffaew+Jj9SPnJYzm1MMnyAWpOaZkik0akAN2mmgNOHmcZdunFhP3jYRqbEbbYt6XQjMlkbKTwMAcKAbeC9XzV47bUqCI3uRzIG92ZkyjuSNtQeremguE2+/TbWf/3fAAb9r/8nxLdeP8GnMuA9gpQp1TJieK8DK2Mwxj2AARZ5ojL6z7+HfPO76LfeIPnWH2HEaD6EwugYKeWwgA7gzj2fre1NvvyVs0hU3/zSICxqxwHFsosyMXu7LuUJwfaGpjINtpUgTEwmk8FSKXGXVJpER+ysxixdyGERYYSicSw5Ompz/pxDZCw219tkszmkFFQLktoRrG20mFmMmZmz6TTyeC54uQ5RLPnev1njG3/8LF424KP3jpidz6FEnl6YkPNsnKym3fLx3BxRGNKsOcws9XAcj9BPs757PszOJehEsHY/YvmUy9bjHts7O1x5+QwSKOQ1m1uSbMHHEg47Ow0q1RKlosR2ekSJZPVOm1PnJ9je8lk543KwE9Fpx4SxwFEZzlwIULhoOhgExgi2NjPUj7pcuOTws5/UOX9hksODgHK+g3CyZBybek0hrBaLKwXiCCIN26sdWkYzmQuZLE9QKMXEOt0Xj1dt5pbSlqKRjgm6Fk62h+tk+PBXbfKFPCunEiRgOYqeD1EQU672kKZAqxmTLYW0m1kCH6anAowwBHFETrnEJj2DW1uKhUWfax8bXnwpS9CJyWQlSWJS2om2hbTgaH+Hqak5bC+VEa6VoEWEEtYwi88yAj+M8FzF7mGPmSmPGNDGJYpDHBu21hyyeYPrCvb365hYMztTJVPUSKnRYYJjCzCS0ETs7mXotSPOnbdBhEgSEmNx49NtMl6Zi2dLJCIAQKHQIm0fO2gbewLyGZNZQxnzhAcwzgck9K/fE/g3QgGkVmHfEuz/7UlIBEZeQdLH7bWOEdLC5YnsobHPjxMshToV0kKkVr5AIbGJkhhhNK5MlYHsewyQpotKo/sPJLXOUSPvQBuRFniItG+p17/GJxXa4IEO70UbdJ8+emvTIZOFShVMP3XMGVun8bnG2+mNK8rxDTP4fjvhhCAfb783GONWyfCexCADS6GNwXkiAJ7ed1pklwiG66sFyD9/B/mdN4m/+wbmW68PGVK3Ni0mqpp8NmLnwCWXFxzXehweNbh8pTI8EHtbLrMLAe1eRLctmJ7MkQAHhyGVqiSjLNABnUCDdmkcSSZnU4qEWNu0apCvdOh0bLpdBx2B7cQgYsoVL7VcI4PjCrZWYeV0gp8oNh5G2K5NtQLbj1Y5d2UZrRW21aDVzpNEima9xccfrXL5yjNk8wIvK7DshDgKyNj5lEJ4r0uulMfvaB7e32VuqcLZsxkMcHgUUi46rG8eYIsCCYqFOZusB7fv+0SdfZZOL+P7CRMzEbGWdJppE/mHDxpcvFjBtkLu3bex3H1MUqDVipiYyNFqJTz3jEXbt1Ai5tHqPhPzCiueoVDR3LoZcfa0y7Ub91lePE91Eno9EBqO6y0yXoHqbEAWl/t3H+PZHgtnJ9hrhhQzCmWHbG9qTi3miWSXD99t8swLs0i3Tc7L8enHXXJFG1uF5EsOSjo06hGNwzqXXi73jZgO3Z5D7OdZXT/i4sUJCl6IFoa9Wo+psocQgsNajDEutrKo1RvML+TI25pIxBztZ9nZPaZYkjQbPcrlMk5R4AoX2zUIowkDxcbaEZeuFDBPZAmOG2WQxrJishjTw+tDswkjmZnCURKPEUQTS4dmN8Fv9ZicsZEoIgMbjzqcPZXWGAzgz9josXMvsZ+Qx2n40Zzo+DU464PxT54MTghBkvQxNkZ5r+M/YSSgUuFuUMp+ehEXo5+Dnr0CcKRIhWei+6yDCYkJESJJ2S7lAOs3/Uo+NSSKkyZNIzVSkCRm9DCkGbGEihEP0TB9tK+IFOm/9fsOd2+kzbJV/8HOLwZUJkIQIYKT1vdgDBTJwAUcrNuguE2asfVBPjWldngtJsHqX48ynJhvnLdE65RMe/icDPD2Oynk873vp1ikEcOcZWVAfudNxPUbqDfeGq0RsLgoaDYMW1sutiOo12IMDrZrDQv/JIK5hZD9PUXOy1CdiEmE4fg4QhqH5jF8equGj0OzKVPiOgssC4LI5s6tHRLZpXUcc3gUMz8bM7MUoRzwHI/jmkHrHh+8t4MtYHouLWBbvd0gW+pw+nRAvuyzcOo07U4Po2PWH5ZoNXw6LYPjWXzla8+iRQRScO/6hySRS9gucnAgabclU3N52q1jpG0wVsTsgkNkeilXvXDY2tCsnM6RL3oc7B3xeBNi02J+wcPJLtPuhnj5FvVGhI2F0IqjA8XF5yW3rz1AozlzTmBZFdrtJsgetVqHxVMujzZ8/B5sbBhmZ+cJWha5So/6Ucj0lMvGY3j56hmm5jSeB/lSl1j4TE0VkDLk+MhHKMjPTFFr7HLj2g6esrl9PWZ7TXB80GN755itDZebN+9TKILnSO7eipiayeFYNrOLeVpNhVKwuGRz4XKVMLaJo4gwLtBt5NnZrjE3V8R20uby0ghmqtmhgRd0cigpyeQ10zMltjYGssFiajqkOplleraEm51ldskhb7lkMoDs4XgCace8cHkC0vSL0d4dO0uD/W4ZC5sQ16QIA6TG2eDvCIXFqNgTYH8/IZtRuE6W2qGLMhoXzYUzGSyVmmdDo0yKFL1IJctnzjWMGA5kP2Y5iC88KfcGwv8fMn4jFACAEvKE9Q8MF2MYnBHpogZh3H9f0k/vZPj+4e9jQvSzKVRy+B4pDErKFPbofz61iDWRjjDG0OtFfe5/ORTkURKn0IWRfdjIpAd2oJBkWhQmRXrRn3zcot52kPIIYbvD9xljkEJiMBitMWakAJ5MOR1fmyHNBSPLfojRi3GrYzSHGChTYQ0Wum99jCgzxpWJ/N73ca68hnj7ndE8fQEv3ngrDYiJfppq/zv0d9/CXHoR8+Yb6bVqgxEaScDinEZYLYIuLC1JTi3FTE9U2NuHx1sOP//5AQKHQsXig18mCF3k1qdNcoUe25uHTE/ClWdyONrHEpKMFbE0H7C1k6DsOufPzzFZzbK7U+LUaZsgibGJKVZiWp2IcvWIdtPm2VcKiBiMjPj4owaaOvUji/qxi0BSqoZkvQxhL+D0WTjYTZBS0O6E1A4kRztd/JbFwvLnQBumZ2FjfZVeCzZXY6oTFXQimSgmPLi3S+Mgw4Vn8+TLB5xekUgRYQysXCxx6jxsblncv3PI8gzYtiTqWtR3C6w/Sqg1umw9DrCQvPjyAj/6601arQZH+yG57BwvvFDi1LkynbZPuZInCGBi0sZoKE3YtI5dtnYkR7WIc+dBoHCVRiQxNhbVqkAon8nZJklYQhPTPHJxhEujWeTR7ZCpeYsgCbDdQ9Yft9jb7PH1b3weRMTermB+weHO7U3u3zsgDBMspZjIR0QR2EqRsXtEStHppPvl7PNlJmcShGqxtxcQmmR4DqSULCwFVCsRBRsiXac60eXB45A7tx1aXYeDvRb7e22m5joEXcm9e4fYDvgdB5Bkc1G/CAvM38Gdn54Vya27EY22w+a2y6M1N6WX6dMxpGfss2dpfjJBGp9KJWJ6IhyeRzP2c+jxMzAeORGXHI1RTdEwa3H8r2bk8Q/k4D9k/MYogJTaYfgfgGHgcSBIB9au46YCTEo5bCTxZMrn8DVGGj8RqTsVDzS6kei+lB1p6ZHgTQOyBtdVhKECNLFJKSAsqfqb1qRBXiOITTwS0FoPLeO17V1evFLm5vVbnD6bo7b3aChwtdZpkRoKpCDRowBTEo8gmYGiG7iIsh8YN6YfVO4HoaWU6L/vsQ8EP6nVkYxBbFqQ9jkQoL7zVhrcfeOt4Uf1W29gLl3CvPXGsLx9vHqbb/0R8bUP0N/+Zv8hqBMbd2HWY32tQ0RAREyt3mN2UjC/GPPa5yZIaJJxAp5/ycFoweUXstjS4sorRTQxG3sWYeIwPR2iUXzwYYDnKnraIowNMQHFaoP1+zbXPujS7ElsDK5no+wSE1WLiXyBjunxeL3J1dfKzCxNYIzhh3/5Y1qdFjE2Qka4OYe1NbCcY+YWegTdDEmSth3KFcD1NHdvH/LJh00uv3KauSXoBS0adeh0ayxemKdUmkN6moM9l1jniBUYk6FYgtahxZ3bMVFoUcxP4gOFsiRXzTG7BO2OjTJZXnnNZe1xh1Zss7tTI1sUPHvJQ9NhbV2CTMh6GQoZ2NvfoNlIo2NJUMTxJOefsZlb8Nl4AHc+2sOPNLW6SYPhbUku59Hp5gjDNjY+03Oa/PwMExMZzjzvks9aTE+VmVtY4dkXFlg6k8fLBAh86nsGHcGll5e4+to0QoZYXpetmkXBDvn4g122DzL89Q+u4Xpdlqbh/vUej1ctkrBAvipwBp38+nCJMaknbbSmUXNpdwPKBY9TF5scbB9z9XKVlSWbqaxNPutz5WWLzbU2SWSxv9NFDYglhRzuvxMegDG8+6v79CKL0xc82g2f49oRK6eDtGJ3HAJCPlVwO0iESYW74WTL2nHLXZmUs8xIgcF85lowagjZjnvskRid/cHZHDSd+ofQQf9GxACeTPWUQhLrZCjkxm837mPgST94q3Q/Mv7EHONBykGjmKEiYBRfMP28LiHEMJ0URimM3SDE85wTr1vCApPyrCSxQDmAkQj0iYA0pNdz815ALpNleSlN1yyXoqH1Pmhd6XcScvksOhYgYmw58kiG2TMDQT2Ye/z3t0fYu/7j1/uB5JMb5ck4iSCFu8Z7JAwC5wkG9c5fIL/zJvLNN+Gbr4/w0yeslCfnHNQ1DNrbib4FpBAI4RAQUdv1abYCHt/5AOUtk5mYZ2auzNJ8zM5hxMKkxMcnTkpsPGpx6mwBSwY4WnDzYZtqvkhhUpAIQ7cVM1my6UYRUSBxXEGCpOBqgthib0ezuAiJiNhY6zA5UaSY1whh4YddVh8KFpfy9Hrg9zqsLGeIiUHD3qHAEjalchqAXt9s4mZsytUM7Zoi6Dax7CLtJpw5A8aGvf06tuPRrhuK+QzFCpgkph35+M08U/MdwiDGUg4f/eqYajGPW0zQpsTxnuH0BUUvaBF0FKVSlkYtpNWuc+WlKpIIgaAbRTx6kOfixYA79z16vU1efXGeRluxuWnw8g0WTlk4UYajtuLoIObsBYv7dw84c3YKS/TwjSKMFFkv5Gc/OWJSBoRZwxeunuHT212yhSyrD/eYn6+weCZhf8tGa83hQZ1TZ6bQiSKKu2QyGTACrwBBE7QCqQzTuYj1XcnCnOTTmy2mZgqUShJpaywTsrmlWVq02d4OWZpPQcDxPTO+f3/1foNnLk1R8MIT+Pj4WRhg5dJwolnTeFX9oDD0xq0jZqZmOTwwmKTN1HwB125QKXhDTzlmFMuz9KgOYHzH6zGIevwcaA1GjrD9gYf+JFPAwGgdFnwO5NLg3sbjnmMG7j/JSmAj+tDJU6pxBzn3g3So8TTRJwXdcK6BUqC/KcQo+CNE2qZN9lM6FQKZmBMPBYYtY4ZCL+kHhY0xbO8fMTs7iTGjTeA8Ucz2ZPBpXKgHiU6rJjUoJQjjiKCbkmHl+17OiTVglEUAfaw/VWfIK1cR12+gL79I9Mn7WCiE0aPm22+ndA7mu28ixoT58Dqf+B4YZQqN02T/fWM8YD3Y+IO4hTCwtmETdbc58+wEYRLiWkXurR5y8XSG+x+tExfOc+G8oBsmNA5cZuYjtJBYKNotQyXfJkwcNh5Lbt/ewFI1vvzPrtDr2WQKkASQ8UJuXG8wvViiUICg4xAEcPvGL/n8l19FKYkJBJaTcOdmi8uXMyS47Oy3OT4KKJcnsL0QSyqqJU2jm5DJCtp1l+vX/paZmd9CKkWp3GNmKsPhgaZcMQSxIu82iEUWgU1tL0K4NiZpMDWhiHUeLX1adQ/lBniOi0nAtnwQLqEJyEofTBatJShNmDh4SqOJsJAEJq0/lyLmF+/u8tIXJnHIc/vOAZefLXHUcmn16ixP2GljJJFFAI/WAxzL5eDokOcvTXKw2eHunV1mlqaYmDO0j3P4vRanTlnkMxG14yqlsk+tpUi6MV7epXbYYW+nx7lnpvnk+q/4whdfI2NF7O50Oa5L5ucKbG7UqUzaHOzUefXlKQSCgyDml3/7mN/92hlEIjk8hoXpNolxcIRNYuITzVOepgDGx7gBMtjf4/TxA2r5wXk7kSXY/3lYd2g0IUlgek5zuNum3TZcfiHT703scvPGLi9cyiGNg22eXsw5mFOSoAdB5L4BNC60Bx6C0k/KhJMm7rjsGciuwRhPAPl1C8H+0UNAA4E7is6PHtzJAokBbp82cRhgdAN37WnBkcFijufeyjEXyqZPvarNKAg90Mb9a5IDLL8/hzIjTHF2ZgKjdVo/YPRQyYwP2SeBGsYyxEgR2f2gtC3TrCRLKrqtDlnPG9LIDsYgR3hAkpcGtjWDtjT6u2+m+f5vfqf/91EPUgDxxknsfrhGg3uGYYbQ6LCMUmc/E1DuQ0VPPqsB5DaIJQAInarRP/9/Q3a2Vzn33DRxHJKYHI1eF2U0+7WApcvP8ex5w+07MVEC+WKPTs/GokerE+EWusTaxpI2Kys2v/eNs0RhlQ9/skkuE4KJyHkxB3uaM+enmKrY7G8pPK9LdmKPL/zuy2QcEFKwuQ87B4LqpEczErSCiFbbsLhQZmpuH7+T8sQf93zynkvtSNBoN6hMv0alogiiOk7GIezCTBXqTUXWgkRogtDmuA6TMwETZfB9j56fJxIBceAhFPz1Dz7hB2/foxt2caTCMQmW6efxR5K79zvEpsvhQQ3BIXoMroxCC5AsLJ7GRFmUEJw5M829e1021hpMTxUJlGJzN0aagMQEFHKaThsyXg5MnemFDGcvFTl7sch0SbK00sR1ctTbASKpkiklvPdhi7u3W8zMhuS9Dq5TYGOtRaXc4qu/9dqgnJGFuQzPPmtTrARkrAQjHDKFbP8cGeIw4A+/fpo7HyvWNyN6nRpGp0I1MfEJOFSNCf5BMPbJfTc4V4M9N1Aeg2SNg0MQuJ9hCBjs1URIJsohK8sBK/MJnbpE2jb5bK5vfUvu3Gjw8qUpfvLvWtz4NOYHf/U+GoERyWeuRxiGwt/QT4boxwvRI1k16At8Aq7uy5enybETv49BwH9PremJ8Y9eAQyF2Qlhn45xTamMJsbQDcxQYA0yR55WSQekzRXG5pJPxIMGQvVpuNoA2x7nABpeZz9LCEZc3QBanFRe40Ed+cSDHUT9Y6OJ0NhIbCGZmisSxMFncMenwWEYmTakwaD/+HX0x+9jvvVNlFCppzTGRc5bbw6xe/1Omskj/vydkZA2I7zR0SnVtkmSpz6X4TqOeZfj9BhajDw0C4GRkpt3D4nX/pSrr51BaEOIQ97WFDKaqZlpytUiUmmOGw6lXA8il+vXfT7+5T6CDPXjgPoRvPMXjzCygRJNPnp/iz94fR67VMWyHRwZIgmotRqU3Jg4bvbjKll2H1UQQrBf81l9eMyFlZC52QCjQjYeODy6FxNHcNxqYZIcS4uSQs6h4rmEJqJScQgaMRsP1zmsHaNQZCxFz/jcXtWUSgnCMhiTx3O6SFIsOgwgk20jbEh8F8sNyHmab3/rCn/wrTL3Pj2i07BBCFxKYCQlx+L8hQwyzrI8W6XVcmi1FEEoMdrGcQIkAaUy7G8ruiFYss2FCxVefi6DazpkEcxP59HCYAmLSlWg5D6HhxsoUeQX7x4yPVnBFl0ikyHsVfGyDnlvAqnadGqad3/0r/ni1SwKC8uyCKIGf/IvFtHa4WC/RqPRJor9vrIXWEawfN4lDkJWlovD/eDZeQSaF6/AhRXB+VOFUWAThpXnjlTDRujpH8Vn8Xv4jKE1yBRMMNRaLo16m14QnTgrgzl2jxWPt5Ph3vSchIXZgNOLkvOn+/17dUwmlyUi4Mtfn+DF5z1+7yuv8u57TR4+Mk8V0iOjbCA30tRxBzm8vqdS1uj0Hsfl2GC+IfQLGMSwgPQfgur8xkFA4+NEsYQYFVQN3KsB3jzE1fo4+aChzCCw+2RwWI+5m6FJKSAEI8E2Dtc8CQk97VoN9Cv6PgsB/X1jHG7pJQnKspDaYCsLknhkbZuTFBXjVsS4SzyAXgaZB0OlqMSI4vOlFC4yly7Bx++P1sWkVBfCQEzadCYypGR7Y/c1XIvvvYPps4SOw0rj6xUIzYM7dWo7O3zhy8/Q6jroWNPraoqlgELe49O7XeZmchSLgu39GstTRbA87t33uXW7QV7f4/N/8Nv4XSjkwHJ8lLYBiVYhCsnqumFq1iHnxAgR4Cc50Abbjuj6Dp6b4AeKH3z/Nl/68jmkAi8XUrU9urHm7r0eF5+12LgfYxdgZj5D61il/EyWg+v6+KGHsqDbPYRkkplJCDT0/Cb1A58z522UzqJ1BOTBaiGNm/JOkdDxDdmcy5/+33f5F39ykVB0cXWWWIMrIK7oRKYAACAASURBVLI0xBJbQbfn02q79EKfJHI5fTqi0UjI5BUYF0cGxMKh20qfWacBM/M9ZByztl1kZQHaERQzdTp+GcduEwkbExtM7IKq4VkltIix8Ah9+PDGDl/8XJFeZPGL9+r83peqfHpL0mrus7SSYXquTAjIqMdPvv8eWdnjS9/8GolR2LJFYBwcJG1fUG+CbUmO6obnziSAYLsWM1+1RrDkYN+JMcHZ3+tapnQM4/v833eujDA8WHXZ3NhjYjqiUTMUCgUuX8oOk0tCHfE3P2nz9a8WuXXP5/nzueF+HexrTRoX3D1MSIIcj1Yf8PkvncMzMfWeRdGLkMrm4CDhYG+Pi89N8G/+z4/4T/6zl8GMzucJ4kolRvE2/eR1f9boHV7L0Pt2kDoklOnnpRC/diXwP3oP4GnjaYpgoF21gFhKJCl5kzWu5/sZQ0KkubdPaufY9GMLQhCaPgwz1B2fVZR/l/CHETYX9Z9SvSfS2MC4p8DTPZvB0H0PJNYSLSSOSjNWjEytkBQDlOhg1K9g3MsZ/t5fsF4/o0BoMwwuD13LZMxyeetNWFmBZiONDQzmk2mqbWAShBEcNprYUg0Vx7hXYwTQh5V4460Twl/qlLVUC1i953PzZoOV889jS/j+O/+OSlUzP2Pz/i+OaQQOF88XqZYSHGVYmamiMfT8iPk5jz/8o0lmzv42dz/9GxwFGTei2XFRMqEXJ9gmRGNzdsnGsaDjGzAWR8c7WHZCvZ2SgPmBQCSa06eXsGybw11NuyE5bGr2DwVnnimShFlmFrJ4qkh9OyZf6rKzVcf2AryMQ+RDu9GjfpQljvtUwvuQ9IosnZ7GwSGRaSHQtZs9LAQfXW8QhS2EcvB7MUe1Nr//+2dJZMzGeoRRHdbXI5ABCSFS+EAHlU04PDig01KcORUjE5tiEaRxkSKmHcdYRvDRR3u4XpeZuZAklkgZEegmqJiCFxAnksA3aPLEocvNT/doh3U826PZg0bTIqLNUd1w/sIcicnQasf8zpdmSLA5dy5meqbE1FyGZhfW78Y8vNvgD779ZUQ5ww9/+Esi2aYb5rl9vYnh/2PvzaMtu87Czt+39zl3eFO9mgfVpNEqDVWaLNmGYMC0IbYs071CA1ndQLKy6O6ku5OQrEAaUEkinak7ELJYK4ROuhdZHQIESKskgcEIG7Ata1ZpLJVKUg2qKtXwqupVveHee87eX/+x9z7n3Pte2XKwLdl6X61a77777t1nD9/+5gEmOsqq1TmbV1tuuspDlG6nu2ND+F/jb8DNOTXV3bKjkn8ijCif+/ODIXgjjWGExUE7OG51AfXTbNm6mu1XTQ497/jbba7btQrRnK07ViNak8eg2WeAhrDZ4zkHXzvI1Vdt4eXn3qIwGScPneTEqRz1nvmFC+y6sYtF+NH/7vYh4t/0g5UpR8gvQwASHViGSg8VnNRQNTTTry0CCL4FGEBaaGET9x2xlTc88ckjbtRTSoHVqBIJYGQJ4xi1W1tjKgdNG1ATFVEfM1lNLPTUlE4aTmOJEngy65RojNYxTLUdR0/0hyQVp36JDb25noQSNgsaS4mlKD3ehe96FeYuXWLgHc5H6T7+Mx7EzEcHmGNQONqU+Ac/g731TmTfI9XlSM938dLop+9GV00hh4+EKp/NPYtZ2d4I09PTqLohZBza409+Eu104BM/MOwDEEJGtPToZJZ7/so1bN5k6WmXj3/Px2P0Vcn3fHwTqzunee2Vczz++DFKzUNvgNMtullJXy9y9A2L2EsU5mZePbSIeFg9MWBQFoy3HX0pme/BvCtpm3nGujlzhWX1dAeLY/V4n2PHFhGjqIWbbsvoLS5iu8rbb8Pn/vQg69d6XnupoNVxtDpKWfRwtHnrsLJm/QTetXn72CL9vmPz1i433NBix3YY6wzYsd1zxSZ4+8wl+oWFskCx3HpjF49wx+41dPIuC33l4KuztIzQHstweDZsLBiU46y9wjMo25w81sGKYf+BOZ740iI37lrFjbsEwwIew+Jijgg8//JpplptSuA7ProRzzgzPcuTBwa89tYU23Z2wStnLkFuppicFvAwlc1z5y1XsGF6NUbaDAY91k1leONYuwU6YyVnzy8w3RknL+Y5eABaLUeW9Xn2yUtMj81y4swl1m/dxGuHj/JdH/xu1ne28ScP/jmvH5tnw+Z1LAxaLPqcNw/OoKZP32ecn1UWCnjuhZOV9F9FvWjwJTmUCfGkGlPpXtc29pLnXhW+9MQhPvLhKznwxiIXLrXwYqoKoZu2wl0fvpKFhTnUdWhnRRCE4p1eu77E94KxaLzTp+96FT4PypwejpcODugvnGPHTs9Ne7Zz8ugCN+5ew+FD8PjTjm0bB/SLHju2T2JiQ3esDPUOgdoJXJjQg8Q1LtEoo1gOfCPBtasQogyTeXVpgMjl4D1vAhqtBdSEoXoz6T0C8V3sDWi380b2XIZEl2hq2JIKK6UCaM3SEs571ETHTenIrAyFeSXJOX0+fccigUA25pZKUzhvGMNVztHkxU9JW1BHMzXX45yGaCAxuL4imVSaiZhQ+yRVSVQH3obIHE8KlTVxbYK59VbM8y/gd+9Gn31iaM364EOYvQ+gd38C+Q+/Ecxlv/QvkE+HmH156GH4+fuCQ/lTn6zmaEf2JTE5c+sHQ+TRzTfB/qdrLSru96HDfa7c3gWTowxomxaF65HZDotlDyMdjOlRFh3arX4oSvTw7yL3/hPK+3+B8x/9FBdmLnDl1WPR7tvm8PFLmGKSHTsKekWOzS7hfego1ZkaIC5HRFnsWY6duESxOEmee3Zc4/Ca4xZ6tDo5Fy9ZPNBpweSkMjdf0J1w5M5y+pzDFV3ysRk2Tk+jvkCNQTTDyRxOp3jxqZPcevs6VHIuLsB0p4hZzzliS06dsZybmef6a8bBKAu9Aa0xA2UbFcdi3yJmEVfC/KUuU5OLTI61WBgsUvQmWLWqx9kZZWK6SztbRFyX+f4FOp02J0+02HyFwWuPUyeFY0dLWuPKmtU5490OE+MO8Rabg7Wec2cXWbXWkmdKqQWumKLTKjgzk+MZsH5tD+/HsMYzM9Mnb7dZNZGxf3+fTqdg9sxJNmy+mrVbHOdPtJhYJxx/a4bMdli7scuG1X32v9hn1wdW8fTTJ7l5zxamOgO8CpkRCsB4xysHB1x/XStovc6F+lDUNagS4R/FO29aDAZw8uQcq9d3OHdqgGRjtMwAlXkWehOMT+R0ug4tQ8LZ1i39oSz8dB9fed3Tti127ig48NoCu64b58mnLnDz7jV0W0HoevSPz/Cx79tI4Q02u0hGG/GCl0Z9MjGgLhJmhzYINrG883LVfivfYoPeJV9kk76JDr/vR+j4O60F9J7XAEalbSXE6ZZEwh3j+NPySw2kud0OYW61w6i2lydNoUQ5/vaFKq7WeY83ofwz8XfnPZLXWcjVnFLeQGMOVaIUMcZdwOHxPtr3rK2SqDAydPCzc71QYZPABHycu4iQZYZer6R0im8pVprlmQWxhvm5fniOVVBDiYDNKF24QIUTvFGK++7D774Z98BeqoqmcS1m7/3I888jv/gvkSNHYdUqyns+yaAIJWv154NJR+69LzAjpM5ATgxJpFpbSAq7Gf2F+wOCSuht4CTYZF05h888X/rzNxkUBRcXFEFZGCxgTIfMLOCcZ6EHC4uhQqTs/SeY559Hfu7nOHzoGOozVJRCofR9rr6izY4dfZ5/+RIvv3II5yfpLRaMTQmzszkHX+1TGottw84dk+y6qce11xe8flA5fGiG7iqh3wP1cHG2z9hUj7dOOLqdFoIwIGdiKmPjlj6t1hSlFpRAQc7Js/MoLQ68dJJ1mzYyu+g4f77PqrEeGKUoWxSU9AYGpKQzblgswZmSibGMTAuMgHMFU2MFnY4wlnVBB7S6XTLjKYsJpqYLkA7r12W89soFXn4RxF7k7TMejGHz1pKFRcVIi3UbOmy5WmnZC+zclrF2DbRbgmnPIbbAWsPqDYaFhQ7PPbeA91N0WwVCjnqlHBTMzU1x9NgizrVYv6bN7IUeUHDFti7jk4bp1dvpzZ2g1YbNVyuD/gIHnnuak28+jjjhsSdmWD0xzfHjypat0yGxi9Atr6+KK5WZc22uvmaSVNnX2hRDVNfs8jEKzYupauS/dRYcC0g2YNs2y8SYZ3pNyRVXDFi/2XPibUdnLGdyyjPWdVy8WHLF1pJSwRsbxhIotIXz4MsTXLG9AGMZa3dwKJuv2MB/+u3PxEoDnu/9+Aa8lIgp8L6L9wIxlFklMKQkIpYScgGUaPIxNX1wKIV6NAaMFD6YcpNG0oz+8TE5s5lvlGiFEmQjNRZn6r+9E3jPM4AhO33Kco0VM8uyjg9OG5OJqTpnpZCtUWhy/s1bVofxk18gZsuqSfU3YmE5GbYHSvxOQk6oo1ugIZ0QYvihPuAUPSRQaQNTE53qeyn0tFkhtNXNMBKTsCSUoD4zczY4X1XpjrXxgPoUbuZC+Yos7pn1uAIufNd389l/9kv0PvnJak8D+oK7/1509278T/0d/J7d9O+9F2MysiyYkdwD9+H33Ix74D5CB3mtopEqqSXWApJ9D8OnP0Xx3JNILPqWYv4Vz6svz3P4jR7OGz78XTvptA0TY4tYsXTzjIw+heuSZcL4BOTdSxw9PENv770sXHczr/7IT3LrHRu56toOqvBHD76IRtXp/Pk2E+OreOutt8isp9XKEUomJgxXXdPilf2LvPrS+aqpzfx8Rm4N27eu4cjri8z3B8xcmOHaq4Uzpy1TExllCeUghGhiHYY2bStY7SBGGAwGrFmdI3iu3bWa87Pn6LQ7rF1tOfTmHMdPtfjiF15mbj4nb1kWF1ps39Ylbw8I38pQHEfeOs/5mQ4z5w3O51ych62bMzK/wOy8Y9VkQa8nfOkLMxw7WrJh4yQ33GQp/Bhbt68JkqHmTI6FxeWZYzyfZGJyNUfemqfoe4z1HHjpBJnN8SwiYrAZ3HTTGo4fVV55zeG0h1KyYZPjjz7zONu2T1ICx04OOH1ywMXFgvPnYMsWw/arujiZB/H4wpFlPT7yvd/Bnd/9UTasc2gBvUVYNQ1Tq8awOVxaLFH1nDmTI1rwm7/5WZ5++gQxuX0odDPdixS8IBIEklIsV2wA4y2nTyziCL3Ax8amEImRQ7lh44aSouyjxrJuywIn3i6jDzDjt3/zVY697RBbkhvh+us30yIIfJu25iglW7YM+KEf+VijzIoLJV9MuIcldTE50UYPASMYUwuDTbqQYvZDImoZ1maymr4kc1EjCjFFBiZhNFX+dEnrjhrH1wJf1QQkItuAfw9sItCzX1PVXxaRNcBvATuBw8B/q6rnJZzYLwOfABaAn1DVZ+JYPw78XBz6H6nqr3+lZzdNQFCbTKrf49xH1aCEPAbFYatqlaPjVK6DhsqVPpmcpMm2lkkdqtn8frOUs45kFFdMSIWjRwds39EeqpyZ1Lj02YQcRqEwMBh42i0TGVaGjwlmaGhzGUxZoQSuMYbSe8Q4QpE6qSpyBik/OoBFyWmF0FKps4k9jr7ztHKLcyXG5FgCciWmmiqUetVQTldCD4SONNYUE850z278s09W6mpTKnEozrU4/NoFdu6aAKClyuNfPsqHPrSdt2cusnbtKjKU2V7J6ZPgBmcwrTbj+Sq2XGGqcTDB9/L8n7xGe8tmbrpugieffB1pb2TX9WtodwZ4BlidAPFYPAdeL8hU2HGNQVU4f145M3OOjevXcexYnw/cNODC210wGRcuzNLpjHHNji4lsFgWDIqc8XZJvyyYaLVZ9EJZOsT0kHKCrBV8NLkraLUyZi8p05ML9Jjlc494tlyxnsX+GDfdMc/ZE21KOc+2TdNIVuC0xanjJZuv6KDekdtFMtqUpTDXy5iaWMBphwsXDZOrFlHanHnb0OnC6ZOzdPNVTK49y9R0zvzCBOMdxfmMc2dgwwYQN+DlQxe58YZ1nDsPRQGT00o7m+f48S4n31pE+0e4+SNbGG9N8+jDv8WxExlbr76dD33kSjrtBdxgjJcOHGPTho0sLrTwXrnmOiGnR8kAxwTBgBZKHD/73AIfuGmSTiuj75QugpUQtdLywtHjC2zZOkVGn1LAuow/e/wY3/WhnSAlTgyuDDWjyoGyWLSZnRHm5uCWmwvQEofjTx89zYe+5yrUw3juKdTx9lslm7YKZ047Tp+Z58YbV1HKHN53OfLmRa6+eh0dl+HNYIgOFBLMqAlt050eSCytQkwA9R4xBuvrxlAqVO97CVnCo5FKgbZL414Fab89QsCHwll9I8Ai0ZiG6dqJiaZs/fplAovIZmCzqj4jIpPA08APAj8BnFPVfyoiPwOsVtWfFpFPAP8LgQHcBfyyqt4VGcZTwB1x/U8Dt6vq+cs9e9QHUHG+tDnRrBBUr1D3PhU8S9y1WSxpNBxS8chlNIRgygksJNUhGrJ1S61JpDkl+/1ir0e73a40gvMXWrTH+nTzutxrOkSDVA3qoS5lkaBiEBEZi4Ej75i6mXQ4JAoXwv3imdXlY9VTqAEM1ngGXrDO8vSTX+ZDH74tMCwfitdhDcZATkbpXahRLhYbNSqvAurwxlbVCEWELBbUKkSw+x7C7L0ff9+9+B/8dJUYl8ptJDVeBQ689DrX33BtVTMpV+EP/+goH//+7dUZnTkL0+sLcs1xUmJ86A2gErS15EQ3GF549m1uvXUTeOHAm31mT7/C6k034v0cOauxnT5r1rXotnO8LmIw7H9ult6isvGKcVptYazT5uixWVZNTXDpknL67df56Pddx7FjOQtzJ9m1axM5fU5dENZNCmrh2LFFtm3LeeLxWa6+fi2rVgmzp3M2rl/EMWCxzFmYs0xNtnn1QEmrfZ6rrlnPicPn8LbN9q0WLx1efaHHKy89xh0f/h62buujtuTAc+MYc4qbb16LdwWI0KONAV59sWDDpovMz63j0tws52d67Lh6HTu3l6HZEJ5BD4Qck5VkNiPzBWo9p0/lrN8YInCcepAcX0Jmg5Axc7HH+VOXuOradTz99CXuvG0SNY75hZKJcYNzhtzkOAqMwvmLju5kRi4eS46YC1y4uJbpSY/3JSfOZmzeUFS+uJa0Ud8HLM5klNpDXQdr+2Qi9EvPqVMdtm8ueeqZRW69bRLPIhgThDKxZN6jlCAZF3uB2Ux22vTNgGceP8NdH1qPYBHnKTXn0lzB1CrPYr/NgVeOc8utawFZUg46BYIQ+3kMhV427n3K5DWEkNTqM2aYVjUpbPo9lVRJgl8hhjwmiy6hR0Iduz0CZTWOgUY10W9YKQgReRD4lfj/u1X1ZGQSn1fVD4jIv4mv/2P8/KvAd6f/qvo/xPeHPrccjGoAowQ8gTa4YFVnW2L3rciBR3MG0hhNc1lzzHS46gNhtZ6hkgdpLs0WlEPJXCINTSSj0AEGWZIyrgJFUZDnedUNLPiJErGMlUilNmeVJYzZmpHU/o+gHqsGc5ZzQSUMkZpKy1jmegV5HhzCVkty28JpKDlRaixBHaWJTBhaVymKqKlU8Kp+iWrIVLYtvJa4/7yP7IFfwN23F/n03dV+0s/Q3HLi+CW2bpvES5+XX+zxgRu75N6TuRYvvTbPjbvasfZ5C6+DIZwYPeumE9t7qj4Jzzx7hkt94Ts+sgXVHkKL+Xll7qJhy5Y+fQSjGRdnFzj8RsYNt7UoBwMWLnZ47InXuOcvX8fJk7Bhy2nOnl3HpjUDSt/h+Cll83po5QU96XH+bcO6jZai6NIre4x3Y0EulMxbLl5UVk8ri6XQMTAwfRw5vQs5bRNiwMfGCx565CBT3c1kmWGgp7j+2g+wdnMJeHy/xURnEQf0ii7WelQMsxfmWTvd5bVDl2jnqyjdgKuvFEpxPPv4eXbfsZknvnyA7/jOKzFJgIl04qlnz7Ln9tWhpwNCjqUAnnu6xy23jwEDQmvSBQyTeC0wohRzjgXXZXqywJgBhXaimbSM7U8NzgdzZ+mEdqvDudlZVq1eFZluzoVzi2xek1H6HGN8PMswsVReJHXVMxSUfgxjCgSLx1WF4DpZB+8KnFUcPdqMo+owCoti0F6GM0qv1yPPurSyATY3nD47y7oNa8hSUQdX3+vlgk1Egx0/mW0SjUk0Apb21hhlGonYN+nXqPlahSVzaeY5NMdu1tNKc3FiQg9z7+nY7tffCSwiO4FbgceBjap6EiD+3BA/dgVwrPG1t+J7l3t/9Bk/KSJPichTZ86crd4fCtmEym5dReFQH0AiDI5A6JYj/pXmQMODHk0m6aBNRMYUD7wcgiSbZUjvlup/NVdVSgoMtjYVjYyR58M5CwJVXLCqA6PRJxD9HI0woaqEM4F45xoihIx6ciPksbF9bhRVR7sT7apa0Mqj9VmCzyFVFFUTibz3PPb5+WjGCkwwGt2qZ6dsXysG9SHKyuy9D9n/PPa++5F9D2NuuQO77xFOnnO88PxFTp7y9IsF8G2uv35VJBwWspIbd7XZf2CBBSe8+OpJvPehdSS1iS2dtWr0l0hoKpN6MwDcdut6NqzN+PyjMxx+o0O/KMnGDGu3DOihtLBYsayanqS3uMihgwMuXOxz9Oh5rt91HY892ePUqTc4fnyKF54/ysBYDh11GFNw7GSYz7NfOoORDo888irzczA15jl5vMVjf36CQeGZX7B0xg2DskfXBP/P88+ew5eOhZ7y4CPHOHXG85//v+e568PX8Ze+Z5KMGT760atZv7nHE3++gPWG8daAzz46w6kZeOH5Y7z5puFzn32dJ758mC9+8QgLC3Ns2znPNVcbjAST3R13bUYMfOQ7t6O+jhaZvWRQUW6/bQvOw5tHHKBcuLQAarjjdsXqAPEFJ4+fAe1w4cICAAPXgrZncnIxEDZnsb7AaoF4g4gBFGMLWmKZ7AhvH+8xOZ5z/PWzaNEF32f1dAfVLpl4BGXuUpuzpxcxPhi+vQ8mVy0dpR+j6M0BHkMZNE6jnJrpsdDvMbMwT66O2Zkp1BeVI7alDtuCQTnL+klLd2wR2oaFSwOmx9byzJfOBe1+Gfl3aVJnzNSNjt50/SRFGDpf42DTZ6nUuDty5ysy1Ij/T3WARufRzO1JptSkgTcjBg0+0DDzzsn6O9YARGQC+FPgf1fV3xORC6o63fj7eVVdLSKPAP9EVb8Q338U+AfA9wJtVf1H8f2fBxZU9V9c7pkpE7jJAUtpdLxqSPKqSuZhYNO3TZQKS9pqLhtT2+TUEjWHBA4h4LTWmbMjiRaF1D18LcIATx4dxgN8aH1oQDRw55TpNzqfpnSQppAkhAKPiRVGM0IkTe5ihICpkS7NJe2JI9hYnalNSSWCFQ1ZsCpV9rBoiCQQgq3RmTCRgwcvcs11Y6hm1Z6Cr0xSIkKuBnxZx20/9DCy9364by/EyCLds4fzX3yWE0dO8MSfPc2P/Y8/gAfeePM8frCa0zPnKMoOG9aV7L5+GozyxtGCTVvH6EhsUE80sxEYT1mdv6JBN6cTHWcqUDjLK8+8QmfDlVyxwfDKqz1u3L2aw0dmsJlyxZZ1mBzUwZuveXZ+oM/MmYwLMyXXXNulbQpmLlkmu0q3ZSm0R+k9bxy8wNW7NvD2ScO6NQXttsEBR47lbNu6iGiX/gJMj5VBYnVtshycDqozDRdXQfp4bYF0mJnpM73GkPo1OM3JxZDR58yMY9VqITcZnpzeoMdYLhx8syBD2XFVC1xggk5MaAfZh6nVHvE5uRUygdJn4Ae8dGCW3TevQdwALy2csRiEmZkFZi4ssnbKUPpJ1qwbhBDjMkesoe0dx0/DFZuEnjN0ModXz8VzA8xYi1a3oO1zen3F5pBZoZRQwFGwWHF4MnJfAhlQoraF0x5GA/aWvsBYi0PJxXDs+CxrN68iF0+vdLjBGEfeuMieG0PgRLLHiwl4sISIisVhcRTBeh9zWZKAN1qhN91PaRD6AXXf6qpbWOM7Tc2+maXbFD7T62QODfcxilQanMa5W14Lac5JJWYQpxyi9PdGJGJLvo6ZwCKSA78L/AdV/b349qlo+kl+gtPx/beAbY2vbwVOfIX3vyI0JXeVGLufTDBx5YkbetvcuVCAbWgdyeEpw9y0yWFTVE7wylNJuMvNK9ThD2GjKV45j41rlGjfJ/gPVF2VabwssgGpNk/1fBFSTSGvZeXYJfUVlpr4l6ZuvZiilDKGib+I1B3QnK+S4yqkapp6AFFh47pJ/vD3n6ayh6oLWhUe70IBMuddGOfBh+G2D6JPPBnMSHj8A/fjdu9h9qfv5aWnX2LXrvX82E9+f1iHKlftnObaDygHX3yGHTsydly5jrfOZHh6PPPUEU6fvMShQwuVtmYDt6/8LUpw1ln14bykvsy5ddx053Vs3rzIc68OuGPPKg4eeo2pqQ77v/w0LetQ9YidYcc1hhNHHRtXhy5yR48s8uav/AZrvnMPp//tIzzzIggdXDnGtddMY1lk3XrD4ddbeG85+FLOuZPHyaRLmx7nL17ifK/ks589y8xF+PITR+gPMkQsSg/vW5w66xA/xvnzBZaCz/3BF5BokNn/5CwnjxjOnJ4HzVizuk0mNqy9WADfYZE2Wsxy9VWT9OYcuW1x5iIIjsnJnNkLc7TtOGJiZJsqzvc5cQquu2YDpfNgWxw/CY/+wQHm5wdMrxKu2j7O5//sMdZv9OR2DIMhtw7RQGrXrxug6sjNAOcznIdVazNeP3gMvxDKJxx8/SjWCgfemAl+I5/z9pm50C+jjLk4UVINngjDkbdmWCgNhw6fwfkWVnJUlem1Y+TiMWqwZoxOp+CGXe3q7hqEh/Y9idM6DLuZdBUMSoOQRZ80Vl/7EEc7aSW6UP2kFqxctC6ICJmEPtbJbLXEytB4nSL/gNhjoybczZLQCaq5G1nyXpUIy4gpPH52OT/C5eCdOIEF+HWCw/fvNN7/P4CZhhN4jar+AxH5JPA/UzuBpKV0dAAAIABJREFU/5Wq3hmdwE8Dt8UhniE4gc9d7tnNWkDLbW5YwLAm4KIZJHFaL4ZWMqc0x/A1AR21t6VxUpniSsNoPLySdhvPTn8d4sjxdVF6TG6Gao9Xh9yow5PeL00gcMlpmuaSfh+tGw7DWkQTQj6BxTil5wry3FKWnrY1Q0WmlkgeJsxLg6iP9zAoDfgFOp0OAxeilLtRi6hqCOU5UhTozh0cfvQZdly1miceP8FdH1y/xHlercF7MgyHDre46qog8Z+cyZmcvMj8uVVs2NzH+Jo5p/1NUVeJyY3ub3LIldJCvadllIEboK7L0WMLbL1qDJFF9v2nV/ihH7qZz3/+ba6/bhsL6tn+8dtov7wft3s357+wn7GJAV0FFcXrgEzGmLlkmZgAa8D5XnCgG4OWhsz0sNLh+Vf63HS9Q40CWVDVS9BMcK42pw2847UDx9m1azNf/vIF7rprC2L75Go5f16ZmFTElFibgRTg24jJKLTPiSPn2bl9Fb+378vc/ekPUxQtbFbyxOOHWbcmY/vWzYyPZ5w9M8D5Ft3JRTrdcYq+Zby9yJsnerz+8gm+77+6jtIpZ97uk4/lTE11OD+zwKrpLqUok2JQG8OZvaOkILNdSu94+aWD7L7hA6h4/tk//XV++md+LMTAq2IECgzGFSwOLONjbawbMN+Hbjvg57lzPXxmmBjvhIY7VukXHQ4fOsU1uzYiWjIoDZcWF1gz0cam8MfG3V3OV1rdj3h3En0Y9Euyll22nPmQ3T32DkiacfpY0/+XNIDm90dt96PPKAXyFNkThZrRe+29A2OW9Bqocbt2/lY9Nrynlb0zH8A7YQDfCfw58EL1JPjfCH6A3wa2A0eBH1LVc5Fh/ArwA4Qw0L+mqk/Fsf56/C4EU9L/85WePcoARjPkqk1oOAYVKmnciaFfGKbscInW5veXk8ar10ARbe8WGWIAl0OWivDEQ62aqSxzwKPj0DjM5jgQkC5pGklVXPr9pe8ZHyT60MA9KJzeG8RaLOUQYi1nf0zgkBj8Fpzhg5jYVnpoEyMl9j0cSkecPImcOQM7d6JvvsrBVy4yuXqcLRu6+GTOiXufop6aGZAH3yxZvFSyal2HiXHPkQPHuf2ubYyCi9J/upRlNHk11+K9r4r+Pf/CefbsXoNDuTjvmJvrMrWmT/9Sm97A8cbrM3zkO1Zx9EhGK1/EP/yH7PjXDzD703vZf9Vutu/czISB1w8f5847duCljdXFkMAmFpMph1/33Lgrp1C/5DJfFn+lhWgf5zwX5wxTE22MHdDzC7SlS1bhRMm5c4YL589z9dVbmbukdCcdZemxAufOzLFu0zgioR7NAM/cbMbbJ0+ybccqOuM5bdrMX/KMj5XL3gWHgnowXdQPqrv00IN/zEc/9nHWTni8LQKeahujQr/vQrjyCNETNfhYQVEJocTKAEMXS4nguHABjrz9Nnt2bcaRYbgItBGfV3P74mMn+dCHN2FMxrPPWnbvPg92vLoDy+Hv5SCZTwoCXrhlcGZUKGxCszBdutfeCHmIwPiq86nudQoQ8XVHMPG6bEXQ5ejU6HxTYpnRr3MxOFX9gqqKqu5W1Vvi/99X1RlV/ZiqXht/noufV1X9W6p6tarenIh//Nv/rarXxP9fkfiPwnKOXG/CYSZbXlLPvJjIsR0T2eVNOKMXYFAWlfq44IODJpeQXCYj321+rwnNSoYWoafBhJNCM5dbV/1z2GSVTENlNGW1jA3SwIikMTRebHFXzyXY7UtxFOTBFGCDSWnI5BSlqdGU8jQ3NbV9cUCIThloUYWeVg1l7r8X/b9+Fd2zG37pX6C+hctbPPbF5/jiF17h2f2LKIYFtCL+KQY6wXVXZuzZ3WHnFsOaVcJtH9pW78e+h+HWO/APPYwaobB1y89m+Gxl1mo4xG7evRpVZX6hhXc5Lz33HB3bZmJ6gYlx4fzZP8VIxuaNlm2bO5Qf/xg88zTtv/KD/KW7ttM2XSZWj3P9jdfxx398BB0o4i0Tj36GyQ/fRev3/4Abrs8YeLekJPGoLRhqLTIkDgnWWv74c8+Evs1AV6Yo1RHaArbBj7N6LSy6cVQHTIwXGPW0bHCabtgwwQsvzuIp6BlFNGP2Uo8P3LCeqW4rRJi4QUX8m2bQBJkKiAHtgw3hhcbAPT/4MaanoqTpcoxrE5pfQt4Jmo1X4cKFPoIwKByXej16ZcGlwtEv+yGB0+VYpxgnqIaKrXuu3wTa4fEvngGdGCL+AB+4eQfz/TZ/+JmnufWWAdaMD5lLmne5afpJkEy+QeDweBPqfglLy7Cncxkdq9I04utFCffQR+2gaaqpcFWXHycR/xKlxA9FsjW/v9xYzbmk133xtZN6hAl9NfiWqQXULNGsqiHqRGsVMG1SIYELlgq5iSWYWcpFR23oND7jaXDzGBKp6mKfz8tLB1BLCMlsZIEylq4d4IcSPZw0zFA6Us7ZGFyMIAifDT9DRWBDFpvUJyLShKaTSGnUR/ceZ7Ngx8eQxQbzokHCL7yjZUMySTOpZcjOGG37IhkpG9iqrzqO6e7duGefqJxcX37sLT501xZeevoFrrnlgxx5Y44jxw6zft1mdu+ZCE5uDT2NEwH/3Yce5cYbPkonVw68+DyrVk/z4Q9fHfbptvo5xXNPBD+H92RiKB9+iPzn7w/VTD91d3XGaQ1Jy/AGTJFR2kXeOlmwbes0j+57hQVjuOn157nyF/8+xhgu/ON/zMxHfpSzp09z021rGLfB2X3+UsnqyYxDh+eRzLL9L38nrZdfQHffjNv/NEaV4GJRrDZ8Viw9qzSfoU50Tvj8547xfd97Fd4ukLkcQ10IcZRALWdzBsVJG3QWL52hloXJ5EDMJK1yWRpjJ7NappYiRooVSnCyN8BFP5kFvG9xYbZk1eqAV889/SY37r6WPC+Z75VMdDs471hY6OGKjL0/+/f55V/5paFnDxHK+HsoA1GQSweNyYuF6LJm0FHCO7pnCVL8vF6mrPToOEnLVOpzdEYQjcmSSRAdYUaXI+zJWpH20PrhuSQYLSK3HGNI5m4TmYrRd14L6D3NAG6/43Z96onHam4fbdJVBcvkVEnGCakdsc57kknFEhBdTe3w0agtpItAk5lUMzCVTS2TZYqeNWJ4SVw8/j0R7FzrUhEwPAbUh5ccScne30QUaWYXR5NGlZUcIxqGHEgiQ4iaLnzTiRzmokPfD9pPbJhNjezNMb0k52vIVLYtS66K7tuH7H0AfeA+uOfuKgt5/wt9MuPIrGXmwiKWRbZvn2DTltU8v/8CWLB5ZEo+Q0S4eVeI5jfG8uhnXuF7Pn5dvbaHHkHuvR9//72UP3h3SMDZ9zBm7/1w8SJy+EhobPPME8E+Kn5oHc0IjHQxz5xscfT4S5w5b/jIT/7XTB95NXx2926O7Huc3/2dX+N//Xt/AzfoklmHsRn79w/YeWWBL1us/rN9mPseQO+7F/epT1bjpjNNTIi4p6SwQaMYTOWPUlFKQHTA6ROTbLpiwJHDA67c0RqSHJsOx4QDqbx5s9BhlQke1z9q7qtCqBMRaZjLEg4bX+NNc4wUeZNeS3ho9d3wtxwVOHO2x/p1lnMXHeNjeUw2rO03o8JYMq2kcdLdFuo7rwz3+h4aK85ldM5NQtkkwGmcJZE7XqvgivR+UxCto4GiQDbKSBt+vXQmTUJeRt9Bpf1KbQoldgFM62/u76iwODwXvn0YQNIAhi4PRBOPq4hp4R25sRUBBfA+SNGhykoD8dPPxoZV9X98KDcb7PfNyxLCOZuEedRU0uxZWpk1PCEsz4XYXCMSiGVjjHRRLy0sMj7eXVazSHbYonC0WlkVkhrmVn9uFAkqYmFCjLKRIJlCkE6Typji/Imx9V585VBKz8g0MShT+TZclGqt+iWXonlO/+5fP8Zf/1t3YmI99d/5f5/gh/77D4XiW8aTE0ozEzWTN/f/CTtu+Tji+7UPJM4tMXQIIa25EMpP7H8ev2M7smoafWAv3HN3pYWpqctgeF+r3CkyRgSOHl5g4xWrWfyN32PNvT+FMcLjf/Xv8Wfj6/lrf/NTeO2zdvUUQd4rMOU4+x45xD2f2oGXEBabxXgT70uszYfOekjiIzzbe09ZGLK2xv0N6wvhx4ugYxDDD5tnPVppNgUIVIUPG/uVJGarNRMnCT0s7e+c9qWaZ5TAEQvil/pYGnPRkde1s77GDTFhrabBeEYp0ChNasa+OwJyi9bOXKFAY/8PBRYHfbqt9tDa6vtpEO9YHBS0O51AH6LZ9vDBY+y4bls1h9H99fEuJZzxPgkSWu1vtYY4RoW/vh4vi3eojvwxS9fUZPgkzVsrc/Tw+BGPG1GL3zZN4ZcrBdFUq0qpHSeVpB3r3hgfiFkLlmEi9aE0EayZtedidx3nPdbUZRwYGS88t9Y20hwTI2kSx/bI96v6RSZMyhiq5JD6cEN9H40Op9AX9TJzkQzji6FoCFUNZR4wOHVA0JBaEqSjc7MXWLNquq4wiFYaU9qX6n2RSrI2CM4TChMYRTUUPC5jzaKihDy3oYidZDhKROGxJ+b44J2T+KIkzzKQQDwrbUPh2WcW2XN7tyJCIsFElVps1qF7BvY9SLb3Acr77iO/J3QeK9STqUUllPV2pSKZx6YezFHzEQ3nnFnBlTmPPPgid/83V5HrOJgCoQilEjQQGCeh2ZBoPxT7intTeIfEqCrVcGnzxGzShZb6IidnvmpgxG8cPs2OKzexOO+xXaFlAjPwGjKth8wTcZ9CZjZVHkoTd8O5hzfUS5iLNUMSaMLdKq/CsPQuQZT1Pc6HPg7L4X/KT0naYRojmVkSoQvaSM3UknmlelaDyI4ytpppe7yaJXcpRKr5kCuUbPSNu532HhPKnyRG1WYYVGKVTdUlGnspWuFQeKYNUTcjgltVByziSKkh7DpXqawDzTUbDb1I0lkncFLTg1H7fqJhzag4Yth4x7S+PcpBJ0hqrBA2Im1Fs2BT/eFQpFiNwyciFm1raQyjwREEMYtX00HEFG9VrImFz4wZyiloIn8y2diIpKkVZdMp5HGR0C9t1CASCEGmUmXkigQJqeqLmkw6xgz3CpBarU0SAVpgUrx/w9Th1OPUIWIqZ3mCNaumKxOAEAiKjbXYLXVmcxZL5yLhBrgyajqqoIZi4KsU/kwyxttZ1bfAa1l1LJLeJawoWST+pLkDF2Yvseg9e24P8eS2sQ5rbRUxZJxGidWh93wa99wz+HvurtaUx7n6MvoIjK+ebwkx3NENiBHlS4++gRP4+N3XAR1mL4JoiWrGb//HA/jor8lQRPtDTv3aBGNQTCjx2zTJRcJdRk0p7anRKHkDV+7cgFHP+Bjk4mP5X6kkuqapozoPT53XMXLm4YNaETqMID5DTajH4/xCvb8BSYbuko3MHWrzmbH10JV9nHh3qEuupDs26uAPeOqGiGpyrFZjiVSx9dUdj3goIrHxka1i8ZtzSYJhTn1PbNJ+oIrdJ75e6JeYEXU7zTXNobl+obbVV/NPJr4Rgcw7V52xEPAxMVerDQsEqdqwD+ZK9UM2/6RZVJFyzb3SJiMSxGQxLHokPOorwLcMA0hIlhhBUxuopfDa4alR0k2I0HTOJBjVfURshShhbBfrnNRctpl5C+GAmqpmutCpO5gx8QCNQWT4YJbTvZrhrFFvqP7mtQyNapqf16ilxAviXVbtU2X3FzBYnFNKX2K8C/Nq7E16diFafd97X88l+TgicoooSJCyrQ/mm6xlq+JvxD4IKkIg23kIlVTINMOTVeYk732V2Pf7Dz5GxwatZzRCJTFpqKN7RglImuPFi6Hhx2Ix4OzpGRwhICBpJ5WWE8/0zo9di5WCPPMYgenpHqeOF4jCD//o7uo00j5D/dzaTKWoL4NJsWn3jz+rqqqyVAqstE60kriT2ao5RphDgAK7ZA/SORL3Imhfcc5ShggbKVmY69b2dKmFl4Q3qhq0IglnmXCtCRUTEEHU1NE2jfOAaD4UQj9p7JB20QSl1ohrW38Qwqr7LWFNVUZvWv8IcdTGGEPPiMKK4BnrLK0Q0DybsjGmaax1yK8jfgkTATDWDq3SjZxR8kumu5Ts+jJSdj7RAWfy+p4y/DPQRiUk3JXI11AS+luGAQBLOCDUyF4R30SgowqtUiNvk7MKVNJVAhfRrDINaZA4hmx7LsU114iWialVvvhfmhIgQQpN4X1pPgmpjK9rEJWlr0p6BzU0SKkV4o5IPsmZl0woecx5SOpnOSRBCzY2jXBlOTRO2pdca2dbMrc0S1ZX+xBFEKclGkMxjUbCXCSVVfHqo/mgwEXSdcdH12OjJOgli8Q8SM9/9cc+Xp1rYt6JMFbEs2Hqi43wKi0orWlqqo0x0B1rs3nj2igFK8YkxiP1BVcDroznavDeoc6y4YpOdenyaHu1+x5CbrkD9j0cmtugQ5qASCjE1ywTnvY3ZY4n6S3tM4SoFq2k/tjiU5XSDUu5YZ+jwGFqYUCpAw98sltHc12zYVIaa2JKqrpKaZFNjbPyk1RfsksFqCZBioEDaZ1lZCZJozYILvqhlguHblaXrXxZqrhYjTdJwSJCWRZL6u5U02yOmYQEwnySoEFqLamhsugopMqeWYOZeYGBr3tvh2fFSrplbepL82kGhCjDpjGN4w0LODHqTxsMvCncaFF9skSrTOK0N0L085mMZbb3svAtwQAqe7nUm5uQC2qVExpSq4/18htSQvMnLNUmRu19iAcbD7BxOeq/ByRS1WFVrXnxvaIE55c1S7db4jg+mp+yzGCikyxJgApVvH2SmIeQP80pajAkQuRDiGYon5BFgpCIg63U3aQdNfsqNNeZ9rnpBHfRnGJG1qSq2NxU30+In5tahbWEuYFHxEXTm0ekQDE888xJnnzyFE88eSiQd183yoFkSQZJCVIY+r5EjaX8hz8L46vg5/ZWGxQIa8AJ54p4dPF3D2UZIsZS8cDQQnO4PECFc/feh3n+Bcze+8N5iUH2PUx+y51k+x6OJQ6WEu3kiE37m6RtEanNPEn7E2IzEYNt5LEkRlLhq9aacfP3ZGoIn3XLCjtCPVZTIh8VsJL0rrgqqmVonJG3UpRYM/DCaGRKUt/HUVCpo3WcCbioRoYDOKJwZW0WHPuy7FBDWky648kXUUUBovjLmEqSFiOAel+HYEeNNVNB1AfhTHzl0DaNNJ5mQUiGNPp6T5K0H5y9oXpxWufoeozWzCxrmIMqRhPNa6kN7DuFbwkGkBA/mXcMdfs1IIbP1c7CIO0F5M1UliBpgirkKm5i+t90oOa+Vseb8zGRuBMjZtIBz/XL6nXSSMIk6yzfJao0VFVEK6khEfF40GHNvpK2miatWgKNVzlJELF4mxNABsEk44XSMzSXpgbQDEmtVExp+EV83fcgeSmWW0/aUxrIKNQOPSe1/6ViNmr5zEP7uf3Wzdx1x0bu/OA1iEI7MTsRBmVGkbqeRQ3Ne4NxgpSe7Bf/JdLrIf/8/6zGh1CqITwl+XOiI9sYbEyWw4HocK4HAA8GqV9/7l6YnUV37sTfv5deGZiXxIJ37L0fNET3VP2mIwzF7ktQ/6uzNaYi/tYEcx1QnVcTmlKhk1oDJOaolLH2k5eoEagJZoERopDWaH2tlTRxL/0MdaFsRZyHtOgRBtd8PeoQTe/Zxjij300+uCw60Us3bJKqanh5sFouwd00VkUHYEjbqCv8Ju1meUKZhMySwGySFtPs5uXjHak68Mmw87ZpvqFxr9P3gyIyTA+a5aWH9hJqS0Z8P9EcKzUetMRiPfSL3rLrWg7e8wzAaV0aIUFC+sruF5G4SIcgglEdUrOE2n6dcKIZYgjhb0VZVs4rKwYvvi7n4PwQcWhqJgnRxjvB0VtGXu18UBWNhHDQUagcuPH3tCavWnn/k2lAJKilaEZZlkM2fN8g2DUzC+Vhk1Yk0R8xWBwEyVVkaC1JIk0NaoxPcwmmobSfGTbYpn2IgCiTnyIV0vM5RMd1M2Q1Eb9wAdK5+orZAXzi7pvDGNQ9YPsR+b0YMlNiDfS0DqVUdYHAi8Ca0OKTNWvwPpTyKEuQeFGr0E8fTAuu8JQleGcwURLrFyVFUVTnE3olv4D9xV+OvZKn0Hs+QTeLhPoX9uJ378Y/cD9GQgRPszT10HnHPUyak2joPV2ddTTZZHEuyxHuXr9fS7XE+PJYjqOKIPNB8zOmllwTrjRxz5v4/AYxTWaYLDouFxZqh3HTzJHOSbT+OZQBPfLMdPZuhAlU9ygyroS/HWsqgaxikD5ok87V5phKK5WlppXms5P2jNG61LvUYyVIzdaDzyngXpULUJmcLYLHmhT5N3xOzbpcprG3aazSuYqhVf6AqEk0GWypfojBjYJTKotAYvytvHP5L4zAe54BZJglGyDKUBnjFCWTEjpypFKTKmhgvoz+bB5OltW5ARpD7HzIJWjW2R71J1RziQQ8QwjFFxQT+/bmy1T2a0qKibkM+SkAkUAQMknRDyGCZsguLMPJX5UtseEzyDQwhfGxVhUb31xLktytMRRlWYUZiggDV4ZqowJZ7LiGDGoJWiGVlgjNOxoS5chlgCC5ZNE2nHrzBr9C6lAViEVoUmMpfRbMafESZ2opnZJZixWDNXlgsP/mV0Nf41/718GBP4BzZ+eZm5tjsDjAEhqBOwTvgvknRF0poqGuTjtvVftrHnokSv078H/3b6O7b8bfvxdp4JP/1N0U+x9HPvXJill7XxPF6mwJLTQTbgGVySjF7XvvyQkmxZaR2jzUIJaddruSjJs4DFQaZy4ximtUOvbDuCcaouFGgyRMxahhstupHecjd7G6h027dcLjiHsphyZpe9mIpFxp+I07m/AJIJMsmF6i1liKDpke05yqOv1N3NPa7FSKglgyH81UscS6tXZoXYkBSuNOJdNcVVmXlPtiwJrKNzh0lxpzq0I14//Mhrvc8jEizNRMemhNxgwx3UqIjXcqmSFTRJmNwuY7hfd8HkCzGJxz4bASjKrqyQyUUqJTmYB8hM8NOWukfq95WOkACw0EOISTLUVygJSh3JxPs4pnNd/GvEefnaBZ53u0nEOpgDWh9MJI8winw1mclSknSfYsTV4L6FsPspz6qQ3EhTrmO+y1oVRPJ3LA6iw0I5mYQpeiIiZw1xeqKEyQsn2GtARjS1rRL+G9x4oJ8eEuMGU0OP480YFblmgJY+OWxb4G34l3ZDZpS2HivV6PVnsc9SVF6enkLUrKGJFlgjnMQbtlWJh3SJ6BOLrR9m5uvyv2M9iNf+YJnNQSdTDZWIrk+BcPMURR1VWx7k2oSoVonc3Z7ASXzqWIxDKYREYyfxuv03cBnnnqFW69/fqgfSXzTepDwdKqr6PSfHN+ToJkmace0Ekrvkw/i/TecvibIMQG+OgjqKO4RsdL9yN9t4jhs0YTPjkEM9RApYmn0vjZHDPtda4SqtrmQdLPnR96flqnaxSaTOfiNeUNBR9AlUvgNey7LKUlzUKHlbbi65DgQqTKym9WJh2iMSP7LNq0bsSiihp3QAzZ16sY3HsFRBki/kDFkUcR2PkkaepSJ6Usv6kSVSkfpZ7F6DhM0sqohDMEI8Q/Sc0WSQExsTrpCAdPko+vHUgulZnG4G0gCn0C4lkTyjcUOixtjBL/pgRiPCQnlJNWuBwmFMxLn6X52ca4PjIP42v7rPNQOqG/0I8MWfCNtZdOKb2jcKEZSqYlzguiGa4USm9YKGDQD63rnPbRgUIZJSAvmH2PYG+/g+zB38eVii8dRRESsHIBK4qIxbYyeos+lAUWiREzIePauWCf73RbQcrLlLxlKbSPNR7I8C7DqME7y3xPyboZVoSWzUAsaiz+/r1B6t+7Fxed0aXWwQZea5u5K4Ok2u8VOG84dfpC2MtYpkGC2F5Ju+UIbhoN2c3OB1OfUV/ZhZvEuwqF9Qwxjtvu2FWZ8BYLQjw8MuQwHdJUR/BYpQ61TSUg+jGnxslwocKh+YzgdcKjUhTnPQMNwkeOCf6OZaT3Jt41xzQ+MFyL0C9C34dSYyRXem5KlNKGXw8qk4oSfCM+RlUNxGKzcM/9iB0+SdY+RX1FC0C6Tynaz7usJtYMJ7MNaVmJEYzU7DKxYXxfQ9HKJqNJ81lOOG3OVQh0pe/rBDM34nv6avCe1wCefOKxShqoDkm1isdPf6uiNKKUWaqnhbls0aiknic7+NCGqw51nko7tFztkdHDqcbXuuZM6t/pkCqDV3S4uxnUTCbV4PcS1pFq/zhC6YOi9JU5qSlJVuuIyNSsW5IklSRZVqGj8ZKkUMsUtdOMZEoF9qqM59JAy4VkLGvI/fD+LfQ8mckxNjpbfWAKKTzSOaUs+rTyLh6PKxSbeTqdFqqCue1W7Isv4HfvpnjyacqyJMuDjd5JFnwxgJoca0rKArLcM+gLrdw3LpKhLAdhDoSqltYGRiHG4crhEhFZFqNLSk+7pRTORxt6YLJiWqgfRAdj0FZKDY1KMhMqrpbO0jJK4ZR2Vp9PqSlc2FdioSQ8MMGxKUFlDDgTs89DTsGwfTgVJqt+j6YNieGwIoLT0D/XmoAvHWuG7ksV6aXDdXiGND4NJQ9czFBvFoNr3iNlWNNtagIlCpqFTmDehzBFVZpR8qPS8ZDZpBLEwhmmUOLgKq+ZYxCCBEWWmFULV6I2q6PqvIUYYVR6T24a5UFGtOZqbslXpxaDUorDqyUXT99B24Ts47T+EqXFsFknmZGSeTOVqEj3s+kvS3MfZRxN4THRvVSiIggngaF9Q3oCv1uwhAOOIGyT4yfCm0kg/kOF1RoIVsU6S23eqJBGatupk2CHSwRxOe1h9P00fjOFvfBLL1ozqiB9LnUNS1J8JoaUkmnUU46YwTCypNJh1emr8TwfoxoyMUGKRob+bpSqRWQ1Lx/mErJNDTkZ3hny3OMKDzbDNvslRwQf6xiyVlk5aZ0HMVl4XXjU+eCoMuAV0A+3AAAHm0lEQVSKEpsr1qZaNA5/3334m2+m/Pm9uMLTykMpB28sVksyq/SdR3/vdzG33oZ5eB+uFPI8o4zO3aKIJprf/yz5B+/EPPIwYFjshYxLUYO1wsXZ8yGcz2Y4FzQ+1RKngVngcnoDKEtL4RxGWigZZfLrSDARFiWoSvgOYBMuBvdsCALAIWpChy4NBFWlYbvONDj3vYs+LDMkFXqC0zYRRZVopsCARilSg4nMEMMTvdK2WZ1gFXHLEjrVpYZAfhR/IZQ6jj6asNZlfAWM9MAekVozBCTmWJgUsz6sTYSeCFSBHck5Gmhl+E6vGOBw0SFsg828IbgFDbiO8HHOVfubGRvP1eHKwPyNdyHvp8Eoktk2EPooMIk0WFUU0oxiTR4EB4kRaHa4OFuuS7ODRaTyc2SRWOcapHejIZN8dF+azHH0f5qPiVn7wc9ol4azfwV4j2sAd+hTTz311T+4Au9PuOUW2L8f9uyB5577L//MXxT27YN774UHHoB77vnGPGMFVuBrABH59tEAVuDbGPbtC0R6376v/bsPPBAI+wMP/MU+8xeFe+8NTOaHf/i/bB0rsALvEqwwgBV4dyERz3vv/dq/e889Qar/SlL3PfcE4n/vvZcnzokJ/ezPDjOjd8qcHngAOh3o9f7L1rECK/BuQbN+zXvt/+23364r8G0ODz6oumdP+PmNgj17VCH8/Ep/73SGP/fVvteEb8Y6VmAF3iEAT+k7oLErGsAKvLvwTqT4vyh8NTNQ+vtP/dTw574W89E3Yx0rsAJfZ1hxAq/ACqzACnybwYoTeAVWYAVWYAW+IqwwgBV4f8FfJOpoBVbg2wxWGMAKvL/gLxJ1tAIr8G0GKwxgBd5f8M3IC1iBFfgWgaVdyldgBb6d4Z57ViJ1VmAFIqxoACuwAiuwAu9TWGEAK7ACK7AC71NYYQArsAIrsALvU3hPJ4KJyCXg1Xd7Hu9RWAecfbcn8R6Glf25PKzszeXh22Vvdqjq+q/2ofe6E/jVd5LN9n4EEXlqZW8uDyv7c3lY2ZvLw/ttb1ZMQCuwAiuwAu9TWGEAK7ACK7AC71N4rzOAX3u3J/AehpW9+cqwsj+Xh5W9uTy8r/bmPe0EXoEVWIEVWIFvHLzXNYAVWIEVWIEV+AbBCgNYgRVYgRV4n8J7lgGIyA+IyKsickhEfubdns83A0Rkm4h8TkReEZGXRORvx/fXiMhnReS1+HN1fF9E5F/FPXpeRG5rjPXj8fOviciPv1tr+nqDiFgReVZEHo6/Xykij8d1/paItOL77fj7ofj3nY0x/mF8/1UR+f53ZyVfXxCRaRH5HRE5EPHnwyt4E0BE/m68Ty+KyH8Ukc4K3kR4J30jv9n/AQu8DlwFtID9wA3v9ry+CeveDNwWX08CB4EbgH8O/Ex8/2eAfxZffwL4A0CADwGPx/fXAG/En6vj69Xv9vq+Tnv0U8BvAA/H338b+JH4+leB/ym+/pvAr8bXPwL8Vnx9Q8SnNnBlxDP7bq/r67Avvw78jfi6BUyv4I0CXAG8CXQb+PITK3gT/r9XNYA7gUOq+oaqDoDfBD79Ls/pGw6qelJVn4mvLwGvEBD404QLTvz5g/H1p4F/rwG+DEyLyGbg+4HPquo5VT0PfBb4gW/iUr4hICJbgU8C/zb+LsD3Ar8TPzK6N2nPfgf4WPz8p4HfVNW+qr4JHCLg27csiMgU8F3AvwNQ1YGqXmAFbxJkQFdEMmAMOMkK3gD/f3vn7hpVFMThbwofGMEXKGgEXQi2RiyCWohKIEG0SSEIiv4FVoKkshexERvFIlipQe0s1DpqQFR84Ipi1lcC4gpWij+LMxuvshubJHuzZz5YljNndrnnx9w798wddstbAtoATBTGNbdlg289e4ExYJ2kj5CSBLDW3Vrp1Kn6nQNOAr98vAb4Kumnj4vrnNbA5+vu34naVIAp4LKXxy6aWRcRN0h6D5wB3pEu/HVgnIgboLwJwJrYsulXNbPlwHXghKRvM7k2sWkG+4LFzPYDk5LGi+YmrvrPXMdpQ7rD3QZckNQLfCeVfFqRjTb+3OMgqWyzHugCBpq45hg3pU0ANWBjYdwNfGjTscwrZraIdPG/ImnUzZ99i46/T7q9lU6dqN9O4ICZvSWVBPeQdgQrfWsPf69zWgOfXwF8oTO1qQE1SWM+vkZKCBE3sA94I2lK0g9gFNhBxA1Q3gTwAOjxJ/WLSQ9jOv5fvL3WeAl4LulsYeoW0OjIOArcLNiPeFdHH1D3rf5toN/MVvkdUL/bFiySTknqlrSJFA93JR0G7gFD7vavNg3Nhtxfbj/k3R6bgR7g/jwtY06Q9AmYMLMtbtoLPCPiBlLpp8/Mlvn51dAm+7gBytkFlPRmkNQF8xoYbvfxzNOad5G2lY+BR/4aJNUg7wCv/H21+xtw3jV6AmwvfNdx0oOqKnCs3WubZZ1286cLqEI6EavAVWCJ25f6uOrzlcLnh12zl8BAu9czS5psBR567NwgdfFE3KQ1nQZeAE+BEVInT8SNFD8FEQRBkCtlLQEFQRAEc0wkgCAIgkyJBBAEQZApkQCCIAgyJRJAEARBpkQCCIIgyJRIAEEQBJnyGw6c26Uwne+lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image111 = source_image_array[107]\n",
    "plt.figure()\n",
    "source_image_1 = image111\n",
    "source_image_landmark = 'result/testOutput.csv'\n",
    "current = pd.read_csv(source_image_landmark)\n",
    "X = current['X']\n",
    "Y = current['Y']\n",
    "\n",
    "show_landmarks(io.imread(source_image_1),X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('own_model/the_first_time.pt')\n",
    "x_1,x_2,y_1,y_2 = reg_net(image_tensor,target_image_tensor)\n",
    "print(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1920144.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4156600.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3666352.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8760590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4887000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2520500.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3195927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3578352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4002252.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3917012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7804146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9722599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9183429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10418065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10358576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13258274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11781327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9399170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12924342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9698852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8788530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9193496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10246977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9879491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12728561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13356852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9096483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16391625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6312764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12717258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13283416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7683043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15240020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12081525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12719151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7429942.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14291823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10176628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12992408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13490645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15695019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4592925.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7015062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8382634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4033575.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4182064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3646022.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9758842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7019540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4524746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5282289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10801514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21146504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8897804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5122195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10622972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4225909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2527283.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10056460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6222218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2685847.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1890289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8420710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8823791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5751042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6507429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2101193.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4549140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4438224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6379121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2704936.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4498330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4838133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5561858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4120434.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3236030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8568082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10432353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10663423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13570671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18073698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12542104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13253338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5131647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8852410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14066918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11519643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10606871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4644856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15917574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13194127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18022050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9352744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13015396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5398667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13727681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6871771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8873488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12114619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7204174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9981044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4743401.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12948186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10882955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7993158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5424303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104597.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2920585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4245192.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3581927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2948827.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1967571.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1785954.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2747877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10750735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12425376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6730761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17246708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11031470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9509114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11823624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12542235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13955492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13422028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7347573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11045927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10289630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9207025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11965235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9417029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12901480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11823952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14014524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10775701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15072835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11284268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15352172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13290461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17081042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7221949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8136280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7217562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13621703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10751274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4835801., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3814091.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4603818.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6801356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10023987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9094332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4857721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10513583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3633436.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5449326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8496270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20164946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7015599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13045330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9444894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9238369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5022928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9608188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12087244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5451595.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4580226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9573825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6731618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4362511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9007856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5723431.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5644615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634412.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4844527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5987740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4262429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2685705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5528566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4737488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5379133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4625746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5477219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2870282.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6955592.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3246584.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7896915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15184533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10457069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13082448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10204769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12621472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13737894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11505542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10883261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16536237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11266884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4768265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12605684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13925654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10765939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13978048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10521230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15358583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10469062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11341423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4916664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3982635.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8301183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20074140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7717920.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14830446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17274778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10814930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3545788.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2386521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2658520.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3278353.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3310510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5098756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3457248.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1985870.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4598050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4246856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17561316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9148130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7679352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13615100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10558905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8293092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17665488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6832597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9325358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9627849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10675432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12403786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13731688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16491970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13002793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9340266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16759054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13584212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10192281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15861750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6535079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8253497.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7671728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7446982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17598710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16152562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5480103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10857912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4837382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8658588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8228122.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9780726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13325257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4216417.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3658538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5117487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8584133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9150150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14218402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9447113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8416293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6131001.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10968282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11909088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15441120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12901602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8243132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9273370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3793990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3014634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4950365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6379903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1161641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6057980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5457256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3323415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3568141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4700389.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7489874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5908656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3720753.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5274909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3729513.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5334908.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2677257.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6523343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6444177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6551265.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4489595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7210179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6231234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13672330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9990917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13645910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11402316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8770574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11687824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4741049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7152596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10296762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8727773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10310095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13579898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4101102.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19500606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18263232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8196018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10351615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14622092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8682737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15763016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13875131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12383439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13139192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11737644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5792970.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4324165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4872548.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6421928.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4300835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3936091.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2336793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4074017.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3292367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6409866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8152828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10498815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6433037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12122949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4326961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9299266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10373151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11151103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12292463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18483116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6844508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10315072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12917177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12528852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13897841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11764653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13138816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18945608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14587636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11903312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11896098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397858.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3396759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12662565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8358037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12843119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13251308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16345450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14878736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9117574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9091293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4450350.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12365449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7385647.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2600716.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4489687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7510947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7858051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8253217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7902535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7888751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8034633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4779469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8379102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5321634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13354832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8151331.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9675881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9561091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5181188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2997030.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2877696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3056032.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8851252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7109792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2489346.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5521477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2482972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2757572.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1239665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3796392.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4013776.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3007388.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3734113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5093863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3275434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2853471.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5003500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4849916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11742852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10022676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7540475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6688410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13212383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12480246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4293823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13967477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10906717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10245496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10715500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9802201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9170920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10094965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6931288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4269800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10147049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12777057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10114574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13301766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12318624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18629860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9843082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12840751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16737819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8816942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4299306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10976254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3026819.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3761020.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3065124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4561655.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6466004.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1436963.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4280264.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7223716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3412892.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6603308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9701906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10477707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9546866., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7936756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9690996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8056874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12294122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8519394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9049278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6127874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11440024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11264599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10834332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15143822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15235057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10652672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12297596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18646176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15825343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12011835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10461347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4081076.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24154428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7026703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14961801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7595565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8765906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12786006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14015372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9181900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14885595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13377705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8444668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7100682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4983965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5477039.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8734563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9039351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7308657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5600165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12252432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14832842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10132218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3042621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14849070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8804223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5088717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3656637.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5512347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16670318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3288966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9114994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6653808.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4865987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4205909.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4777195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5782283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5052472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7829407.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4253810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4164524.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5214075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5420882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2731252.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2629434.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3482081.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1652608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2417135.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1591396.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9108044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8800155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4594812.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12463646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13742805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4721755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11337811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13765531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8917622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20607160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16618990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8956102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15486140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8772106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3433162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9748818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9692798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8829434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16486404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10827597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10088167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8601107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8919356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15877126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3599210.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2316072.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3936172.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2900641.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1154668.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4789429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3769048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7382977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11856451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7883836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5042568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4597462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9889220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9770651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9275268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7925134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11854998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14025937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17199342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14486425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10234076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11812907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12443025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11612085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13727560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13220548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11823618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12133175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13107129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14176764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9524519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10678911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13664733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11531183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17003448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7117552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12373063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13386596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7198679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20921644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9427024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9711546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9042185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4857357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3853622.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3669575.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6103091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5497190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8346939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4835144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4935902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14003823., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8618991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15246596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4479014.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4558849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10168155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4971964.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2188357.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3065062.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1932624.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6379005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6832621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4982154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8248529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1829587.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4863271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6079315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7278659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4301651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3074706.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2088339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6333539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2185027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2080823.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2374773.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5370495.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4407072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13933407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9514581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6830465.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15862594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19616588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8851135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4774494.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7415324.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15186409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11799076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8876633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13417492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3692272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4582075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4678963.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7923333.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12886407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18181460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13761904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14576773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13215346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14933937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15154393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10272355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8602364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12492778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13151982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1981917.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9392736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2582251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1904094.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9192873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3938660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3346724.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3477739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4269726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4488113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10342923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3319955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4382044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8877991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8431164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10602073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11461857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9304787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11207810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12107398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13786882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13677770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8447453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11634853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12036096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12374874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8054787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15012602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15020906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9494893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16740224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14996628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10289861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4380073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6957751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12401949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12718827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9267276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10441385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25760526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3913025.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6907647.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9945712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1712540.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4263237.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8580227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4020837.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11730589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5552046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8886292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4726181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3900984.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8646118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4744688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6002447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9834809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19517222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4973670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4442303.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4786649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3116493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6168427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3104756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7450937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1835610.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2124866.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4498031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2228729.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9524571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3665988.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830479.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4697869.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5137986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053384.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2118841.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4114863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5958106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5250292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4331204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6829757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1998640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9566879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6390797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14218917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11277458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7984446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13417179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13740061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12185251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3576913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7822180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16980238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17172906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6861546., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10361962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14502534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8668718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10304795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8992957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13076515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4668101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12566820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9455728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9412010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9209108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12592489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11432025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2932036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2558972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3243363.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4130341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2287232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1805255.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2207723.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3790819.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5706678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4891317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11587427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8290016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10613664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8979173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9002316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9190706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10302615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10429851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9019645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18544854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14095695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10157877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4683234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11964767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12118630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13528047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14616121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13072579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14592539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14952357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6570818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3558413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12254846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12295326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7510020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10189095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7475606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5607710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10732553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14171635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9197479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9409008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2884513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3960529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4716293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4691188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11191380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15560224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12267238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9633816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3538570.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5090273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9601652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4635451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4853832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8369834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9382044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4762332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992707.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7741643.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5348990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15725901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6942390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9979220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2670053.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5228089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9119277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3098181.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10421067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3863590.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4360426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7439458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5240640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6203320.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6281112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1663133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2212262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6378504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5923067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13662564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8597739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8381740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8835666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13897576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12998232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10166708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12406457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2261641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10150682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7124770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12931106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11399949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20260652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16251377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8560148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13077231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12822927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5153046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4192544.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15532312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11747378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9509069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5031078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7009153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9107062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13504230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5612716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3743372.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3579359.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5454133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4225250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2486717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3120291.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3567823.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4599650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10571551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12555499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7639672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6916982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11593345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9392468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9265635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6400551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9114456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18612388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10747265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11131066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9324752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12957948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13660985., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8101042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14662282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11462363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15126839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12821167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6613032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10962616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16797110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17717140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11199639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18070160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11675087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12829525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14265512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13254320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9454699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2956109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3156322.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9513468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4613976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8499302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14849832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3715807.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8271182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4277486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4018517.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4582918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4539158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9152857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4917655.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8321884.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7825544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4539642.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7971885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5881403.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11857266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5894429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1639627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4575939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4207853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1790907.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8478615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8722912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2779727.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4483471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2185777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4416605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4057965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2780329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4849775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5925096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3223369.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3228946.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8113574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8474261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14528398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10764877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9307169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13433959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8497198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12603852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14187560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10289162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13575570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15957465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8777115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7897610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13696500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9693423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11978158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11436148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8240594.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2614917.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8306537.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4374492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13485490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10575220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10935765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19465244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13976744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14948889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978987.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3960299.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4959956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2663731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4027072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4125145.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3720216.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3850869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3856313.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8704324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9135763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4777029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11834282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7831839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14935115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11952220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9439428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11607357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9042256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6547165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13598924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11531141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11955563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9836879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11518837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14620810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13209161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19874542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17596246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7948334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5226664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10083385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6592187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17987168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11682228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20366354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11671409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13347987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9206044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4087225.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4863253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8865246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1705934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10292139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9156494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7874468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3316491.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8242062.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9012644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14076582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8802143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8005965.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3966792.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10567849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14544788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8423325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4848754.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7119551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12924608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10959174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3404686.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6100582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10397499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5989161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2641103.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6168430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2901345.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3114162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5360384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4241635.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3660798.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2824477.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4679020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4391975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4527596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4148850.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2955372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1822437.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3274112.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9430802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4158558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11621562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8495972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11967277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15153779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10908117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10344593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15148966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8884090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13075397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4607850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8748506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6646243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9154119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17333838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6923125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18069060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14950161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9538423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13446806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13670687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5123596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8511140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9414541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2137852.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3674981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1408539.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3710604.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2282553.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2700428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3850615.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3060928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6215733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11471460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10453313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7902989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11868343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10219273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8318359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10372448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12171718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12900617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13921652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10892263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7074814.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12251798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13225989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11260408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12594968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11192571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14101333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13393744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16474166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12223068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6580740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2069054.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7913726.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4658888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7281984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10710634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3160567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13946115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8796408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4687455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7877096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7698636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8198656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4805885.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13448950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4272945.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8168398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6338507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14032184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8572039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9327178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12097523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6040030.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9028447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20588054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7284539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8019784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10930899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6505844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2425659.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3506833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2956429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1715243.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6823774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7743532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7000388.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7481070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2301423.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3600832.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4288193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6393825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2556779.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5543055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4832401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2829541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1987032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6549250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7601284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1546352.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6430989.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10531243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7655925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14089177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7002015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7327885.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8405040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14080727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6970131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12545793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2992326.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4211543.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17037282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9221505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5903370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4581430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13699278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7955806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8635966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19028464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15550860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11159033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7970967., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3931114.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13086256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3121045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4202191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2429478.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3944110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3854704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5344780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2312668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4177885.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166859.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10620225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3628387.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4562732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17969726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10490503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9434405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10401241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9459671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8165198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9004427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9914481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11020139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8002682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12092789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11269204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14666048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12537509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14133516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15836643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15090070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13280213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5059208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11572823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12437333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15886799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18821764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13611750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16528411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10846300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8525571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3742216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9351598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3654513.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9091430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8171797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7079104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12770805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8812586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11224254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4283441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20860614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4371428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6581755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8253835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9181329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3061839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5659602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11499720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11233160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3004429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6233890.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2523600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1620115.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2419591.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2819147.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2155033.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2718689.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3276420.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7751723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4007963.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5630070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2810279.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5821293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5429971.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2322633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5002661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6243242.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4462817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7279326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9709915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3932436.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8094996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7948671.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8931062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21132696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7863591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8015503.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6394451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4001351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3869798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9925066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8460407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14450362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8341312.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10729332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13416215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17352414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17389432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9330857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11396755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10180241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2779378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7104869.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8233929.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14289266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3051575.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9713264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3916490.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3967325.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2643661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2419891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2441128.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4295744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4247484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3865470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6190405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8795279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4380786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12503935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7767448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6809758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11714272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7970910.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8400906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9892536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17197744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12062379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11090372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11411324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9688465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13680645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12307337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13298358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7955938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10659608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11204341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4494038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10296605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25438456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6953621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10569911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8324331.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5569532.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13615685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13174727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2469582.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3321005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8143208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11572835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2063217.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8733964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6822279.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4355903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6533613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12907214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4731794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7704611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11146681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7786093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9875505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8809905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3989290.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8790074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4389800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8958305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2008771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2278879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2788624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10675738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5793321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4453853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2433287.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5946145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8954146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3220491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3366316.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5888115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1165631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3814966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5130229.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3399622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7108452.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5030382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2975685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6870721.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12558400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15268541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5576491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8800318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12406162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13768433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20330224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14558925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12180449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11445161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13048118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10220498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12798257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9163484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3866607.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3837329.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7807592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13055793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8504451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10734414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9591773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12277322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10298997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8723245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12763425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12993408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19613252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6802152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8606977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2676669.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3802006.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2642347.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2278861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4424314.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4553558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4779168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3709852.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7593104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8953392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9364074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11706401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8422139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10007810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14121074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6241341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11784072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14583334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10011442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7387817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10305322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8856710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11779622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13940720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13650482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10872347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15940777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13505544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6017091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6157367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6912186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12793652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7216052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9835820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12548658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17330390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7127180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13642201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4496255.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3237043.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9449963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14304368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8326012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8127352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7126378.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9437064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5544093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9158078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21040614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8178627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9880216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9102689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10719992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4719497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9770345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5470860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9516726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7110382.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14604063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3484033.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2528603.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1142816.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2635611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3153522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9134132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5804941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2085753.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3604723.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5376537.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4275514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2637132.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3315683.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145305., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4118554.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6455156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9535224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14150520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6364306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9065918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13748389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14221137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10241258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14484491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10140920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17790446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13244014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17925052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16193017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6866358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16120727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11883374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15279811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16689244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13430769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9433001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9703095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10428694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8948959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13640388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8882687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8695546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13013234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9731464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3821318.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3653463.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2707606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6521622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3319413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3465512.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2148794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5036250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3999969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5732651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7693676.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6967779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8419589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11724046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10200731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9473883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11584816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5010264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6042019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12236252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13503745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8247788.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10448424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10940021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13248953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13856910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12362092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19285104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15918662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12653994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6099471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17950458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10797181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13236743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13169086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12739485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12873638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15639205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13613532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8675286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4877028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3213095.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10017607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2794888.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7098243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5172104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3780432.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9075028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8647019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3698706.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15071428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4011867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4705410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14293355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5786709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8102046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7909747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5222068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6949503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3459914.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2998302.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6718480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4992812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2571324.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5448113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3021377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7053833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6956077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4022924.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2591894.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6139268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4466560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3249140.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8199001.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3191925.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5577400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4975172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8837639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5111044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12559185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(792373.8125, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10649494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3781159.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3486082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10110247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18630532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4461233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4596815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9343119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12795859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11445983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12356726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4429027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8819984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9433712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2930778.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13173003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9281068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2189916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12962312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18812684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4768863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13740856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12118673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10351006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12364392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3600600.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3290915.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3098277.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3596651.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6051871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2758253.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3524236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009446.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4336435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9446825., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7560812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11299151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13203310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3236389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9080578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11821218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11275773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7809884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13635238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11060807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11253618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10468824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12832553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14909553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7208776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13257719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13584523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11359548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13821640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6873876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12129169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14483912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7025080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25965642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15459760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8043687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2609346.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6378304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8371638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8451600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9081266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8039659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2702570.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4510774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7012924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3956711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12169838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8663454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8580279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8477617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8042814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4528650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8865374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9387731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5749830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14244683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6886353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5266028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10952601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3140153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1423263.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2085706.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9164305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2514164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4660979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6162308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1613651.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6806555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5736771.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2324224.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851982.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2141747.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3079463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5259245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3637999.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2445968.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6366128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1807317.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15008480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6888078.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9817007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9432036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2528244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9634960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13347449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11735451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13143769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8983074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11138222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11160828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9099838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13310153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7643396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13267832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9488353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10538151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4828461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7695279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19029002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9607825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7912039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16921114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8116421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6413699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4679364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3368838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2675907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6778951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2267909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2623947.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3769126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2481507.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3421636.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3616838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14087558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8336178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8992804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11743718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2785975.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9294236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11474904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11209346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8696235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10764934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11715768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9990337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7733158.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12458329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12864545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14731531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13832912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16320346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14224887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25127192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11125561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4438889.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12699742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6871052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6283598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5111677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5286987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25418754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14330353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4745774.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10221760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6703514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5757517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9019304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13665242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10529259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2111255.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5892807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9325770., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5392200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13497818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5315058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7824332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13435298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6013625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8797969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7699933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4764470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9243308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6550285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6558001.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6550363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6307750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1319257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1576929.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669929.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8656202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8997775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4521251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3102492.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4651589.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6645554.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5362476.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3224096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2473005.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5391843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1472911.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6814809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8690389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11651515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5817804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4727180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13770906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10228879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13059055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5398737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7503890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20151070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13102540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8689697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13196971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148324.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16340924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9585392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12876298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10281204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9280306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13507905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4750399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9049840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21067474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9853355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13538209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12660090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12351027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12672584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(670438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3642461.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3433345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4221603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9078981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849874.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5133927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6046015.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3121428.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3410497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12781473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8505708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11210479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10922494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8482301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7929974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9651382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11126930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14225673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11651888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11712982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12563298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15013524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14447185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10400120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13489857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11616113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12567758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13536964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9944616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15213085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6023962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6827876.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13019390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16453804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9321004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12220663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13117419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8824749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8322623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3941586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8511306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7270848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11754026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3671887.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13105966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4487409.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12215194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6230868.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14421415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3491071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8176194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9258909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8705019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10453922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8517288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8305918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6774998.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5841005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5106577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2113370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14018855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2942756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4847433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6804195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5932542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4452439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3059172.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2196755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3257074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2649154.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3997497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4438266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4923692.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5946428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4850667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3558305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6277408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3840434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5225419.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10063076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8133091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4435852.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13330670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11767362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10442811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8028248.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2338244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4744424., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11843115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6928959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13238604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8099810.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11108670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11954740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4487824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19115152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15953664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9938553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8451335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9942152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11244110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13068108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17753182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11977248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12916502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19194602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4180465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1883765.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1214557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6310864.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4078364.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4399199.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3219857.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4613047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3008363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5002740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10600122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9107356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7558392.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14595009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9936913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8106502.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10478204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11416130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12791776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12461344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9899262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11532626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12600174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6675177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10970046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11657317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15523818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18721240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11324733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16515780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13580095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3859724.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9010610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12348597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7643833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16518419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19027368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12576962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13717358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14960336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10601625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3247441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20486316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7866111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4836218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9223081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7803762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4239972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12064323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9191176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5406079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7181335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7432088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9345069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9477194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6391045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13319588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4542909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7942601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8358636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5170692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2465719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3069566.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1680380.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5491704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5640850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2988080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5868129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11760279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2116387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4489423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4411007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7476986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6952819.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2642716.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2152130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6989833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3619472.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6704830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7921780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10825609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10363541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8581255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17884676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9342497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8824293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9765970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10785695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16443708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4585128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8223968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10566347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10350686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12733557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9080019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7070300.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10927856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10348931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13606941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12479450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17353412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5563868.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11100882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13184246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8927738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12865551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7094130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4076884.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3075192.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3215081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1220831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2687472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2905613.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1827138.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166721.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3097935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4710913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13842791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6481195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6995865.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12092922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12281611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6983780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14591419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5453110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8947640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13678427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9978295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9976307., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8117653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11880698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12683086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11071739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14635668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14897179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20987120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14566210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11399276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1899842.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15728543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7241083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7935726.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(24109480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14243804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15975107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16660344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9956968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8201890.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13524127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5413045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6926199.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5285347.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6010413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10636510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8504937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5391468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13376897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6504644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7735480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7979089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9512732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16848954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5559541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13373134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3063207.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7379348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4187823.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5790167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2701757.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6521208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3330579.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8639102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1692322.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3274982.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5612221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3366984.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4444452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4743443.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2011750.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5438946.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5326783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4550418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2825408.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4873996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2832414.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4223192.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13402313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10340698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6802549.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9058524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9072604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10782775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10393164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11807055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4936764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13402686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13468228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16728096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14179361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10358608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4376102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4837240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7307622.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11456920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9168446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10080348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13379748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15050654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3291560.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9952850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15415989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10929304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18303424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3627290.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4449735.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3089337.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2534924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6081666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3810521.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8477920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4929111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3530006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738987.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8020881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10835902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9914546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13005028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7047723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11062754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8930234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13968428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8574042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10402724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8281336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5744195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11629350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12476144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13388218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8585943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14519676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19896244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12775245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12338268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4303211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6104189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6964192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16389111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11971601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13251082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8374981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13559848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19515986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13141171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7757470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9024425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2734806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5343918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5428523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7670826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12360904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11343078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9412135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4627485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18685266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4240467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3742981.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6684184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6819449.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6254405.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9736826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3624116.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7862339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6852690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6407905., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6647972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3419565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7426164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4564456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4455546.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3102396.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8345203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5150568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4092754.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6731966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5805187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4821998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3631924.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3326569.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4564245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5000143.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5362176.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6292662.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9137478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11122641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13957564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9767570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3257451.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5657045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4995289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14066884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10202853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4457688.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11290803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6035471.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10854529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6883485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7373115.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13052575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9967669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11122469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10540466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10505372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11828962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9012646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8093097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12662595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16415074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12056928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6994970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14394702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3584371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3130597.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3573759.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2976970.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3318297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1247146.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3176915.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6944670.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3602552.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10504270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9936956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6995057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11111735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5976233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7961493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9011157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7076525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7160970.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11463131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9735495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10753731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9804692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7636090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11581101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14079920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9968709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15074845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11113176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13235385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13919877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5980687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5435849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10018619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7095189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12021051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7914126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13436127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7231803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13500709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7378207.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13341483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3755154.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4093516.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5282708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4535668.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12719391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13879457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6063682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14284568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21469394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21739448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4561405.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8414152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5182300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4210850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5035481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6291288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4078433.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9584814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6240904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7660964.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6238167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1905923.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1602139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4752888.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5509262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5995613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7167517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1936285.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2000230.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6010206.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4659416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4975641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9497297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7496032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1595694.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6746094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3718552.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4004620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16421224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3906614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8847732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10942501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12796744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15915839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13933763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11930933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13394496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11084526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14460348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13296753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10377647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10483450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8281092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6648882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14511908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4998441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4919801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12605545., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8787245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5208892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10207114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13162585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9598606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11869590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18087298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8750273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2209585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1195052.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3716577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2347295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3314075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5146594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6454799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3526500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3909727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6036606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7822846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5989256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9527810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10584346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10629060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9712534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10564763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9855410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12000821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11328662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9640659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12367699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7454306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8340941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11138476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10138367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12066582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13691667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10750775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11648949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13788456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14026269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10751541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5237380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7822958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11075710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15207119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21957662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4832011.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7530641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13751052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11718074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21277332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4582462.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13090738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12336881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2606406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7932895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4194098.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5036653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12943459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4675926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4843135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9660306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5380489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6501964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12652397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4484611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7804737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4571023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2698121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6134978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3188962.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6215450.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5049417.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6717552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2610967.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10472663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3667361.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7411187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3973760.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4453247.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4227884.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7169570.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2655878.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4072267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5174604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4273183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4994031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13418123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12487083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8964988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4809607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12724232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14565867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13685288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6846901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16319770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4141038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17063294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6819847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9409398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14543372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15749522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13095594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11129693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13663679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12614989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15149232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12963944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5662659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11810432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4922290.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19746238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8518420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4455033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2804811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2899613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3533883.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4469590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3335031.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2590085.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3254532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3233570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3636722.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11562142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9721675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8717682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6427708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11207030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7186859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11258783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10416074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12022130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13894246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11228374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16580322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6699561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8377625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14887703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12389842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14197943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15671683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17433318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13560948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9027366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14981894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12036229., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6277650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12902491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8801417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14936553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4127308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3128669.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14253297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5801801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11454933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6526718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3155031.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9132973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19818496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4015562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8526446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3681526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8806555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8543054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5157871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5280700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4988365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5930245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6572273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7825734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7955722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8758685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4216721.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3155394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9512609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5696876.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6446862.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5847264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2495299.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3294880.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4736021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2163833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5475926.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3916600.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4243022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4429282.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2046841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6219160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2734074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5966177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5034097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1998308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4661120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8179386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16664753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9020852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13493376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9558270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12262637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7160087.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17708708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8702072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9711846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9712809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12971823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12006950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13184752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9100673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8527224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10187911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5512674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14803459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19399160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4671538.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21414776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5379149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7636325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14702786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10429222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6552479.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772694.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2860218.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3763323.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2754975.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4552190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4114356.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2739007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3426707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3043597.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4406664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11950226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12336678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7187265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11916134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9487789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6862086.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3881209.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6234231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17811528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14275001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16848646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10989377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11331077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14963418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11871673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10774180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12908055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12557242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13361293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16803878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13335872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13192789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5807373.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4089490.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17510882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7944433.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13473688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11649334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7781730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10830909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7273223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8430069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7796321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11707271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5175279.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8471982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6522784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3803155.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9021254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9796601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8160998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8343667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6206800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9705811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14469417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3163595.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5403734.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6131985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6457899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9564278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4796293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4171168.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5458065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8307271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3122191.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2167010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1551704.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2291711.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1971342.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2087237.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2536270.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2861773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6935896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6522699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5185179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13517015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14269107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3825098.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8956709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9096006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19829360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9568503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3149895.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13390833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13550677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9382752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7561174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11571484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12977254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8979630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15536874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8512126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9973006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4634557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9984744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10934775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17679626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13295118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13698512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8239780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15126383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12982759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2067313.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4378684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2698860.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4380502.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7154684.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2629717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2545953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4948960.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3100119.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4091503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8474826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9094715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9307495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9238881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11742826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10702554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9591016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6559873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17484078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13684633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10076573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13506624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9526664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13196344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9724202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13477840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10023923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13508868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13198209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11033915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13217574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10840533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10041450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5949099.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7213495.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6635216.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14208693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14851599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12696568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9700989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7847679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9646745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4116776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14534467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12978501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14256468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7901644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4620056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6723226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14408189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3977049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3171109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9259768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8902658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5322713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4830065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6838054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8031902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5435323.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267877.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2932435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8419557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9792072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2532422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15432859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1912364.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2011326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5250882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5469631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4144517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5001637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6595902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2687134.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669982.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2641651.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4638709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2319260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5501208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8578617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9346691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16475060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13080519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13503452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3556319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9048399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5621124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3763646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8831894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17622712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8368176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10105588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10609463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12893852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13408362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7512897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8552483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14920923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9047902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10167620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12529682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10226823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13322488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12867009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9855814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2424911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19869324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3245183.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3834016.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3896470.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3240030.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3137971.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3882508.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6581026.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3536020.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4575381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11938977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9435572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10064404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7824946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4861517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10261530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10663191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7267057.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9531969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18569498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11560755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11581726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8216380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12870390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9594415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10626742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11368299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19263892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14325863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16703401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16443628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16023434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14569458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18396520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12911324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11669672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12932274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11294793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18761496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8773090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7749383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7597996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11939413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6677659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4563199.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4461003.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6506986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7901233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6080531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5596740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7830883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5014949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7203701.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15448456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4445148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13529238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4636227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10673146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4399880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8391758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2788729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5927745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2137515.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6184333.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1625930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2170153.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053089.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8563173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5319305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6143172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3215213.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4489685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2387906.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435939.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5909355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6533111.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1942740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5469453.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6803411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13410416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7791192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12775488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4755332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12299003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1690965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18468552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7601480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9246952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10409622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15687494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7533643.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7427272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10433744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10692458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9105591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10524685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17888536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16101682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7494913.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17590380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14048509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13834333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9613991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4908085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4955150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9281995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2025355.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3555699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3217297.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2777934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7015563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3217758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4282732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2592681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6634591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4733749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8569628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6856476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2945941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11934310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9547051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9198369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9404620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7633218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8020817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12202774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12733141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9715533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11411777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10804371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12561000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11763753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9935435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14920624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14006763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12287785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11536050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11001337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10942593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6762481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7264198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6703781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11006114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15082155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14723462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20127872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3626916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3018854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3454052.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8556039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10750561., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8277361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20530994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7620621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8465904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10065616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8109346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4338703.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4666361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5844881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9480092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13642714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6745624.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6179050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4700233.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3516065.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6275174.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2422282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12244193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1602647.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2584878.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5767124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6307597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6237873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3179428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3791806.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5715410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3928736.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1543419.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4649946.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4613882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1689682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2427258.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5426100.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8455167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13368808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10084060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12518472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13154568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7947876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8749624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20363898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7749882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4481315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14024471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9819134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4335117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3525373.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12680363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13102302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1850834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7394491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15450757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18368422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4548975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17543488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12786714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10550958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9759281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10799089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16620176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5095269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4316383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2648749.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4012390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2692073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849850.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3366798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4386237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3139972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3542830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8150055.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9228072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6844253.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11114716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9148114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11260957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14128423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10887200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9567899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13409756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7161737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11019948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9126601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11990880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13876919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6920029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13138699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17958130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13849718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15803811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12918777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6384499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11059328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19128756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12290869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5778599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12704094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6988388.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8067514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13916784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7802636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4335349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7707593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7087072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5357334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7470391.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9103478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7924984.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8053650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13815254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4675446.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4595323.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3765199.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5008680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12223533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21665538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4459435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7405377.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12441236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6030862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4019849.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9905022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8330574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2920641.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6357679.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4588877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6688715.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5240324.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851184.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3234842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3938657.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3870438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5312504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8156026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6149313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4806833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5131057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7811058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12812051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7121109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2911034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18001102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5080258., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2320591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9989928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10452474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8485563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9964066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3551136.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7291349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11803477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7828407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8347640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9678293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10872639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8022356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12438319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12492769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11766625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12363396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4475949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6851937.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9536849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6778825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12427293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6110632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2420983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6526145.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400949.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3659015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6480245.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2394412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3382708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4930111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2765922.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3666412.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12198302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10839530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7094983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12842448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3681412.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10753710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11889022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8909211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17526858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10885545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8497604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13230518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10319587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11780329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11757467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11651215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11572189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12415483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14517582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12264419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10195301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9445370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12652366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20167636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11799564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6415220.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16220840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5406303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13316752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13905067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3803993.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13351299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9067762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8789815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8562696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3939380.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4598867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7127857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5638224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8251502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8448876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4152727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8442612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8380176.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4105244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4123842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7637818.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6998778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8845037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5532157.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1314098.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16087607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5279208.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1767895.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2023534.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5754972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5083628.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7203412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5754398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3175184.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4671937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2189136.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4560883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4140936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8499279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4377304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2652072.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3891616.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4642010.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1642468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14681707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2610895.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19965944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3004267.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12210595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13262675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14960049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10495854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9609928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13443922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9370403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4012421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2859964.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10015796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12721759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11847018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10293629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12942485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18195282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12601337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15032349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5159052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4706899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2657934.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12345991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13619057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12446501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2194994.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3377478.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2713628.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3755450.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732343.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4412643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3313028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3257966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4782122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10788886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7159068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6948914.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12259691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15711606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9299693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15261310., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7475794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10488119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9512972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11239803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10562059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13609546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14463968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17536234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11435107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12768229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14089173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12507885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6456928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8949171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14808769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12679378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7716116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6938095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12664044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14792733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13305549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12728879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1818211.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9955951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1578295.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3614249.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6610318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8287249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7817905.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10920253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6975716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4916001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4402905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8009893.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14473442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4875261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14783632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11081144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6984408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5332369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4825946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7877343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3225828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2072122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9680296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10219043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4799516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2632310.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6043710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5798384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5918263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5284524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(930928.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4436353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2251535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2077935.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4070117.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4945595.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5463955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1811778.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4138584.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7333421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19542578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10227730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12525728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10790640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8750687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13182789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13872130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7687376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12991410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7232361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17076602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4461784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10186751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10741065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13033917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14423349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14847369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11312104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18346620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11136665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4689129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11808300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10175130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13973062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11016144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16425604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17870676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3637309.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4218423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4472283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6309848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5121127.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3238182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4340681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4173730.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3599115.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11500546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10235819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6497369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13305653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10023322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9087072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7702782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8298166.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12634831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11218555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10536830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8459327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5659093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11532164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14362944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16596498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10061190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11587970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15978179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13410169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12218885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6537861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12092314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10321162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9033598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3111954.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15591269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8134776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7811792.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14248997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7896239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5191048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7769939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9691661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14056759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9630698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2728155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16733287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8286492.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8938003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13462070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9607909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8023665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4678462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11866524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6379943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8621356., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3793880.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12316727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5591624.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2870252.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4901584.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2768842.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5935406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3771531.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2241529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1624769.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5861686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6985720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9886006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2035058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3114430.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1976230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5222828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8593325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4669621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4687249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2319962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4003752.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6611263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9679702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10027943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6639890.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4589444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1371042.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8456352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10771894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10199008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9587532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4405888.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13184613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7136797.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10836814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8920749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12650212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11191090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10182380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10246543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9941193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5602146.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8648665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15422985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16277095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16241289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13603590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10058218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17461174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19503558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2595435.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3633130.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2761362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2021577.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2688179.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3199473.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3917719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3346525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4747843.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4914557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11916841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11670810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10991904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10936893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9877766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10591266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11308718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9824034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5155860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10842091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13415603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9868453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10325062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18018908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10327224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12424800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11826610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13885238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16243766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6277470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6420266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10461145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15557012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12155149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3057131.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6673656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5075159.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19466460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9417775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7975336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10650259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7092059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8385357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5861190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3010634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8163633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7770775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8169416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15478863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10353992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4013824.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7391283.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6589399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8425153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8754484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9942886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13098244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8820312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7175857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5142379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5287782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3489343.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2068138.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2868068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4949765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1604946.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6501087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2959088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3244401.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2408260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3629156.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4971414.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6030343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5370609.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4695664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5218755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6442974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7624542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3860960.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9500642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1067365.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4012117.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2017645.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9422432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4507427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11750831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12574557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9663590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3798023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3771831.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8258629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8336406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9906018., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7620394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6394766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10557676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13393159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998058.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16385103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14397085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8398115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4495684.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11021602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12709706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12027616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1199018.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4667183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6528655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3287598.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3477319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3580048.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3493522.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8984612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3579674.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3856461.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13558463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6333894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10175434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12093310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7680047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9268674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15800652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10882116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12771620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11546350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8475826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13364650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13186195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11662988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18403016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10262326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11708719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12845962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11347941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13490503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6511037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6660819.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10827705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17665146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7477266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6960862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14053634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10885363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8697292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12912661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4328008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7810285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3710068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5581949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4584786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14114124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8825576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4493696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4265714.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5693258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10520132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8669207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7272112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3161445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14759942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6077354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4898366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7702878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7637203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4132128.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2018031.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2080592.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6207747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2841986.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6267090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2191895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5570815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6331651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4817195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5719486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3090349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2027780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3720444.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3176187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5142899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3110548.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4284977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5059135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2020023.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8120535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9050895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14643719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9029490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8142098.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9702779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11865605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(879545.4375, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10047547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6759717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12602310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14338157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2260361.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12866644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9673546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8074909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16532230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7391458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3139637.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13251005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4295153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6712170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19575218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11333552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9232074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4583115.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9341487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11025374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12177342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2093271.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166716.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3812523.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3300960.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1502589.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3353194.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6310048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3775290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5635666.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104773.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13605234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9869161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9400272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15584483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11321916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7221678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9211483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11780962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14803184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8138222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11152834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10769684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14141717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11072920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12405093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12755992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15369625., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8866478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10676510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11447145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4609332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5871606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10142243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12967660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6738898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13186431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11296261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14082959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9906529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14133416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7957345.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3671888.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3368056.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8456500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2765513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4385721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6694213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10038546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9798842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8432636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7930472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8043882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4739570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9312497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6587371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7422858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6839840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3829350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3019016.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6878820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9963734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6529163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4244674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10599824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10085549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4723003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5433786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2180391.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5448588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5069776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1826321.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5075630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6211111.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2277982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4422113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7039440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8204657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13549393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9901135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2398027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8332526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7073811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12448114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11746433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16086303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10254630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15219478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3850366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14705323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1205189.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8855131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3654324.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9836844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12086307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12515616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13789733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13779419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4421720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10929431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8314940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12666500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10785906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12619517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13107976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9001641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2718610.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4075300.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2664119.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4724007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4272925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4133674.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4013782.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3825167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5507861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7448685.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10378291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6272383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7385746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6602229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12222565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8359455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13871504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12876106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10044595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8502172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13567702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8355055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14179924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10686835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9808241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18501478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14156197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12518918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10230365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9944755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5507069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3622981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13261422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16572502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13859216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11041013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7780752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19184006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8027366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9032864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6041841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6808114.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5303528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12378854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7268305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9001286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6798377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8393396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4246369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13946262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9899846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9183275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7574461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8335899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7710700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6889740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8416943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9258001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2225775.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1331752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6529296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1192289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8637058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8772501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3062743., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6032326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3527807.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7208146.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3398725.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3899964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3191751.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5143020.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4545883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6611017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4295328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5328113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6546926.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5156051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712617.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10399869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9149934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17254550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12258822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9630079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15833762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2122542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12925781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13529421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12558599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13176457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3126421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8459205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12678293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8434250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8688126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2568314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14883199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12581803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11294032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4993295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9485778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8029184.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9057355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14121157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12376503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3820914.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2306436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2342755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4157234.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3879817.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3557350.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2583899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10050724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4483313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7563409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11702086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9503324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7076514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9333117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10459403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8874750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11455384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9461942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11073052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13427021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13311639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11459422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9544377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14775272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9124432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8696651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9541718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8355714.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12844000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13409241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11020863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6324839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9952933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15600505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6603305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6681653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25227316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16779716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6155686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3969851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3614185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497563.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5310089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6794054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8948544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13159793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6827011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3245163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10822577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8224188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8447465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5358706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12739310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8624403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14038178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8035758.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4149930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4441732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8883492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4583225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2990555.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1714647.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2628338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1184815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2167457.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1738678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4097372.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10011512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5163126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1929414.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1726668.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2054373.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4435508.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8183226.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2737662.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2560559.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7084450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11349043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13459124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14484294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12435435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11099072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8006932.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10959523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5078483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8168267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11697361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9587722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12155291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8703414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10530145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12495629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7358666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9489495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12538741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9953131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4743643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7450447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12749844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11549940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10362144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13137109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7999239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9001566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14393358., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3818918.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3981562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1812648.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2731462.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2470645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1177240.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1745941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3736937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5770918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5295646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10659916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9880975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6367699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17624728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8627522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8769982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13574639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10338624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713815.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7213847.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9429834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5772201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10244803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13172328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10685598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13275689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13239035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13002460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8541864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13256967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20597066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25568778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5805823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17128756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5827190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6377442.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10606692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10207731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13561902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12588879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4998542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4443386.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3891427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5045389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4852118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3339429.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7983214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3811845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278494.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8047701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7846253.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5490279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8925750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13533962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13950591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4227872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3929266.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4848293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6293252.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3417444.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9332710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2903126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6403056.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3625676.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3767490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5811325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6498495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8632944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3404989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3157889.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4594297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1956380.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3655295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5801828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4744557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4351519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3621283.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5321178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8398167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18358650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10204985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10698799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7374317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4094334.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4360661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7848677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11598299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12636725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13095595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6727169.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11419935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10087534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10043720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12806324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14631523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8742909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7823569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11122804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10391648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17129368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10697746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12742484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9255441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10067713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12400050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11498581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3731868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3351682.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5658138.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2993392.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3251645.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4235826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3531227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713847.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4196305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3958930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7162909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14552954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11252441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10070832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7325335.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11642634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8802388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12887455., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13286347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12944025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13345223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5374988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7486238.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14375530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12129279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13718154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13810774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14103692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9147025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8014536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19952910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10335654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11569913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7444762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6842797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11008799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7892116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16760330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16197412., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2661075.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4082962.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3633417.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8220310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8777447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3498269.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11773843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2095615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3763884.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4226319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8354162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4203370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5765824.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8280505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13819545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5816350.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7208894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8157828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4139989.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6297310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6632256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1230921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5282006.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8680507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1980118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4155977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2032752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4983089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2473281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4474872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5268076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4542646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5724359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4734907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5743088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2929620.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3751912.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4577274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5461464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2136769.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10892163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4815036.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18578368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11410222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9911971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10500406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11113963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9929673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11466864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8004618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12391929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11391486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12259412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6870742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12666227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6972864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11243995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14730079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9178255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9893982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9539820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9254549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8561587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11674043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12100269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3751815.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2859727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2250414.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3007054.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2721365.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4160634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1783476.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9047819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2766912.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4679755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11358795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7432703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8901990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13349131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5877110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6695152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13393578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11544010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11496504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10077437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8371541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11578097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8109499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14117920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10367395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13352586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14100727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12871671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15512120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12500581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16603404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13142303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6760370.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14382572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6672712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18040288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11786680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15001680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14163114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2960956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13184077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3868737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4026067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7367528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7892873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6466456.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6954625.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5633978.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5075387.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8675636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4240595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7610617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5664653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15229196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8357063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7222111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6631209.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9355044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6737662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5006993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5866460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5632578.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2215992.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5405177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2372591.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1473903.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1908220.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2291967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3979520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3225103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3073385.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7419228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7210870.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2512739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5739224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4525656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3321742., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8083514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3856034.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14223239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9093993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9442947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9814430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13333451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13751171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14592136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13255352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9393139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8479008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8784021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1122213.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12879541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12322181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11747536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14960878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7883770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13744082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10337261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9852837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8497977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10193198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9818268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8563661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4236723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17503636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2143785.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3869114.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4910388.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3832717.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2380916.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6309202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2875380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3773168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6905355.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5339254.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11846063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6737223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7126991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11330117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9439941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10910842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11087034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7350355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15533121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12476290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16912266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11551673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12248799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11899374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13529151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4990004.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11529497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9318103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11413544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12419028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3753660.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15908661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14264827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11366784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16700453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9663378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7631468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2453491.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16750135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13530790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4658896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6629075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12098951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7607010.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12685331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7105170.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4056647.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8199374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7326441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7724573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9315795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3075578.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9179560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11776610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8656959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6268144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5459501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7052610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3640070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7276517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5196397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4746601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2811315.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2610935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2735914.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2792478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2846003.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9431112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6370946.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1746989.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174582.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5395423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4757491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5502049.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4371668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4804569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7297771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5688304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6024044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6051822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10740203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10097574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12603511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9204508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9174250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12786985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7827608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3119739.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10677127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19574746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14808138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7417816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7758799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10611936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16512368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11910482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10675693., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9245539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15751968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9731927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9007192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18319854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3965073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9970018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16610879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12818661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10961267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3977361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2460104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5251719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8355449.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3538859.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3365027.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1700796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3673691.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3123031.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5074990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10934060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9067573., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4856908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10160240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6860564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8946735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8855777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10603995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8647723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12865713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9598904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12828686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10533763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13191535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12306004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14378866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14318007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11848578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12240319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14947199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9738705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13641674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3768947.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13356313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13582561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15583896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13703896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7005237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10857895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13583913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4955141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13350939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3865486.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849222.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7827085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10353319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3545408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6666737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2572326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8942039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7697045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9389026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7147014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4875217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8136369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9384383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9281721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12553178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7794768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5972024.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3571310.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3651882.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3640024.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3224277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8546236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5664249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4185373.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1996654.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2290680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5547203.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5429928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3811760.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4115079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712647.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2826989.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5085332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3017046.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3480473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1937361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9383648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7345505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17482868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7923212.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6714985.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10052225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14060828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17216936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10756007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3468778.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12442770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8920833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3985382.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18370508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11293840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12654106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9806754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9365139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13270268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7562858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10784867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10535476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15845920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12659395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12524062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3894885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12153755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4839642.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14594013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2766364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3251520.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3349600.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2217345.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2637470.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2996124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4439427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4144752.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16981878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9325006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5221491.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9481617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9678627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10526033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12623406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9198613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11664200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10866916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13496423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10670150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8963821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8835535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10778918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11650456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14879940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12540645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12646831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12212043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6852573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6567109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11824161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13068185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16590331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12863324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5135451.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5807036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9513381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3128669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4263939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8645881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7717828.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9849385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7906999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4390025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13977572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8414914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8308480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9468086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9614110., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9323257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4131385.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9105548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8242409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8685633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16219094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8046165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5951249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5987936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5623783.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3220201.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9160192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1488867.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1652751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5654137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6951727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3509233.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4910752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6661758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7763748.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4467084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8465917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3994023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7542430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2230161.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4254731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8225683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6525930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17853560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8437118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12610679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3901552.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6889360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1059783.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18339100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7436647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16420745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9570370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8880791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13175664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12156459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9914427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14556650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11789408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8240542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16292307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9691748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9572606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10909262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5399508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13138908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4935260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4640886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4396921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9793819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3612675.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2709445.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3884477.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3238525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4661835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3031095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3843109.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3022290.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3058064.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3481291.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12492399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12981700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8798521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12406827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9261907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11497687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7932412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15837313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11021514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6074195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7124664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9220778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11772962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11898376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11421215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10089641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15678232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9716722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13153356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14543432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5948257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6584980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11699644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12146929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15592713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15263200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4806333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5500756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18207138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3895193.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4171258.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3584737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3396893.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4733038.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7708306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3664103.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8302051.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7804618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8238499.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13642825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8382727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3664135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3785732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8210081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9808647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13028010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4732474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7468745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13075898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3023584.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2714288.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6411826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8422048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4904651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1835636.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1571146.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3683075.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4223970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3028243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3999647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5226197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4949072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2094682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5144992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3188217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3378302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1866268.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4776402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6507855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7264473.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8683409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9709164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10749161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11033944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13400008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6524848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12822616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7419333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12082881., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7113369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3087955.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099296.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12797473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7257094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13413430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7859650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12751179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11738432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14714696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20877604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11201459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4812578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12110969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11102565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18643230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3981903.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6070288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3483088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2943552.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9375193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3918793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2755322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4458437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6712846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3789221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10374657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7099221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13255296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11375885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12843624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6312491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12564740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10052972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13874599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11230532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13290598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9931391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13226991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9834540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12455582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11206198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12697155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10496584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12445973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13102293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16516103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11545545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9642757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16892506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17128652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11660389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13138281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11302580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12329835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8837526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3664832.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12664486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6999306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6809195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4860973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2110164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14550024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7516569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8508744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5009336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8287393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7435674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9957725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8126055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8636169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3857303.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6940674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7754957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2764130.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9454633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2533075.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5275109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2397462.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5319342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5676823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5470779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5767958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9297569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4805150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6188949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4061075.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4187862.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5203045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3025725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5059884.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2100506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3570441.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8287295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11859041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4326372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14021765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10738996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13220979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8134013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16399122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3882789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10664511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9094304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13180364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16669891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12499732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2974073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9822432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10829907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713885.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8098994.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7023159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14914248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8826820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13952941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9370440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12448108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13017539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11196612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12560532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12081173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2588871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3372641.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3650265.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1269598.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6434178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3954973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4521240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3635238.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4751507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7274833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11139258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7880608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9484335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10728530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10638557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12855179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9136387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7811464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10633231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12777622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13415576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8402171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5328454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8917497., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14282288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11377712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14647014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9057316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13338682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12237732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6048241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18171656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6922556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10657987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12368547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10739464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14955861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4390442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11708810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18482752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6705454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13055852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12915504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3516688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8125714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8067549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4721913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4976945.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3618055.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8616477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5166411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4814448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9431368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8093826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5886943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4644550.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8239321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21287338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7793536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4544687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3300143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9620026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1220040.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1940431.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9071392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2629497.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1551520.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4483413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2676806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1274758.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4110247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4571523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3199583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8655771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3144654.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4649999.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4285989.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6732973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7258235.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20626056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7154708.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9479587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8951446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3876938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12565761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11578893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10464678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8758901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10871352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12295921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9490589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13644238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6938325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10336219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15354253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9983572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14193497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7671011.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19191514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10394545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8664588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4725793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12172946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10225826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18134342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3659802.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4491308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2275397.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4204532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6457546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3846850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3708943.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4133257.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3436204.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3222553.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10753736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11478227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5848725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10729540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5320116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9931777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11122475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8937520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17078492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14393104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10597258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9687235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5359042.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9565793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10886267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10865741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5260166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10380982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8045820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16362216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17187750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5162025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16246335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7787491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10336317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13742962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15056870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7620460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8833982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8931565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8567980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6234052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2701904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8427512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4861639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15914481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12575446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4361749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4831661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4998180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3199695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9073914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4372151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5908481.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5655335.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13463475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10468357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11890226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4969951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17419694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5955639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5759996., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4474004.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4082399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4384395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2544357.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2744708.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3675809.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4780189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3870315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8347282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7303763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5114531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5602362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3188502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5190157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3406272.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7004518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13847203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13302235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11621699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8244313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8653198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14669132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9470616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9070598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3140613.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8968997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7849081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7500901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1500959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10220950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7215474.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17508806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6639722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11653868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11178233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11249846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7165958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8941021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11218817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13006885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5292732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13740962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10213366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18881200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2237509.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2780040.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2304019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3760935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4472574.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3578674.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2877529.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3535994.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9619039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3790940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9909224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8394072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10196362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13769449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8831922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5227180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10574135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7546878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11090638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13093867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10672634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13084141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15365966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13846168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11211136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10509622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15265970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15578823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12765559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15465837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12223378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5993127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10285562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17736832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3152522.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047610.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7734990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12305288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7818603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14583171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8530429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1705254.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3739097.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2609875.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5171784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5063602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485024.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5051933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4520410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13643075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8866139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10675396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13877405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10534963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9845590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9300175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5684943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3269728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7763408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8626216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1459799.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2836152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12830698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6718051.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5267144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6394447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5039822.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5580001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5298840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5807807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7212745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5458096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4415558.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2459080.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4319739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2886295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1744172.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4581203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2059167.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3132546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1592392.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6729874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9987231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3729638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13025161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9299774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9838287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6523551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9925397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4522365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6052261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14875992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7119780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6285077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12829271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3132975.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12327288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15189326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15018590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3628830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1824297.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5053075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9640316., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12700695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12689414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13237607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10889005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3718519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4655834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5736652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5678180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4972119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6410312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2095689.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4406571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7318182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11560120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10601500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6902087.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17196552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11583109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8819215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10816925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9380979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12854580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12771998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5759915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9313555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9126603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13116620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14517556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11094081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11803359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11325557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10733878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10341523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4215293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26049586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16721166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18532946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7598552.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15049626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12992475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5539964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7001787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8673504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4086221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8209838.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6240688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6533294.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8820844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4232173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12508955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3720354.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8378348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7396796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10296470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7711395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7967081.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6365746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10502587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6139362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8229678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7477302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8154646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7334531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6677263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2961171.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4546544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4432248.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5182764.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2135242.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6375817.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1492334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6479074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8813159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2950709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5379737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4082925.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4171334.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1800431.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1741186.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4126078.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4116127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5939187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8448442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9373047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2760707.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8325044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6507016.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12167670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19938606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13407356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8099379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10370824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1566690.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12169222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10737784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14262078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6443203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8876953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8126372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14514672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9068728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7272021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12316630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12412291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15760517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4548564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9031423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9976297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10342098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16445978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2937523.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2926076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1260028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8901488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4033929.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3889787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3383031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3665395.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4268470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4851507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8853268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10028213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8054804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9539961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8839560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6899848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10361712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11038890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10747141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9548522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12094989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10496178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12165592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12271014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12197546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13042752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13767593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11648750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16446790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12544642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17943720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11018950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20019990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18247910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14508069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7224284., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14303465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6807108.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5145555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18168430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4580863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8567721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4395364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8257591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7698525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4098257.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4498207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2343865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5904126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9564534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5069077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8119669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7339708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2684652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8765093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14431050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7617218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9901823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7229992.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3990397.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6832421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2792206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9141896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2093732.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6585911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2190289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2716463.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4794525.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8694843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17057074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2883613.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3743663.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4156893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4454667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4515721.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2256264.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3622915.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9304532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971781.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7536362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6835886.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8967601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9987281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9134855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12573349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11696461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19635752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13021502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5813956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12823036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4044448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9496070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6340264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8257298.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4409130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11245117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9473190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8387910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10092484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9539079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15886194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1943199.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13588872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10502338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4875579.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12077256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14979643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10881257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5878293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3328965.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5582332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2293421.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2635133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3019051.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2987399.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9497169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4201273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5361255.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11341652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10399039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8191200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11738482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6044364.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9799375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9645857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7727562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9792402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10842785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9620652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7994278.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9744927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11337096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8173487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10688941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9785292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11794122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16336450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3217185.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6036587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11210491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7629589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16045768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6264848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14627893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10609599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7378701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22884468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7454117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3695909.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12920906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6485829.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8333047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3321214.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4385044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13527255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6897246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13501868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8449514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3071966.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7279889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8700092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4291330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037009.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10436817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9716743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7087579.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7497220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5501487.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7758880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9718388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6076484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1274857.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1716904.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5208542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2443261.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3045527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5150481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4326178.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2716402.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5103383.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7631971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4587851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5449140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9900216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830778.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7497797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8977495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7990434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12579511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(876805.0625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3950040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8992433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6728543.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8478708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15488650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3992295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13094461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6172284.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12226711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9021883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10580830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12137954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13433252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7480103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14649752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4219903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13567971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4585019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13095534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4398891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8479960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21772152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3035641.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3103749.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2361367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6105480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3063461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4997820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2944251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9689111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4095058.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9607788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11636329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7840928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7690286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7649472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7552561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11862350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10732316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13617499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10449342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8097650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11349627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8936540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11304502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14341383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16769323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6902922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12530264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12800518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14989138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6799878.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7330464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3723347.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17976838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8699755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10940584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17133492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11570446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7287745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14758894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8203585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9621757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8431696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3612873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14217758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4336073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6977904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7304965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7006708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10975574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11099369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4927023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8235397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3301089.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8295769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8828714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5796085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7294590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5152353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9967725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1868229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8178649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5875464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5423917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2478479.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4805130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1400285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1568167.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6069164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3868560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2967517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3633843.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3844120.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2801749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4640435.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4383587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2375826.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2238377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5990088.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12926314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6645131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6893374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12134109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8631593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9444197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2199444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18611486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7892314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10145213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826051.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7903928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10817716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9601589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3440731.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1186760.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13355182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16596456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4645342.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12652482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12586094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9448959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12029322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9200767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13153843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4462841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19011292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2272314.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5982940.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3864904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397246.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6511780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1176341.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1467451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4753169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3581457.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099414.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11412980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7582982.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4871077.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11841586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7620108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11146607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077811.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13966491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13085065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6923693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10470905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10762662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18203044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12929744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13786689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14327087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11205257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13619995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6039729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15383741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9876274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7412242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7109643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2609666.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19383566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10170608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4843506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6523493.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2944208.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4263527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3305240.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9476816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7804102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8082262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12986508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9729904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8418843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8010874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4924675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14146235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9492337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6010729.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10145180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5241385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3514411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4433751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8116776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3134013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3199266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6627290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3384002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2357224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4994734.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5159753.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7321847.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5925241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3095058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4789542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2202079.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6723801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3665729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3481801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2902472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3429121.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1669536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4993649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4077503.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7204522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6738438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11500776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12095719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13095427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11653408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17481568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9179340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(971681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8559979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4042684.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8572635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12268764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6530590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7729755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10511117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9407036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14161351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13066454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9043336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7604727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19604946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5034362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8609633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7122737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4346149.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10898727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6166806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1255022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5200334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3902104.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3725004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2333645.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3954945.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9270730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4967124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6340588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4969742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11275706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8548437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9717824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9118345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9832782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7583439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12847716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7474502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9544275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13217086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12791686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7813948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9186952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14249462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9005879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18078500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13269325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14584510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15242543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3946668.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10321783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11624146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21743322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10792399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5537131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8299180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6708106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13516427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13922479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1642126.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13336313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2883196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8502884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8386805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3974396., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4553009.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7204239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7457131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9839725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5252820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3553275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8125170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13509866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10538335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8691728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22477762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4684246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3793633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7185877.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1305339.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10473987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5480892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5439373.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6003325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5310665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3220632.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3500103.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4573706.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5596275.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5551939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826910.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5605903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5740935.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4550806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5672867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2293703.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5747007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8163956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3873881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9912926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10311804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3974785.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8190354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10965445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13255892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9847525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7000198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10277411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12704566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17277112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7485873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3663020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17357618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11685286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8029589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10510689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4622338.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1897176.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9118243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7616056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7244301.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11006840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8244523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13084642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12500874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2490804.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3670053.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1300825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165718.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4251163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2717276.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4221712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2666036.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4404343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3411837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3863688.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9243832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10803988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10900129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6644245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9653951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9402583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7896454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10761985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8287532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15463166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10603180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11448599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10152255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11576570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14316377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7097682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18343164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13304236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12207239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7111197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4961255.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16041926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6336599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4802164.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6431636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17768408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15528114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7146165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14446777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3539458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13171589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1345718.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6967172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4959594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9282235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3521124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8806570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7970048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8326247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11062457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16743691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7590774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3993085.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9639180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8063057.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8380513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13653136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12350983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7311854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3243378.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5215199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1523463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6041262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2706799.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9029263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4618048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4947337.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3683381.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(939282.0625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4297871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4968456.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4420414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6237124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5728719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4273115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4457949.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5511333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3284718.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7961773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15149869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6761147.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14312879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9578778., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12471208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9026637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7808587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16520742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9096975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8957499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8799731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8636285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13707075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10928877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12927340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8646100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9385560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8348895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9423514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19441008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12361694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5568046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10007936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2782361.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13838357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16627948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13358678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3194745.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2761371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5950764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2766507.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4133342.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2652532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2115355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3193668.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3355197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3886761.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12319122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10105361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10765226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9510857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8364444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6326452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7640567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17510272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8028241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9588964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10511136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9564384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12268562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14525794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10056720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11144097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11699229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12999621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13076243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9628584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12264277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8597492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16837998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7870912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14012362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11686954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6855371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10472851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16993806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12403530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7678029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5829400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3601485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7507072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795374.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3639727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3574040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5385320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5507302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8954596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7939591.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485612.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13732949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8763573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3988636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5152194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16414332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3924022.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2067529.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1786605.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2527877.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3443548.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1032882.5625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8905517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5809081.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6779803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5579422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4345623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5333655.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5935101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2586723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5298651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6408736.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2624206.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2610017.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1693595.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6186448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6159431.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14597477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2277091.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3545928.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12633646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8138585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4108025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13422054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2728403.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10327717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6368307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9013546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19279686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8093410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8569081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9602264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9168942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10601991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2009218.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12862881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11861656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12223747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4909497.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12805601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2486204.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12819431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10012824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14344654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3176977.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4236454.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2467071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3665767.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5549615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2954059.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3486597.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5134102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3312837.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8825078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9051580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6617244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11810289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7747114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3435200.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9398118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2865786.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9895736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10635912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10490578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12975952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9656199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12406643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16617054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13054667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12218301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11418983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12654308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20607048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11287700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11535648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12135091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848204.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11117613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11935433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8052910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6387925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7662257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13828984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4291970.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7868907.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23267246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2910923.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4767328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3958651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6819757.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6827602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7330266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22894320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4670697.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7851363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7628027.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4637224.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4835759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14272097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5057123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7026163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7200858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10043191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6584870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5708061.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9326028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1733326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5118045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1062544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9005571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6008928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3513318.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3870075.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5106792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1218225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4903923.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4043104.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6205095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4770620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6120875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3642021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18351056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10404244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8992109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12981722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8008571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14673519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13210471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10980327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3479501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9656572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9579310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18071264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2826965.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8669603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3948551.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7335815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7793633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11094913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14585459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13834127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16296020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5432032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4664159.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13515110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7116933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10636442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14951835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4065466.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4232325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3417421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4720785.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6876712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3704745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2934200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4715770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3370545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3521918.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14346507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5258839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8622834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7756389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9082509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13841293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10373527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7057866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9224672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13900306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9652722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8158946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6632594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12897629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9262980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10826582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11006549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17836844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13063404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12066611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10998287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19609180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1436371.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6191864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8175962.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11462403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13347292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6376651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19696112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12672110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13202005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3343304.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7274121.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7717772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8657149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2703167.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11695873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7187617.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3248468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8271831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13700170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3388627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7515043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10444109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4956727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5952951., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7047524.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4770185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6520351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4594486.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1827460.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2233340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2187240.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6768989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6279594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2616994.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2595556.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16045995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8904958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2999882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4597988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1848656.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3714214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2648982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5032970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6835048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6373230.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7116499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5012342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10332936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10086182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10584407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19241812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16780720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9761828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7601005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9903779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13411085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7868739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3984136.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6316129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12013803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6685037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7945434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13823117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4214380.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12719142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9540846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11122658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7692930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12886932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17959830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14119259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13584213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14104722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2106808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3662881.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3611348.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9088029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4273935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2340337.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4259822.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4168908.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6272047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11479602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4958454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6690145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9989815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10028644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7016713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11870335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13908902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4929172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10040373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11240546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10271300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15367930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12175086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10282035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14431324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12524140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15118717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14318986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11822795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15186667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16272927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3997625.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12765881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11676165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9798572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12591346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12171940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7895001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15519753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22153274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4080248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3432716.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8069689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7406957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7701174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9796101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9259146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6794573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9256271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4545498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7027399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9842621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7510302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11253831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6189752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7596910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10204357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4135027.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7728306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6199889.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8383312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2929971.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6047678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4970062.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5835470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5482050.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5001161.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3578309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5746435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1592098.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4635099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2518715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5204100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6586189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4486576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7748519.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4544181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2704615.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5465235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5948433.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10592656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10706022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10186363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10562436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13706381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12976713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13270059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2497572.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3462888.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14754635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6930259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10543665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10743100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10209163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7133172., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16609534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6672593.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12866792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15055854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16361379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9780191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14713105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12836998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5527494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12565860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12712702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15259564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2209202.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3868944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3365901.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2714273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4791609.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2440514.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2943735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1828391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4218935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5725855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10332116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8444963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8539235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8291216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9813934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9205306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10855287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9262291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7874289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18444320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10327664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3761124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12590663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11905814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11458245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10123342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8317594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15080428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13637707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12994334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7079269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10947825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4718781.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12075439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16288123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11566839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13088618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10812082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16093380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9498946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22299670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6904639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13236384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7290480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13783547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8754598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3836741.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4599363.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2615193., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13808046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3422503.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9440013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7323308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9281821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5695059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9597766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9071553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19610312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7565146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5986285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7016598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1435916.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1922303.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4557685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11142826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3325125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5344173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4329176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4138306.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(933583.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2088261.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5498585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2703186.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4394901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3924251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4808587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5599376.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8363963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7753247.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5562059.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11208680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17060226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14517688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8863273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9533300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5679324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3559610.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8653929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15280175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16629985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9613492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9676717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13579615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12260152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7739410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9082978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13858626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12151043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11433716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10945281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11376976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12230125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9405546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7148215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7378555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11962420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6164463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4665070.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4154426.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3718817.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5185691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9017316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2857845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4271916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3939692.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3896465.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13104377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6963278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6955175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17245798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7573687.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7121287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11810459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7032032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13402354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17325768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5472732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9449882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8770979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13814210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11293139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13150435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7207944.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10881826., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14078250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13998928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15769284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10502864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17840930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7981618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16955746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18769430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12949681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10681594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8181826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14005457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12694144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3484318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12328066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10266979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7465104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2480337.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8004555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9704376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7020232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8652626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3423741.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8358885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7043366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10326964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4924403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7771675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9760788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11767392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5871003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2993421.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9835371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2617772.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3297369.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5294712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1593806.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2774039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6359036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4804026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3789427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1592453.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1638316.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2499235.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5882902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4007580.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3021547.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2560394.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4675479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4638003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6353289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8709659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10704620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11909420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9257146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14997126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13816233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9156545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10662106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11983497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6926826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7899301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9399482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1377220.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9952344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11996200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10934524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10641116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12566922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4352493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11035360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9018634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4622340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11483567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7198678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11071320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9391945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2623657.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3559202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3721601.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3119775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9040710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5963793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2827722.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3782695.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3702459.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4878361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8838075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7471198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10330074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8565612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15747699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12552442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11903381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7507200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8704621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12754787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10613372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13295058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9753068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10714869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17713724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11117202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6992737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13232334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13409364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6171227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5741524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5968224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16884448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13238865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12547613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16360912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7179369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14850295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16346230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19282858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7997498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7442252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1451690.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3131214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5257663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9530958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3753771.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9179212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6858235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8550720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4372528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8581745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7756985.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8775530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17557298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13197652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12929352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4088167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8045433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3523808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5748529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4495215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3492870.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16475527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4977244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8598338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5160935., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5254787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5990957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3975050.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3740381.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3147503.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8429021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4328529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4687501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2508716.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4547979.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5128539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8931063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9260727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2542939.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10438447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4021530.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12519543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14455066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9956795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3186539.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11948996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18068504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10457868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8803190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8144264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13758445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7218742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7816508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17133412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9647291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13264460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12371046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10812253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13103043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11308538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12609087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12981648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14574162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15878427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2377001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4252997.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4019404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267418.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3527562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4667648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6035018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3946712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4753478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8538434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9133306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6558258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11343754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7370708.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11372339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9368959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11550411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13440430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9763643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10743278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5085752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14613370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11365860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10249609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6702248.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11121164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13006496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19617396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7643684.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15558573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6748483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11922887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11989627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13915203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15790744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11564904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15092676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10495928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6104280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3368931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1745953.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2785034.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7367839.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9337768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3270740.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5950981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10597673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12783975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8810728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7823280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4713765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5597985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10916350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5633925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7634577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6439606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6391567.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7242938.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6307253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5332359.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16744675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2904423.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7715438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4539024.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5403415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5756669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5564121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3583586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3742265.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4881936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2067988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4015889.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5498362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6702585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3008569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4221645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3881326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4890701.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9275590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10246842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9024771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12582975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10942379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11753133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11274054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9090026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10876408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11964329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8270566.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1487143.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5126390.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8820297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4197465.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10089408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8461069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8851283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10464174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13013892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12520973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5205425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13730851., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16365365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5838219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7665048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20747934., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2559477.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3675359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3950246.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2712406.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3955124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3729534.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2929027.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3468862.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3421267.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4755128.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12777181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3438670.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6556077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9008463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186084.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5841868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12104098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9064844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9412875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12547514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13156485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8129879.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10707162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13856451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12048662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4387274.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13845162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12094305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18436850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12768012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4354401.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5341772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8504246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7496061.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7988180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13401833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8384853.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6421779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12309830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19346674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6063500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3430170.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3207246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1254912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5508126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4930440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11910499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5187118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4177504.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14072978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10776092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17025252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3416603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4164081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9586025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8753199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4331878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4314641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6967633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7793100., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6591236.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9620962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9896056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4724445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6203327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2239095.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6378101.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17280762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3836579.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2042512.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3757941.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2605455.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5414980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5519332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7395429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3589104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4699001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5433144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5367048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15522438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7447426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13273214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11529229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9001415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13212537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9230809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7279500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14326180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12554194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7294374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11019805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8976766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13629422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8927235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11409003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12385024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5065724.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19539802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19212034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9169166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9208627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7937917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5029875.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11504025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10919393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3089131.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2682579.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3804687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3319819.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4314227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3771639.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5517351.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1864012.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5466419.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11476594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9456128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9651641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9967446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11148106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6923651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7195697.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10253972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10960632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10952070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9403923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8648570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7704262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10580894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10603163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12200644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16708636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18734510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9834384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12029772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7250778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4065677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10386334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2244292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8180424.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10249622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11317562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2736029.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9979120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7809135.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9182039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13200092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5519339.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7613527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9768418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6183518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7146346.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8056045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11876442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9767902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4576803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5846853.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9943885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8232308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10245621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10096793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7572713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3882922.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12426872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13392619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2901680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2426618.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6839197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9988955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3134983.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1130077.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3430245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9103309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5031684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4041559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4535508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3861599.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3302487.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6246251.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4035700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4727918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1850117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6503536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2606985.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6874086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8078335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7931019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4068263.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12539926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13140007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6624469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10924065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11941078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7216149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8777699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14703936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11405574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12556184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9161377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4125743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10020059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16099955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6588872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10473717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2528447.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4761940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10794567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12864425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7934637.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11078458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9067271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9624184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13667260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3949321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3233152.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3060756.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8558818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3786139.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3354159.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3597244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3954403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8966488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3947912.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10317070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10520696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8704930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12583263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8781570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9099210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9162062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7145074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9196976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7968756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10229995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13165694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12576319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10451230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11369907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10456058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16732934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11422501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15314339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14588463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11404231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4447015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12141467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12168345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9032959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5244542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16675665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7159628.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9028638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9854289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4914211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8583962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6674660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6530079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5592844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5488779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2536909.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2963296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11421976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13453763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22647428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8893845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9316972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2992647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9525107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5295250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12814025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12497166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8203959.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7514848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5957929.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4930021.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8661977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3360841.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7187857.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4006579.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2957035.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3062494.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6454678.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7771732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4274326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4823994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5434897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4373638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3974245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5530532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1789019.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4766380.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4507439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10046799., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5612288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12114737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9952518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8085527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17563736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11552717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12290784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15376506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10453817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11711574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13362249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13998953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4833154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7645122.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9237940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7886211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15560173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9943346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17065280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9605649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15021449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5186045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10194298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12355025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9753566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14007543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9426921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14335940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3909470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112416.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3459910.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3111512.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4331218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2278372.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3561243.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3203377.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3416032.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2319599.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13050364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7899025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7792809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14945012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11119865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6842268.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12617196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8929616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12929723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18736850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12208161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10709063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11834577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10836621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10936936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11081420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12559854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11871070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12532330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12797220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6948529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5202098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6361773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7938795.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10306326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12343161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16564159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13828767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8590221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10343895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11079132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8339978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1574598.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1566313.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12751802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4700485., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4778959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4958158.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2442768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6731624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3105055.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3735731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8910349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2779558.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9000184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13405767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11991950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10840200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5466557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2496209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6189062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5861700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3885656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2721272.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3806832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6195833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7348241.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7676340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2414045.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3306361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2688684.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4629722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6752911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4292078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7098432.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5198414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4382980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5959433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1794898.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12176495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6603289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(972060.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10445000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11715589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12569258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18126494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6400609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4458412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8371951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8293291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10352425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6487982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8809821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8930824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8216659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8422083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5275107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12373403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12027112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15280153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15270742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12172784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12306801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11175220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5025681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7067658.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2904896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2332110.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3303800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3191188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3736406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3763856.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3152830.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9483123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3963080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4607876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12949278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7600550.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8815432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10538261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8985654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12529615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9268451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7845169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12712198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9331249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9152327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4999594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11089453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11247421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9842588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10783065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12149681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13469987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9548136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6322436.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7155485.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1594599.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4811175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12674932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11943512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19161518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13521612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12984023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2206227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7106324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10861884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7103963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8821909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9804114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7770605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22263624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7514048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9581014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3373580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13265198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13567141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5175577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9981294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6470663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4683068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5544942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12232478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9397121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4370746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10528145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9059946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5669373.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6675823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2806744.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1821239.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2914294.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3255305.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3229192.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2876812.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3686071.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2678416.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6090259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6782517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4462207.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6774365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9699865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7706601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11046988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7474761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11473259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7209014.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2147545.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6133897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1643680.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6545475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4595067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7944577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11481175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12163634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9075934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9915424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8934089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15575846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3979374.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9231302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9500696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16185697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10819361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11641535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14586801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7111818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4816336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7738588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12691931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3484074.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3046415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2837828.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2873401.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4031774.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4138104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3474239.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3230818.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1646917.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4560083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11738915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12009931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10459255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8783446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8242116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8853417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11511672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7858859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17894854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14666189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10003177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10218756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9451105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10595928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11230146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6176652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14135010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13198768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12053871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14159125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6755828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12454140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5802776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18466806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16840340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6878755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13261682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11512073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7789834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11850945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6001036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12809374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2712124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7756200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5352410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3834181.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3924606.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10731323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12578383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13700963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13918031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830598.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8155415., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6847384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4387927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9289206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6531705.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2827463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6458317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13418229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9862651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2172218.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2831696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6142082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6601044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2393224.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3289901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4033525.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6123776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4228700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4916448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4925644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4566176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6285736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5046452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1787429.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5318554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784497.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4069259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13430103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10903990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(498471.2812, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8848081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13049314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8034874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12215853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9409905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5491285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17550320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13959359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3910055.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11760258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9806823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10068526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9096437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8406002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9961891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5139904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18346530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2125836.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8332850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9839646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9268567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9321037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19709530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9365661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11100676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3248936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953190.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9424284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3854949.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5008569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2273994.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2912866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7164317.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4686448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3031941.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13214518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5594695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6774402.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10355340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5410184.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8975388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11407676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8778152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9781991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8174501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8258945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10231998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10836352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12138226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9109913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11868150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11376867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9888064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14311739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4164654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6415012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11736389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12086971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10743629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7471157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13357530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11284989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14672810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12882222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9081280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12982029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6298737.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11879302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9507588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4816114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6189013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8804713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6382776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11090361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13810336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5138073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4139977.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8662329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12094732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3420524.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5081729.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7667293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8474379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4465976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9905069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9815575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12207355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3034271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9173548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8508022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5576189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16234360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2521932.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5413871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3952822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5394784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6257071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1401720.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4291490.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4635344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7232012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5149536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3742579.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9283701., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5057342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10356347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9244816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12805024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4367423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8455044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12542315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12073954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7660467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8142663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7869983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12524290., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(14350385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7721944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20026930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6574918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3935817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8722938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13611658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4897366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11068052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12590301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7129993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7491253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17733776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4791346.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3301440.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3123917.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3337493.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3005177.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3305809.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2380034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3867959.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3520232.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3588591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3700544.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10949023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7480192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8039161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8940284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8169733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9933541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11827564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7775250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9352082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11566493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9875581., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13303057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8985141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10230382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9550848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12214512., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8820153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8301374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10832091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26010900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11267006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8444517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16096118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12301767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19650812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10557487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9621975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13112835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7926790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4317227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8500574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4184808.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6671763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8257906.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8915530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11266427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4055541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3765742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5244943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6333626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10398520., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4932428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2327924.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3932883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10112053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5365676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6942368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3476470.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7785219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1352655.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1993743.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2814451.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8849468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5900125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1170669.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2666103.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8003235.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3607772.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4339313.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4285001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5769406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1309389.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2561734.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1745789.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4530843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4284103.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6301182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11446470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6897942.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11444895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13781315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3411236.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2990695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6599842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7142095.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6238837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1453118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10381927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11748858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11821135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11537346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3436795.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12295836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3641478.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19049684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4911362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14571877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9666415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8538114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10957785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12959097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12377354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8630552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11828377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12046322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3841889.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3586072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4891410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2624899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6411527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4630506.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4075102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4549430.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4094703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7959784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9764884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8269715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10389222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7610903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7329104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17830840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16072313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13019920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8778497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9078845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12496247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9904209., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13955153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10862202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12819705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11454985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9516379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15448023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11203218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14414009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11666457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21765986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11819238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12471626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14896617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8666155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14259161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8834742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9679556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4973328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13423274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2672341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8701134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3797602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13720424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7925767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6553104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7927260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3320960.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8348188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6210232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4790906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7977488.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7244163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5441406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17248490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3349930.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1669814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5860849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3380914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8566584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10653821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4541221.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3027380.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6934083.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3046800.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3402599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2047314.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6164422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4724529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5424147.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4910170.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4629919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5643668.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8175628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6129547.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8838073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8431938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9058542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10766150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11461444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6187884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9540619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5372794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7976732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10218681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7751451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16958048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14368869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13229102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20128638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8889087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6680539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7273955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15208596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7660022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12824174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18181018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7437070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5417722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17331572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9522329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9017907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3131385.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4796496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2864535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2136028.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3774665.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2982339.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5500082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3299464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4589144.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9396568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8500618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5760832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9915208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9842451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9646154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8511468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8793422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10651176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10594836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13912242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10000427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9140426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12540061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9903648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9563930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11632801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10448637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5822545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15778815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12174474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11807803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17731266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11620093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6997752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11988492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6574426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8509315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12550194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5392883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15726168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2869968.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4347732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3139936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12867421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7889289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4005513.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6467123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2288188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3906903.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5730646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7168197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3154601.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10209735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7925653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8586023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10907207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8694490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7425589.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3132434.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13905987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7354656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5311060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4841004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5819785., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3321007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4558102.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2752445.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3056205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3280061.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2365642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3048950.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4124111.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8013343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4070903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1964363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4759058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4376260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4151811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4762124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6620790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7183638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9225692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9725618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9185284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8553951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(606897.4375, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11810564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11219852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2572032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10076680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6581179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7102897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10347168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11409225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3459535.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7552998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1800425.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11200759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13508021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9507846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16827568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4187801.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10819812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418425.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7864057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2615173.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4733223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12739061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2480208.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5798372.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2172305.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2745854.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2403470.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1853266.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2816056.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4665707., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5955759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3477671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11272848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9563431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10496002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9347427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9692480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8412139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6578919.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9625301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13713413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13407439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10654947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10794958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12812154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13676958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10131219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10981370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11827086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11032257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13180717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20161068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9039047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15886042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14923147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13061404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12085169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7197866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11021867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11482123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6606647.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6659968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2740337.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8919842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12628690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7738116.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13183154., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9437158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21583866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7355546.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2494341.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5941680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22972536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4535432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6883095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2684453.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5468546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8789462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6351306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8321442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2848697.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12174094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4626235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9299146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159309.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3047283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5793335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2860437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9346996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3045460.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4034808.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3472897.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4354295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2338219.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4778765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5782341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1651680.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6800778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3758789.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4535868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3211037.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7715691.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11028819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9362521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8492351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13884215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9905787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9182938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14286649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10234513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12459105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14945649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9994384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10820901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4323542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9364507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14524545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4054454.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11742889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7683338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11559531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10585323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10997812., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14516673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4915478., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9888617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5306709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14955248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10549671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4819546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6334440.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9504093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3741323.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4470165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2734463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2758820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2817463.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3341187.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4951004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8722279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6859610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11557963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11585883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8752266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12199186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9576959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10175004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12591187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9131813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12971954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8116215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10682196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11302839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10764434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11125471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11535972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12496750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8157381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15410408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9410642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6186249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11639610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5955728., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11802908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5722005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6391409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10665679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13900186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6746262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9872122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8564804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7674308.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9162569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22820954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12369816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13168549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2579902.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13699765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8742684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8932691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9151069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4855533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7829768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14164238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5619827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4977735.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12189896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4147460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6252542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2205248.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4287413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3313764.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6279026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5879139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6290460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8403005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9110690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3655800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1784268.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3555931.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4030652.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3340667.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5802273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5053337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4410406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6773153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2423734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8416852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7306354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12818240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7584904.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7768925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12300177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3671224.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12044837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18139026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9857655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6836634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20205316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6361456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2440586.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3084005.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1437297.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6402273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16488554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9842404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10669865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5516924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12329122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8757806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9968369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9809259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15097696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9581790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14213381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14673162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3915202.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3715802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2778496.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1804173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6329953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3121058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4456125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3386967.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6642523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8352288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12806078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12558853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7230030., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8809483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8595526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10963223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13797364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13682656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8967623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10795432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11371651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11298494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9931272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11804094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12366020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17072544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8149404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11776291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15285999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4028964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9421573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25970240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2592129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7641370.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11359795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6506828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17307018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10933318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7969634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7908302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2987814.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12816939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4422025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4419215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7116136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9888670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8953866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6750626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12678590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7157702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7001673.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9798048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7447864.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11274172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6444582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3820811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6851651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3387978.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5560097.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1948491.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6460234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1199444.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5224412.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2600078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1651196.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6174429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4127865.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4917817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6600358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5217781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1625185.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4925757.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3626865.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4499763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4544959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3967613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5958431.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7545571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14783480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1334361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8234440.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11989641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9761995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13343487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15244667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7391649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8038473.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8115073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3960575.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8397955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10842286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16949990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10422864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4307932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4000712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14794555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10884786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9909811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12019775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11443318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11768096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7006560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8038973.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10938807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11520148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3453396.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5890028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4143603.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2910447.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257708.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4105048.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3492786.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2764286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3216798.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4528820.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9767294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7681765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8661470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11666065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11020431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8999169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9321174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9466604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5087911.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13209714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10894964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9934487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10003570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7418179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11949098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16810902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19789554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14343482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12548510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13468708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6900633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6640745.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10734289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12180725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13768907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11606329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5442834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10054682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16599303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13981630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6359160.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3310173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12783732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8115731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5014354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6918894.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20383240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2507046.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8432743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7775400.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8644047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7221800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4774523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4854058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8068122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8079038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9768784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6523745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9770575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4841418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9056405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6865773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12449770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6123365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8033826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2212325.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6743239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2471413.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2634215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7566085.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3125610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3709072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4401526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4457521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4290472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6589983., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7894176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5334523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3776947.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7282236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8419805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9240874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7977861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13563854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7150005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3302231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11136923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11008646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9440042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9750909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19634126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12993739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6947830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3137557.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5595760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11974169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11658783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12276443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17036752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17251220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4238962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12569669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15311076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5709379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9492453., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10793647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12911750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13272668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2052930.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6140037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4075424.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3979630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3689730.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2890421.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3605308.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3375998.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3218663.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5904647.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11081301., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9297205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7163677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8172245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13574769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8843091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13393538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7043176.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10701190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12986115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8343831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13036605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6451189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9911899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11585689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13302885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11491032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13937898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12848264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12336473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11487544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13588814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14498414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17820252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17935450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11465192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8281045.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8758790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13112200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12630157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8777921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6952183., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8358644.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6297005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13522092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13257144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8130106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21197522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6713938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9527502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9165685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12859136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5424550.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5005222.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6154541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8170214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2858833.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3759487.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12654388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5769025.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3444946.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8626043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5791527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8684130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5020317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3146430.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3105406.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8496546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3002683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4798047.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4818275.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4779841.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4181103.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4223018.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6986939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2979577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3916101.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4677836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5034140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10600454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20205972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14774214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16476281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9287047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1752732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7874938.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9912867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12881731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14387213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9864827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3132786.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8901747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9240580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2392566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14057876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12336662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13048578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12123916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19840960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13637621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19896806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7216231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8967421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14387477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10363185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2968347.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2908117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3148823.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4051799.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2953943.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2886479.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3557498.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2449687., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3259201.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3909511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8794450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7808139.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7913510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8988596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11745560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9069584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17401928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9098294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11380995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11354410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13166516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16671164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12287585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9846554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10915573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10541567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11168398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11409892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12933323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14108694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3659617.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9862856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10027386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4859763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17875756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6204636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5593355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701086.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17477584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19032968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12859376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9230177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6634484.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3913440.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10601727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8928886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12302503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7030322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7550867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13642904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4501713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13034229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9200997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6543583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6186190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17781352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4535455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7490800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7475762.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5530877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6423266.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3602807.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6134346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3328443.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4757912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2763351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4714777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2732018.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3103686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5547141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2290285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3422005.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159591.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2757084.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4836310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6545883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5725924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9794819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8135598.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7357278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9338664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17545060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9586051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4121743.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4229162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8451578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10793244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11308382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9637289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12700754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9289117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9627659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9213957., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12045659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16720361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8923259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6715582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10251012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13959352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11644272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9816884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5726542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19956858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10108468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2869605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9748371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6831407.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2530718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2376062.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3247194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3522381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3637865.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2645444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6503659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4101616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3571552.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5555473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3617387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9629709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7775932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8274134.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8957337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9440531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11733573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10374371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9929536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5720576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9306752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14147445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11209384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10467029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14888272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13767096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20662824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12168342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18031656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25170876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10169244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6935722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10236099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9728968., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12723404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10732082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5586534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22718662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7365309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3201576.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1555680.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11142293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8966623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7116215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11646827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4397581.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3848470.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5404589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9084095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6696324.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8901019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4690158.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9768208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13391084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9389549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5332358.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7255805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10416326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5592358.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5555792.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2141381.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4886828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1853198.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4668733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6258859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3509859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5644278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10722574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4582949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3912273.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1761452.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2663246.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5511743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6330272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2732610.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4642232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3575041.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7303190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4896318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19258328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13736533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11434081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7119859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8692356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9359023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14546034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9668815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11790235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12065807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8323649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12339620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9342005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8953716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10192106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11436644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8873157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4846616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13313004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15343829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4786490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14093718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8995646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12307625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14387883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3183603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13591358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2665137.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5937648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2212509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3998182.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3707580.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5798067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2247549.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2955621.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5502830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3431737.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11383609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6787031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7938545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9819936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8953738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9282934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12248285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11120594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11756088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18549554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12464589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8889138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9208646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12430954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10694826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11469480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14346580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8978702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13731722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15822142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9799049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12870071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3839942.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15867340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6819398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5777402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13644415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12041915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16696383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12558580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4941480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9048421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8000571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6203744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8558998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13524307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8478944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4434407.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8105091.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8743643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4019107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5421761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7785875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12404836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10651516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5752835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4624135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7757694., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5687825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6858883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3383646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5728584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6193913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3488392.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3330985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9130774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8551939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3112114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6616272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3838325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5694867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2393009.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2144337.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3555544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5328280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3466154.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8031231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4627367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6216839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4980417.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11779502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6396631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9871152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10436093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11724139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19568722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11437916., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10902752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4337916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4703190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14225559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17304336., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13518169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1426974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8304019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15396244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9965085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10184956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12442295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10697556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10816402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13873170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8732780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9884673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9425086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3979705.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11279600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3795323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3679147.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3181234.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3185646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5553966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2772599.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3354967.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5816272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7185532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7406896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9603859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9589863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10835359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13410412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8480626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17002232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9234823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11111152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13324627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10263039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12505039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5364933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11448666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13465916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10506788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11383211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11958091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15064840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15940650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7200240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6495919.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6044489., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11635172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16703709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11461947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17530898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11434516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3661818.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20398372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3140298.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8696338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6955073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8667702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5369821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8862118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13154875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7277541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7361147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9908335., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5253649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7438777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8225482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7639909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8218628.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8782396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4482362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7840528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8392898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12891330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3240274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5800373.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5180699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9409212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1821098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5131090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5342739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3507324.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2253262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3864260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3802488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2759017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1098631.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1276288.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5842980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4605140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5082341.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6836401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4597872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8563742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13484097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6482880.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9896545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9367991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8173218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11456502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9283644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797002.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7121834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19773446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12942084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10777898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12034776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3978178.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12191902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7688023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7392967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9855281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13166436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6672442.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4400648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10847345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2781315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10473086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9406888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6362623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2573717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3525656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2711468.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6566825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4755393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4282267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754757.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3773842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3449898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9653788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7591152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8160276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10942199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10291924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10938572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10642444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9360418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8368602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11281105., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9615106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10053074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11656534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11504388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10129994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10774421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10904137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12853054., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14837186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8299325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10958295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15087984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5892774.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7195942.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16037244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10796517., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4176735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12380323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8731975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7450745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9200026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1299687.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6259545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3736646.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7454040.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4209572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2341067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11425165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8050524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7745699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3009023.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5487605.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6962770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4837429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7377242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2689881.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20938710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8681097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3493271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7224286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10128681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5288568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9145463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5812872.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3189942.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5892026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9603002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6260682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(937989.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2549084.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5771938.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1657597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5027661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4555069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5252166.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2642038.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6459911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5166438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11502454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9425556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19957196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17604632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12498425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8923568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9886984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6878145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12449508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8179423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11390681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12631044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12298303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11547809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12365120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7813107.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7001526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9805943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2303184.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13382661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14138505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9753703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10957338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9412948., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12353940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14615232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10979386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3876173.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2934090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3212914.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3394796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4161759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2761246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3282989.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4521441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4405877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3417096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10367877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2733958.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6625133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10801759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8698862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10411776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11152225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12194478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10160099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11159677., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10304014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11289808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9310297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11148373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17303166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16636635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11402016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6162756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12439463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6594590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10821530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10260590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10217732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7403156.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5387597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17188444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11392275., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7745952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12522941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8550593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9294240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8200090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2666934.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5316014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8734161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4533325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12583570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4332186.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7958356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8476203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9193469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3370483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7480410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3996555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9953225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8411842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5378652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4072039.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8057633., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(18078826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9673106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1977395.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5414452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2083184.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8765224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6108916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8822361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3200916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10648278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2700795.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2782806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3914536.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4387997.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2290347.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4069672.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2520571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3253216.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6088988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1732992.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9223600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2589199.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12366208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8850980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8676814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20086690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10164016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7023168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8970437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7659806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8088845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12648021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15816478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10217588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8379769.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9539148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10276605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17314972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11510269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12307989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3270866.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8547289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17609582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12225744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12059201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9462345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17258060., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4119319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2412443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2241066.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3026024.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4006928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2486632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2935207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6654967.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2429298.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4401897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9542903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9099350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10286801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8625142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10379177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4445232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5225267.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11513805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16830048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6944655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5275098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6577959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12539835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7932518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13058996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12700304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11663488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8142365.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14746613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3845113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15048306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14119346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15924384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11883419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11374950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5801271.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7512514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7585262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9292774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7516183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2648827.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2923022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4602449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2516910.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7803117., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7157189.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7093854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6110655.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8906001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8044801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7780520.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3586203.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9949567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6509763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5732039.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8105798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6859987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7779112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11190016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2243313.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1249477.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1880354.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2770222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4051578.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1338272.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8986347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9444309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13742388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2397521.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4921858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4004135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4248744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2690257.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2749309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3950909.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4244711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2553172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6395813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5422370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13026456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9064363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9244877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6149468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3825177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3988715.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9645002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11503266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9544309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10768974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7588400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8378167.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5045673.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8180461.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17530748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7706322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8597102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12848302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8906139., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9203425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10052037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18259296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9170947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12977500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13555924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17129998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10663294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3518893.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4166845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6286304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3574581.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3285466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2805830.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3491932.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3764888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4489310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3764259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10268534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9107479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8542700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9185982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8340096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4627544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9143452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7415572.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4373651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12875179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10745789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13180741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10273876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10425819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10593078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13447532., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6362118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14860346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12193862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15879618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15682388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11152828., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14325769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6961476.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7323048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16014979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17394772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15110375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12655597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14211502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12384410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2914547.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6539146.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7063495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9114654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8498390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3924735.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2229655.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6537815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9680985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9295209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3729661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21277746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7133480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4731375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6347531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10470753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3705487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4977782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5563563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5870931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6934822.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5381832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3516174.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5885757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5295807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4605032.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2080649.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8573926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6137874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1504533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3969053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2976069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3034718.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3968498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3427339.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5845302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5164065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9108469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8804600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10427760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10376535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8001136.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3764107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13514689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9959799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14803227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4781927.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8220285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4533449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7525658.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12159782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8354110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15736092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11397085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13246547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12709502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14465508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19603320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21641592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12416138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5661842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13785632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3004444.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13242839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3543707.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4274539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1121572.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6585889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4365276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2410194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3685337.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4292568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3535409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4408441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11162389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9528299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6645219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10593891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10194316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7278438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8717667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7313243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15528122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15279844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11910321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8947518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11634106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8352446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11320012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10967020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12767870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11973386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13817400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12264090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10941157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10031457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9922492., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10630371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11801107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10297823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8061334.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10718368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7643531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6549979.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1620750.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8215291.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16418094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7364233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8877057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3576519.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11490428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8312952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4282136.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9352001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7430816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8567653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4598499., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4499183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6011224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14399744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7996103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4091859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7011288.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7653027.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4878270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3074160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4727105.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2710706.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4542263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3088422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8654103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8472216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6762952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4173746.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1975618.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4775595.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1111916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892336.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4355068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5337857.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6976119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7015882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8082606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6993332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1712218.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11086637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8938571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20277830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9757823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8622493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9229346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10765830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6020231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9431340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4769790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8176367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12218019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14137063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14812182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12390375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11371543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19098708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13235107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15682442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7552231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9291628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10210771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9333272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10866958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11946901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12635956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17554774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2865624.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2654319.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5696130.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6336835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2668100.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2821990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3247662.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3376541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3012827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1943994.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11101949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7265801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6621149.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6136310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8942814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7080633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11069822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10619770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15466776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12290095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10884241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13255934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14866837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12318471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12070127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10519209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12193611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12317937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13345432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5284380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15542596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10955204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15273256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2726393.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10795806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7893169.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11024795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7769384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9181971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10779343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6337889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4305157.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3743783.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7790867.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8099904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7833399.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16049040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7318241., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8316281.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5211844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3037398.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7560786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4478798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11338194., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5033561.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8952518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12055305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3457861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7886978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6342649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6497018.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3215164.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2378642.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1243937.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5310313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5702564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2652380.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2201278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5849674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6475662.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3757940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2358372.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2829472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1408829.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2305678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4071391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3833775.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4248814.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4125502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7569836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8513388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10389132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12388739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17659684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13104121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8580708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9239495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12171243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9563045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15076706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9720005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10215354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6921556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7847849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17077312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11508653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3419016.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12706716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8721542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4377042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4376999.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15078350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16978950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5723655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11844562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8924280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7556155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2511038.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2850490.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3996693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3887021.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4071459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3706894.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6030182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3413786.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4737760.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3964451.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13376026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6851736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6375479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12483326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10398995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8607578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9595229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11124820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11298544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10870644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12586483., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12670903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8934413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10881084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11166005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9681287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13519953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14861204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13305184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14211487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15422596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6795611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16356521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11266880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15780794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6037048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12023022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10349898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6001546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12399370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7268523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1561588., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306322.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3362809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5537437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10347138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4386226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2604629.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6994660.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9679671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5565852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3991155.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8697688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8157031.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6751400.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7832916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5617761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7161270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4259951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9464262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9778093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6171356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6473238.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4992815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4982988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1298284.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5772456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3121818.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5892259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2124608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4673662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5300829.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5174731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5683354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7128869.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3966370.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2419434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4944617.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5655539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4669575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10719944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10052433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12096327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14795112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6647916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3433124.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4532779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8749295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9198102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7616843.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8583348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7801295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2514937.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8001285., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11824431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6801790.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11159560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3190601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4837461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7068646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9137337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9581475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3029478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8337423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14819915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17567782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10946158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2125184.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5913664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3603263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2694580.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2740285.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2910563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2806698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4349541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7140243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11213384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9195220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6396583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11160466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7402034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10023866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12169744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11272626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12031417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11078966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10196036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8135834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7872255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10457150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11157368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9820724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13332577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11479652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9946496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14995311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10443762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6448650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5266411.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20290580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11937471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4870556.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26965384., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9652312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17498006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17820414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4467383.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7909918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8387506.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4971849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2454963.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159821.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6554251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3519614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9025195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4811988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13016220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3919733.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6468078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7569303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8351877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9429886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3406655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4529617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3881963., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6651750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6396637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6936577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9024834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1834129.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3056578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5644148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8730825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4868435.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5442385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1836569.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3744789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3009165.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5292858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3457619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4986309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4330318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3741688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5861064.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5595816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12601575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6558634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12708425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21677562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6201125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7765615.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18051826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10162990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21189540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13069573., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11606660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7496879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6517055.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12341089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9289198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11467399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2482171.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9512343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11725921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7861504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15439924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10409741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10358129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5002200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12303165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11010915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2041812.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1891716.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2780354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3626629.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957131.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5886340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4491651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1400705.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6638330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4581635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9540416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8815281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7374238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17716110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7160283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8732494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10628909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7515176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10533006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5887871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797096.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13325665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6485175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14689083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11010582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7352068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12532969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11946930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13171816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5807698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10889698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11368716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9792443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6946906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16344095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10749626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283391.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14519073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26230140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16121161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7982525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8357805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1507152.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10822155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9029314., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3130312.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6772189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4278280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7427796.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9605965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3873156.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5061975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949299.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12866682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4975903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3916137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11961230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11261407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5494519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6602457.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2904809.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2023788.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8769215., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3563981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4018996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6488080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5852152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3381935.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4193238.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1857615.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4673815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4031570.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3842099.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4134273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6113352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5330829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5815648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2058535.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12405188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11960577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14792924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4985285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20307182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4059981.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9742211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8944892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12375804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10792185., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3936744.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9178369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9666531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9591705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6915879.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9991545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8635037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12129747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9435916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8801697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12044956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6153759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9107600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9935451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4114682.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19396820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3054250.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3532753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3497968.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2618909.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4010318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3308190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3360117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4427250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2903135.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10351070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9215482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9212927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8561248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10447964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5102992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3049400.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14855829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9345287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11642097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10493305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12717700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10698836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6527142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10466363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9182430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12419973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8196133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14185936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14877736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12041633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5876943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11710026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166053.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4528173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16221593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14511646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8501550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5977859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4510521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16977142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4306755.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7440957.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6522496.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2261329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4088563.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9114830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3570201.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6399185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8788806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8549894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7697584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4873686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6982274.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5875768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6131822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8919206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7476696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8863870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8285321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6137020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5101540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5704309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3216922.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5876646.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2877722.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2775136.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2832518.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7552638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3682696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2159233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1554036.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2884361.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2066700.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2606707.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4318376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5701038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5880663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3547046.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5587528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10044173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7933523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5639715.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12216811., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4140244.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7546161.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17841838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18260416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4619340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7718852.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8293648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10463392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17766648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6370046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2543902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12096608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16306560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7221338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7797289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4382675.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20364134., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13273813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12202890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21137860., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4471681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15424424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10631820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3858971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9919119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3468539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5652325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2393469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4032589.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3512865.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6165092.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3198925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4498517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17592288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10100469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3868057.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3443141.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8634381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076301.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11446165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4508385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14947886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10986724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8974516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9411540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8406405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6982322.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13442168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10306639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11271267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11188396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10791032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14935383., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18268542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25757036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11635440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16107889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7606106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10995254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16715343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18382636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7532934.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15081930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4366536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7575360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3282763.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2793614.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8385427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1799841.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7980696.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6348855.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8689467., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8364457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3416466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16812386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7591647.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12728092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13030912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7612716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9337279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7413092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7618203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3210594.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5472103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5064770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5588721.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8649631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2249594.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9912017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5103010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5406800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6015595.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1746117.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6105428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6132462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6433777.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5662673.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4754374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3740598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2148423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5210541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6302074.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7367306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9332641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9527093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12425307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10848309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11551816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8706696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12901111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12206672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8620208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10853981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8328832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12238293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14011243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12255908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1948978.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4706636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10313717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14861132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9901930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14364546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8277649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6404200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9982785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14085820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10836087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12972771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11571389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2175564.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5750653.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2970004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4012625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3774313.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3438468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9186434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3521496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3482849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4621565.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10900159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10489984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7903056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10956542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8800378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8821180., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9072857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8793990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13170783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14139270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10216753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10043747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9398095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11690069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9065966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9934552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10418600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13985682., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12242805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13139706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12388474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10778793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10566975., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10553932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12539864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6321790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7699764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6245463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12000832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13716110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3945416.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7520448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7193259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6535378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2499326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6703010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8186232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6896909.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12750399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13007929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4696680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7966223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4653347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15232889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10937480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7951000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8074834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3156612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7528509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16662605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9110443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3174125.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6591921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8637337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2826053.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1980585.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5491595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971621.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2784640.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2763451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5923918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6151598.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2880416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5602367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5748573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3446687.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4325461.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4390850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8218564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6467781.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12326601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10198934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6565832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11895239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11743818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7467643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1912144.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1831343.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11374449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15118184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10224463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8785961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9140114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12068452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5052458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8110274.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9251737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4877595.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18191540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4405763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10671784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16128672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16377052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15647422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17178320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10043635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15133378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3227655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6327675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2816904.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3305860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3739995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2763542.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3462238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3341944.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9913944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8726853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6703989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8333863.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10776647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7535522.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8907329., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8748859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5980008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9456774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10926551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10058408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11043478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11837138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11539214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12015291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13249626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12375274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7010370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11586781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13015142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11357217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6062258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9950768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10592286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7484323.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10987506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17000298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6996214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16551848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9351496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12665111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8749161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4338200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6525622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13018543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7395997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11034604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5117478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11374675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3724924.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7560496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10402276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12388583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8609555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11668250., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5844662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7229297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8048250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4724231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5084403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6827396.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5403901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2105760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1270071.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4978367., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3317340.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9783689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5953132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9496714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3849079.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4731163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5103736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1879859.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3958488.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4540527., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2977180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2862119., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3173969.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4895800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5700657.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3794925.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13401653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12168184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13108145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11780877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12080729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9128491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14462717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9015836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8724852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8480475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10506399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9127569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17132326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10630508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13426900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4525589.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5053398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11686782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7647095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12470516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13125403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3358483.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10525720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8386265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10651417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22575952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3127687.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3615327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3007244.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3734926.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2329432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5765858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2747199.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3273984.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4283382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7118580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9148364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7095964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8045502., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17368970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7933171., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9880733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8406105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6264108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9946921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13028559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9187758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12350953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6399141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9545658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9970292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11147604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11587651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6918112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14761806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15813261., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6668211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6870528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14040300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11309703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13703989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10875190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10440319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10682991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7759599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20772270., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2153393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11515785., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7031944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4136295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12087237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2543006.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6808651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8614622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8469310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8684613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8038441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3020779.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5107938.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11493590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7856990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7516484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10414725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8412950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7215700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7799041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4720009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2933634.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3031595.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5617633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3886498.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4395903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2181350.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3451081.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6099513., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5822109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2895133.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2003093.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3812427.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5663483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4219415.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4749451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6595143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2360259.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3810951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7827417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3778343.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7382422.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9469126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1320301.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10525529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2687773.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4108624.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10168164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10846341., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13004958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12037273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7305067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6339117.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11485307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8548797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11564811., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4779601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9176889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19376484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14270231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11171064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9663795., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14272224., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8849203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10588667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5393220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13419562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5416022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3008283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6376949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5731879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3483011.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3563351.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3771052.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4279327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2416205.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4005507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6361206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8545969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9900465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8345397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11083484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8577105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9291481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11203766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14675235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13745632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12636256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12447043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8637344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9214613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5890032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9789298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9787868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13987831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14818669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11862248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11700356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12037281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11292408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9570922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13576396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17153234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6745966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6765198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6595416.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14102777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13518717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5073883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3213950.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5005152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12174924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2725339.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7857885.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4674896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10288541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16311841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9973766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5520528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8911793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13585660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10364415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9662623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8785877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7796471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15344947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8523778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9454595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2967546.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5716464.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3067007.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5361322.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5232467.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2564415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2694738.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5650311.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9455254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6949352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3745217.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3380276.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2767675.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2401566.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4319632.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7096898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3783603.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5171896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8431014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7293894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8384068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9016803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9941634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8690546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7318415.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7677697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9900579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6780639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7863393.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8005601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7261898.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8410750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5059979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17110604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19815626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8892332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1009523.5625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8128932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8266698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4337703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11855307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4875358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13159445., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9353746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15061095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12487265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10386290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2926607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3154515.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4095380.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2817139.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3922261.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5619499.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4519600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6499582.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4076028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4656752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10315825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9108411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6253156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8305252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8308449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6867840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10299754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9241460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8738578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11124177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9874883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9784346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16447068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11313094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13456615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10480883., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12300888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12200208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14260683., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16811212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7155397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7486037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9608363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7528644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11369470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10701823., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12838934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10088389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12512479., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13349687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6482520.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17387306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3713842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2695018.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4202465.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5623156.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8074020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8245564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3746876.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6182762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3388217.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7432310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16992308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13034529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6290278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8412368., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10685255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8126239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7133943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6427693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6453068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3159218.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9242433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6980268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8921137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4694596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8929862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5832851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6417351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1007351.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2933154.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3703891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738730.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1332792.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4427232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2525737.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6135006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3954537.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4476474.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7602092.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11085131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8399159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10155042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17565614., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8265875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10317299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14829615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13412525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11773359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12136319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11779264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8131472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11196788., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5513962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8796143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6758246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16797720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11839539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8089983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9168954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8514763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18323208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9205053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11765386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11857406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6092472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14601231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3643544.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1289138.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3584001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3464277.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1407203.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3223941.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3775376.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3436557.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3935925.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5284469., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9448913., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11106500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10525354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12669606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6913997.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3736879.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12369323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8100106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15492590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13769837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8889853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9392376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9241535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13235882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13986681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6182010.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10656020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11979123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14680199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12210609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10828670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14596041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10062906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11704631., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11370092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12041673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12536582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11053630., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11580497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9578056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8159744.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2959755.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7944018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6603753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5291870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7777466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9421380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5112243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7866862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8441006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8425547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5179981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7934638.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2864989.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6024685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6083682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13157979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16715328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12184787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4568116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2852223.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2152926.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8806290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2266904.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1262739.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5746674.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1584731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2390568.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3948722.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2222237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2474862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4181232.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1482201.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4750458., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5687679.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5811162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5688446.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4377835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3773250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9194752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8158620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8877518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8121454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12726205., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12124283., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7824421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12583622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(940495.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16374974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7908152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16690206., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10504999., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10289990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7202135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7410763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11695246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12355564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4732883.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8764237., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9403089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7812930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13301115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20085022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16979586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10490021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13348626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12087189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2930438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3449560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2590889.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3708157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712150.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4820719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4305132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4140273., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3234380., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4898720.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8454597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8470548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9750556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7384352.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9562702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9776203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7855909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7190506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12379636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12589642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9218420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3121765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4506560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9997401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10877084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9340190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11594162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14688358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11995938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13196946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10910804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3994462.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8612491., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6845035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16196756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7828726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12496864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10842284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13677518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13792413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7665619.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7348832.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165139.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2472064.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3789767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4411306.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8113708.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7934776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6721242., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13380259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4772347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4947481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7345985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8278252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5460333.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8054950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8156903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5283721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12415035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8768291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9832125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5916956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1144041.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10882088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6384987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8688943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5005468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5498515.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9547031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6604304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2851676.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5293506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2291145.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6196755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7135809.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3526825.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2088444.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4321611.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5547610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4701442.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13031516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8571227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9199973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11697348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8360027.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6092620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14253038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15680229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6349652.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7332240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17523086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7587794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14061260., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9196349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6972716.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14295873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10754815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3792199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11876542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9505583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14163417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10521749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15543605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2882503.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13100618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987822.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17854464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14766541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3150632.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4292954.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3384452.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3501929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2665040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2292954.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3437182.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3020977.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3191540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6666165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5939391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9364806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5433155.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10282699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8018262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2920050., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9168362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9990954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15855818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12750269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9487464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6841331., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9545781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14815653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13375162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9762718., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11371266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10114900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12257516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20288210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9274306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9890675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10091488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12491319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10173735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11824085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11514529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11068080., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11788505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7660936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3987409.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7726750.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3461897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10665462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5433438.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8916815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8135536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9442395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6932156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8686917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3914092.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7437160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17776124., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2856760.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22617798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6324033.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12337662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12747326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3127210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10238971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1361112.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9219622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2886712.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2229238.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5352763.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6108404.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10381858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3122305.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3289648.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3215709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4002679.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5215711.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5916448.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2681397.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4782156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6890535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5354280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3711783.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6818360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6762991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1413375.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7513616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7137951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9032943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3578938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10866246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10476318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12100026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5451391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9063536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19111582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7645903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12209702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10395255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4940680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12407498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11678534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6790616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11778530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13783969., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9350669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4931843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5840081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10743951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14635051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11191125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13669896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9424271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2800768.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3621135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4021609.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2784755.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3694568.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3368593.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2795871.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4281760.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3972531.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3169636.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9697931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6295194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8100798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10287792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13130747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9358783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11315044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8915719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9915813., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10104409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9371174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16496994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5105748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10542464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12023452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8877649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18321982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11888300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12953088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13933139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6438213.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16466133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5821875.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15878903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8006280.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10827302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13635276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9003911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11343814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18657010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13024165., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4123994.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7312958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5943664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9527070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3520625.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15940051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7823123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6303258., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7680620.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7295827.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3041738.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7201257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4819946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4874529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9763650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11999627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8881032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6542708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2377483.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3549327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5772179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3194174.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6017826.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8873232., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3487961.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7780617.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10241459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5640059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3880278.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5617526.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4432569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2766552.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4726872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5095806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4692297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4602063.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5824431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5134590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5270706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9054318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9040021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14461482., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17460706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6583318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9172684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5488149.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3091886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12368332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12890598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9277095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13905680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10223243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8744456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11139437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7881012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15656020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10943136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9567337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12826234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14645355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18240340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12311891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12079163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20072464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9853317., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13891096., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8596709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2757650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2648443.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6228791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2712752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3244952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2555474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1607216.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3169748.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4719640.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10595626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8844865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7001645.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9797393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7095958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9479008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10234433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11486082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12724600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12460842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9607500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6546376.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11312359., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11356590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13080111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6220857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11421340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14599191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12364806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16197962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4158039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1785909.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4866188.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11301931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11229903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12239476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7456565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17233976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14231781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7081534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7669925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8371486.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7212540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4099046.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22922720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3550150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7309543.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4778727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4435546.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3340783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5140307.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5864526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8053693.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10657509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6362659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8281234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8537910., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9697978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8088105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5221919.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6521625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8543098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9648419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1929238.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3443357.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5983127.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5671782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5588111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10470796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2201681.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2665574.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3768832.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5039805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4637488.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4341441.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1894609.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6974257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9064299., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6493972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(303318.4375, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(11482945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6685819.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8142613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11590104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11455398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12608662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13146966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8734110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9801426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10673909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8313256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14375562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6728876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6917402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11149647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11478053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8639637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7629099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5078316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16452354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9140880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8422090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7607370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5818211.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9471208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11366231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5349748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2351566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4299408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3267249.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1660663.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5110399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3260283.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5120309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6595915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3260707.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4999427.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12842095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6924540.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5347407.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9673002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10285839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5036055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7812753.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10095931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12197966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10191558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12003200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11836661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15541120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11261486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11069944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7325495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10148034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11605204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14481360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12631967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6812515.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6444135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10139033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4401522.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8472293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10194541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13250307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15952203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11313207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6681723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4948425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7813933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22923970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10057843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12762392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13629305., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3758782.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9272894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8557218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6735597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5748006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9788168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13713056., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8151629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11278662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8086213.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8433645., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3818482.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7505572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10379722., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4866928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3322748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8219725.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7268700.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2350195.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6001256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8341529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4600951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6490346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5480799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1710808.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1568325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4298566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2377637.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4490495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5077049.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2455602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4389499.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4102342.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3833941.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5628229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13034346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10526829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12288049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4222996.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6332808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12294443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10846671., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7223749., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18845348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10392510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949776.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12519782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4981263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10184934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18967112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7751575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6500201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12929805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10375622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2238168.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11600591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13625888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9303065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13356781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7758663., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10512834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14134000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3493200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5663993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3253197.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3226020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3552807.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2225439.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4741398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4785330.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4033515.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3785462.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10258425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8999256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8031454., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12768515., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15698102., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8591121., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14958617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8023538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13459388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8179636.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11931592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12226227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12066804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9285960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10405915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10385162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11076837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11108869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12749411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11928681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13791575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9776397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4921739.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12374397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8040934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12607753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9302026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15612705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10817393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13928802., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1607398.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12334279., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6213183.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3912089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12910256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7469046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6154054.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17549888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8170523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8190525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067170.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7162034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8267196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6831698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5877432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6799039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7621248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7110674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12172944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8325921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9752723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2793006.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1959625.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3188298.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4043503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5624825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6020843.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5121328.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5448310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2580229.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1583008.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112433.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4109834.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4071682.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7074329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397753.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2469107.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6506108.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7184040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6875035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4783850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9298174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6576729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9936195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18002936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12485189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12460036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7058573.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8532434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12954699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9553640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8475632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10339276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10957962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1215595.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8734525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9220128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13473407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7916596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8517426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10796523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10503798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15031709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13442041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17269422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9204126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20353654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2030569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1898023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3258409.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5747859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6634845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3548887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2785896.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3445551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3304582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4437660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8039633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9551074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7531217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9822166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9596507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8953289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10454408., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9182831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11322989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11831371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8939101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10358717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10974659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15575625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13094582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10210407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12616016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12095689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12818238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11971521., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6423027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1985816.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6595318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4340831.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11228950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10241422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6077740.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15253764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16793484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9439287., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4885436.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4827048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12060243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6187795.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7329753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3673069.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4433176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5171536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6368041.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5629985., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7318435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13339406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3559239.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12272371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7983217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9086875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10443650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8097516.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8032640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8444120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5063594.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17907732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6811945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5202991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9125150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2659007.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2276811.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3243270.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2137532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5603784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2956359.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2074970.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2782561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047489.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2558220.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5091152.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6544132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1811751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3848956.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3249532.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12244371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3027333.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11275535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12100946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11575417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10846077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11020020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13735993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18061672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6673975.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8149583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8708001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8158232.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16700735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7920911.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10139413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10415940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10150525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13623176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9666554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5265848., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10797702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9042857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3711165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15476138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6642154.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3532531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5538367.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2737230.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3322666., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3770998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3127616.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4374806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3302717.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4260541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5269762., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13308544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11089470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10105044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9305779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5317466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11130310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9155714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11865745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15567908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10620409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9421434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9311897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9558917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10912294., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16753379., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18394002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11941495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12545490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12944253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3592823.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16006772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8696981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5133244.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11976604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12354370., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8152585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11665404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13073278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19052596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13402603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6535974., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4309874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5717160.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7478664.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9727944., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8908821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11020345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7842412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7855695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3356382.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9441924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8415315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6467836.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8905753., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5747625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11580187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7115669.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8293834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5095455.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9591604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6179310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2960495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18177980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6325203.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5947843.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5568138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2427597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2460217.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3633856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2872793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3634048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1896338.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5991521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5181797., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3714202., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4476138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4333854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5170720., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8192593., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037516.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10327986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9488145., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8359560.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10552107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7645903.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3832508.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4710858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7282756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9937049., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4253459.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9031244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11289098., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2662967.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1033448.5625, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14753099., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3826831.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6006237.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9197040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11224278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11206559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11255152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13245668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9980536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10914717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5390368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13402726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13129536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3517086.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3523617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3747256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6338314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3876706.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4271315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3514506.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3512449.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4369596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4314152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13626347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6574162.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12880149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10066311., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3209210.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6789384.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11589470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9030031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10484440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8249506.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2925215.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12293591., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11009084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11636074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10759316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10002201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11244794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13769375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13735996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10149764., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6784439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10836362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7521148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15426323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11244146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6206819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12214324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12395097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12408553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12910837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3495111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7501580.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11737350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6009477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6397259.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5383741., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7111632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12134900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4077078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9519198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13315328., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2461596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13111829., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9583106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5563249.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7111414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7120497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4196562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6276012.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4031437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5684800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5611475.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1434816.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1184010.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3093205.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8419397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5372087.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3973994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6106325.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4945475.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5507293.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5707933., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4544809.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4921440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4774980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2571411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5230767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3005937.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6335281.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4033239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7812002.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9410609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10341460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8128220.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4475053.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11663936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12419612., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10774977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2767952., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8184153.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9143381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8050281.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12067468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10127756., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9786565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16846646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13729435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8659847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9464055., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11063836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9702032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10598560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17890854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14181235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7211782.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7560625.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11656942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6674466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1487197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3758702.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3999149.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3182833.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4343077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2289642.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2987586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5303650.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3180313.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6731059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10121678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9169330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7524782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12482560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14926621., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10048882., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6956640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7149340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11610500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10869432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9710991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11977771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10692557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14001937., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(9473438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9649745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11095870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10688625., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9597815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7543095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5773530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4687080.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6225561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7686310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10835803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7572727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28638534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5056406., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15328990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10900665., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6886393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5747864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4676536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11178245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11028024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23025414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3721638.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5463836.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7462796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6354453.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13733733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3236962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6021818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8366896.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10218873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13542700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8858211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4593893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5035798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9790400., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4450366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6884424.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8880228., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2818271.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4274835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3472116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3597074.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9597881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3790329.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4267882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1816660.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2414291., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4654921.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1719040.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5946073.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1278506.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5017446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2487362.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6078071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7142419.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7044085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8636803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8607965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10151155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7372519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8908070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8620423., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9314600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12263599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4526708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9935936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11874705., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13729506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6671345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9808675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9158244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9934885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9015875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10739454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4286835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4715932.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14056216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12217109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14753820., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15080569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10839646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21654358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2989062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2956721., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3865501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4517249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6912654.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3219738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1871096.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3986071.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3891793.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4159572.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13139561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6938884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9844118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8585945., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10197905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8776136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8681272., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9377234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8925010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11446516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16993048., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9553598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15705525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9155940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10070307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10339200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11856522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11206057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14474111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19797316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7584854.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14791437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9711917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4527804.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10681265., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7379051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8168238., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9637600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9356858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18512298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4788783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7653624.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8673020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12340982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5388842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9680487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3639742., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9038938., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4444980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5146327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738752.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12561330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6920860.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10519858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3719597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7720761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9841859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5231425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6851789.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9150077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4667596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2125042.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4667971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5698511.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7727358.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(1373990.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3800296.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5441429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6539353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14260643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2032275.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4067989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3816133.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5037109.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2332745.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3835761.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957661.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3151208.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5144530., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5307936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2836508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4247560., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2651958.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8345203.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6587284.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9366411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8448834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3599033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7722069.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9182166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4661528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5855619., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11525727., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9174604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11894476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16761173., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5683144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16094312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9605140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11947852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8544814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10122715., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10599568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11941941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8452161., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3047677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10999567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8589415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2967533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1210902.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5583386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5655140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6305063., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3381587.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5683195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4161689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3294965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4756302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8675654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8864658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6378123., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9554065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8248806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13455683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11870071., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9804109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10547576., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10291880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10745563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9484310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7747086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12046786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9671155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10495692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13030638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7711061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12754930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12666363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10385088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10160227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5934366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9652176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11509598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7348548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6546053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12703651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7657378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5753937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4670827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4385017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4257849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11969051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9721101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6915144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7080808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12452172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2495506.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8518510., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8153630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6524509.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4912204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7450095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8092088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8393884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8884610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6790185.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4712013.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10920652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5580181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2647990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1811148.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5370740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6514919.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6138839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2546761.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4823918., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6637783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3847179.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3002058.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5991368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3769419.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4677263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5132602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4644950.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4085893.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2374651.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4088056.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7586535.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4948092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1828356.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10188092., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11000928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16748101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11886586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12199547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3294755.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3919397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8685725., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3738252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15521371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3936618.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10957067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4043263.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11546337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9223659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12252757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9193950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8092261.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3656866.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4167183.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15972676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16510979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10438338., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(8906716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18659912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2892610.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5865321.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3861974.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3977472.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3434142.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3914897.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3514353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2400478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3984549., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4418314.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8595072., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8780347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6101101.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10208640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10440389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10860407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9133109., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11458954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11990650., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10005983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8893176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9277466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9650032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9700887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10496660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13277353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12320461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11561939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14535306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11656438., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10992029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8909443., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11854758., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7735362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12798662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7305390.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8002135.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11096698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12398598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6879565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7070452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13331651., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2896043.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12280357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10769781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8293506.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7295061.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5066437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8376457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5608881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4419373.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7736769.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5253052.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4500034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8647196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9461746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3868169.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6795093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13328125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14198160., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10133231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2973829.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2411307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3241396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2602277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2886354.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9468660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5794332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2147208.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3815112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4036589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233193.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5910082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4765263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8765824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3701478.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3876841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3643882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3166862.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4251289.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4677107.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9301606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13770405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19214540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9006524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7753768.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10101702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7703165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6541286.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17234780., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11948133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3693229.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20230900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2571661.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11548397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8224574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(855748.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7447371.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3277108.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4766888.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17660506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20514044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9347878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14303470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14082214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7588138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14841451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5694475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3387682.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2931682.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3823623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3975216.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2981297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2880145.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3612928.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047385., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9043783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13513450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8898312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8050534.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148732.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10047713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9337429., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9227997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9258292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13147175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12134020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9019841., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8713141., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9637073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12693643., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9320870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13773498., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11195274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11594878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19517188., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12368236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10292542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5844477., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10944113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16187735., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10467446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11827165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16927962., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(16404799., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11385358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12159789., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6893372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3425191.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4461801.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7315585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7356394.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8415864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7915095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3480095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6744092.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5838034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2492667.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10078506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3595630.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9457887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8092020., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11397661., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5231356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3477675., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4233246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5233336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5191975.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6538636., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5678326.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2540577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5420516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8771428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5833342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1994934.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2157871.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7074496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2643511.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3100952.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3522032.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112390.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1274886.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4422363.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5199468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4383848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3771225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6574628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6936570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14508306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6527186.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9958220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12104032., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3824773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6557563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3926914.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9774009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6423256.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2110716.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13809268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11784297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6510662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14695736., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7898169.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5795882.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10967472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12079198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9435165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8732871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15366320., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12281464., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7037565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13790629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8784180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12474222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18908710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(975015.6875, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3111792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3245547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2657171.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6517480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4444592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5980572.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1768038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3048377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3830775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10885949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7072257.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7624418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6287500.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9716833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13591239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13412253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8926372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11444862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11807528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9240388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8659356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9199872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13239492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6387696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9241808., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8196993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13527106., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15155932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13390176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10285547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6808295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14817204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6596747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7020126., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11737218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13148895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15762966., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12894460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14275893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7531731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4264547.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6903848.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2920059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9692246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8563435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12232919., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13153807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6990131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3654906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5086364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7192590.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7650821.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9805888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8306354.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10219251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7519754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6996805.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4435226., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12960976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1293088.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11022567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4860139.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3060720.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9314129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4394631.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5191180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4501835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13275065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5465214.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2564173.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4971887.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6301027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4125262.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4126225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4799681.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2411619.7500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5002744., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4301983.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8928093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7988068.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11607915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5848180.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14398022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12221470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13409748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6585800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4560351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10062407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14317257., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11635480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17709120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10520289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(965768.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11713757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202203., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12050389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16535433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9313413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4763165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1963033.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11613127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16256127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15287587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13963214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17067200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11964704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14050814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3806800.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6845730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3095409.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1027437.4375, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3146202.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3183499.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2811262.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6345865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3514027.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4957541.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8057550.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7388460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8774602., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10523118., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8313422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8621334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9887528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9045508., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11593703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13390815., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8228729.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13170038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10536719., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11004713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10289623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12928776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10827804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13559075., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15301190., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15406277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11416005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4047676.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14583415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17165838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10179611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7598067.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(28514014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7463319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13213292., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14690683., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7183447.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6871006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4626263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2663037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3967104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9396991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4518677.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7197336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4360830.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4935309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6872967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5030461., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13281239., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9692738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8623842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4449859.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9430922., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8584069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12089760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13043028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9756835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3471152.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4343284.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2123534.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1369646.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5801893.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2770850.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2193191.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3252042.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5677098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5010779., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3536959.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5100353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9053751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2547375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7134660.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3941172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3749878.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7775608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6731039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6734904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9684098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6505614.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8558644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18951346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7422684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6693160.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4409078.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7448236.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12584827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4020757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(830288.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7775947.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7921278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6264819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10015656., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10746657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12597590., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7393971.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12173083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10265002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8484574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9936471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12776490., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15363132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9613543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3598423.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13797130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2528091.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4249695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3603566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3302740., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2488257.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4993568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2762198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3145332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4287072.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7288778.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8165859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8840346., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7364381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7401250.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8924771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10483290., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13687760., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8935392., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11766837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13166003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9081198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9509084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8372772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11704402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11050169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10442609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11251333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14788516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15056796., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14134433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15617350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9024028., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5350386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16050460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15159642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7625246.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10783855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8410216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12768879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6463353.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22271618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1528476.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2555418.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5153773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8642296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6766372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6728264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8276851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8941703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8775672., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6454200.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12660524., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11922319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5112744.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4165564.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9510869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5157568.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4784228.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5784259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5316090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9649759., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4183632., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5646039.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1362858.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5797115., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2674427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3070133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4596667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11494738., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2822644.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3539851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3883869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4826369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2134559.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4406706.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5308182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5068842.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5748129.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8149235., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9043111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10572403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7327857., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9504047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6532531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9736439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8032450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15423984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8451094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4060679.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9390695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15730859., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9497417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14918531., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6570493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4376039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9669737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8042366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10485309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6953538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4979550., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10833033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14515739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9518314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9965886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12776322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14154537., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3699208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3798851.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3074770.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5479648.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2483429.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3873348.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2758487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3368272.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3468978.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9033426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5932569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8965271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7694488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14572192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8942995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2915031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9151277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12249150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10243696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12617220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9746991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2844851.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10377416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9466388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10406459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15929234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11550082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12291222., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13961546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15274255., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6866862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11512667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8993186., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9734120., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10005892., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10562042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17362930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5896053., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10534839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14532340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12630896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7332905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4132854.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6958749.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18277074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8465710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3151349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8180395.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5644869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8203765., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(7890426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8456571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5310983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2781940., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10934327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4037293.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5297419.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11894689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6256781., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12723554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3337144.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6563784., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4803699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8816210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6268668., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5554065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6250172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5724577.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2798897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2959625.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2992504.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6209039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4547840.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3607043.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2059759.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5754902.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4509986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6973971.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2504889., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5761638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1685199.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8713175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9096070., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9098960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611112.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3680331.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9249298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9669459., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10233801., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762340., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7029175., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8177649.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8915083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6760372.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11349541., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8228850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6201916.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4188194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11265686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13515412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15021518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15485964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16561308., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9150772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14423774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20929256., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13811064., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9020655., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3539277.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3342581.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2734995.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2983304.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4080172.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3344449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3348010.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3989410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6872187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4680264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10929778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11548843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8144065.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9306598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10561466., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5568366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11102399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8525992., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11146111., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12124904., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9394421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10339153., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8352837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11683024., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17452144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9371044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9528624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12647835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12925881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14842577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9900716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14418809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3288123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7367090., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7647511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4414104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8010295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4420118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9973548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14270350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7635909.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3313765.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8522909., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2081744.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9399364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8342378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8445637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3865620.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6168963.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18015006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7826166., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12454017., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10278989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7162058., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12949846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4978468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5002252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7105428.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9097451., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5195519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7130605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7153027.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1212653.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9214880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4252545.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10166043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2122629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4797887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3679159.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9207866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4259807.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5287659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4449113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6578307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4014742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6340726., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4006177.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485400.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5560458.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4665310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7506829.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13243589., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6145694.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8134234.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12169162., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13955046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8752040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9207921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10854970., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(4551198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8899635., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14128229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11993723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13166533., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8327057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11043164., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13265494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3764271.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13992901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9449786., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8336071.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11769551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5856657.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14886545., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7612265.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10006627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10211344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6615572.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5024191.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3527529.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1166814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5996074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3512055.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3743324.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6095046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3588134.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6659028.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9176082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9542147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8691833., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9674582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9192538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8646432., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13190837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9640543., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4881534., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11631046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10265996., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15854774., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10139585., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5116413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9619076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10989031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8566233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11086304., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9939568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12402223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14918107., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12663965., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11190152., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5624163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5203901.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11489822., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14896253., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8316906., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6287338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11120900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7172767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3475864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2122539.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4074737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3528753.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5397512.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5373935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7672148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7915971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7965076.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12878076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5580935., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7819222.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12952373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13125967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6242892.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23292018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8675817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174857.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4704165.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9556454., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5316695., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5314995.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2552656.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11820551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6638706., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5814224.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1323478.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2683669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3355519.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6907190.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3400020.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3446445.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2316033.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1718104.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4759201., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3870086.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3091565.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2779166.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7732837.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4086633.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5395609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8799082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9518921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4187916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14819047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10206140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9314771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13763746., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9543394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12812426., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12060987., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4344456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8225751.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3287931., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9482837., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10571870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12066849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14279442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12497213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5404870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16996460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13560074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16567035., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14277179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8891548., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7523044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15238687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12534809., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3022835.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3695509.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3017406.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4014263.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2915309.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9628680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1198209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5459947.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4258955.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5367689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7070835.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5716767.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8073977., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9605264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8702323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9086023., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11072979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10608196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10414757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10903951., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9484988., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(10113807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2534914.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9844087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10434007., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9760686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11041181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11033928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14393582., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13858472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4111019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26068234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3907770.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12326729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6834798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5487761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13187418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10527926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7270816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17824236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13105617., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4267821.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9206554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3931169.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4507723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8377711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2842263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7370933.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3322139.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6265385.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113030.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7919358.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8204970.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7662756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8831026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9490962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8334846.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12663496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4885773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8478697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3256112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2014562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6395990.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10324826., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9643262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5337680.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10031396., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6079948.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1885505.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3894977.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3732920.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(844581.9375, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5679057.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1631395.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5225044.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6198251., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2866903.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2511765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4032164.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4270333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4294448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3835189.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9125830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7912974.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3814798.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18507772., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10793506., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9977457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9094264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7781583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11624187., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10273743., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8977151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6464989.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8762523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(949469.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11927518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13077084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9397213., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4647085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16996022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9658714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5187264.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11394998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5411838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7615832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15114958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3198468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4056102.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1775142.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2768240.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3788171.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3936257.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8473608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4469516., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3983227.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3897530.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8894165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7457000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10089353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9315941., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6882002.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5443936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11422197., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8986068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18455646., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11351898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2615362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9296888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12626914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13877091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10117416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7263787., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13259748., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11839381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12372357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12849798., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5774239.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10662605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10687052., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11313414., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11160364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4531789.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2993139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7002137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14372716., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8991669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12555086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9888319., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2551561.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5282193.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(23122690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7040782., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9152988., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6925808.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13919208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14897397., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4679756.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8213431.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7544669., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7990315.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6274571.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8464439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8600775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8412062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8086523.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(3650130., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5355407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6137069.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5140466.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3160997.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5092119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397044.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2021417.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9434460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2083638., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4821597.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5277098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3872229., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3480229.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4104001.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2675744.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4562805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1556852.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9117002., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3254888.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(264056.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8985440., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8260540., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6655146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4171028.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14418544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3777661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11214046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5684640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4263316., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11943165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7437993., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10628850., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9120923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8071689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12637767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6173760.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14167470., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11912817., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4381097.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16524704., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12001009., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9214208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17015790., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8698733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10095875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15054685., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10633018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3332067.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3674677.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3303332.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4094315.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3623326.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3959858.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3394362.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4156622.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3983765.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4801746.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8549468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12405900., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8568629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7186147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7752972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7497452., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9348350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11402681., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8153836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11025507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7964861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16825838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12105061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7543635.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13164198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10022447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6630450.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12220648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14272473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15160101., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10110847., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3616563.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5973775.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4064238.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11679603., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11404792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8041881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9792149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14025281., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14121278., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4606072.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7734246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2479876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7744501.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4277561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8070212., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7335547.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7518794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6407942.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9776501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4674739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9883855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8236132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7617835., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4032937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4391528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3824272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7745405.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7357413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13494475., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6743600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6755245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3265422.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5653411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7348089.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9143156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5179562.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17087398., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2402438.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3700938.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2803800.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4798853.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3837666.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3697942.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4610008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1454186.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1987649.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2617588.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4762136., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3865243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10051127., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3720514.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2415503.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7485420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3730384.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13715139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6771456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9425830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6435869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6687639.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8428138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11908315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11574427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9598284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11564437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148230., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7229555.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19092176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9005123., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(12233566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12264866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14902303., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13760155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8880363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9294564., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4664151., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11804878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13149339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6581140.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3586988.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3814469.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3718689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2565296.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3447670.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3831845.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3953711.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485591.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4353526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13283773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8877983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7119539.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9211794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9199608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7024484.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10860628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9887641., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13375692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10767844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6721327.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10673536., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8294605.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7913921., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10783567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7154773.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13855792., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12553623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12708492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12861943., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4566113.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9287915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8357807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3539316.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19770418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9478337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12751214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12043863., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16414761., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14246382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1332883.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7297885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4426431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4174222.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9791043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2476246.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7848623.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4000103., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7450048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4805719.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13282600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13323794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5670578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7143223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7919278.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8006533.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7418917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3444131.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11971191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21930946., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5935277., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5462664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1919058.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9500844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5676332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4348686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9983010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9217402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8237157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4524723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2309596.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(813680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1927240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5973536.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6568615.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2745669.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2042873.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3982048.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6581452.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6789610.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7354076., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11693915., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8812044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10528547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11679116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8873958., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9521997., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9411702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6885518., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13617670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9129079., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13570131., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8816679., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9336577., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8635664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14044176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6028697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11086811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9415139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4568507.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12395616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15045686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3570730.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12122446., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16981480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5027306., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7742807., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13439708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3814376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3327611.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1690445.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2129491.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6098517.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3355260.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5389330., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3333609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4112034.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6070626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10245598., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7826895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6723017.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7930104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5739910.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8711982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9711356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9238964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5174682.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14385492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5271531.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10724387., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9061045., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11466561., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10115354., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17025956., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9253605., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14218081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12807984., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16478300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6355852., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(6679015.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6353244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15207832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4869998.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9726649., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13127739., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9821098., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13165271., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12652378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4277217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2706470.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4716231., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8111450., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5603029.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7261622.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8604218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7989983., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12661332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6021022.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5630159.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5415137.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13167575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2808546., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7688014.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9508214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5272336.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6771325., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2872521.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13038686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6619021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6778439.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6367803.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9713163., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6438437.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5967865., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17701022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4764381., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6784581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7337551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1691448.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4698867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6377939.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2415666.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9753407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5275966.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2326618.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5501145.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1873595.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4576584., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8879611., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10409497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2225800.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8213034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14984982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4166753.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16904244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12488587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9413568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11725254., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9344898., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(904913.6875, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15094184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8966312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8884047., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6603607., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9324457., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7556343., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9127069., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13589036., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10624702., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11317567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15277634., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4997196.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12381351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9466040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14800989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21464108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2472262.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3011342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3786495.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2090184.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1815669.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2558119.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4387813.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3292834.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3376175.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4358395.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1933967.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6240896., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9969395., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10556012., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12975250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10383061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11054293., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9051425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11331378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12320067., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9732680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9835653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7545476., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10474840., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10884472., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13429559., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10944893., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11833276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20267366., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13674754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5381252., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8739207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9692345., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5579420., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11105664., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15960125., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(22908628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14912616., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15638775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10321351., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8689263., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4206321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4590386.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2973832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9235401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13527875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6743093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9420337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3899923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5242363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4899718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3679645.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2786496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9576062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8856723., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4261711.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5434888., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8322077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9886332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12404268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7647871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6071340.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2844126.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1222901.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1795734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5028642., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8016078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4942122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9865773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7349768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2379636.2500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2875177.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3288849.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3923157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1216757.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3806270.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4171983.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4954755., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4848885., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3142381.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3614026.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11212572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2856398.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9955713., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8987733., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9536062., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17567428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1245602.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6759478., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12691647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11553667., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3220688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17336486., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8627928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11920937., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3624863.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10612211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10983089., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16969912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10485041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8518424., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8982097., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20157140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7441361., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9452821., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627925., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5001972.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14566734., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3451788.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2301120.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(941356.4375, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6364954., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2914844.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1717711.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4007997.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4095525.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3705419.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4224684., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11008140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9095565., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10019427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10443897., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11601018., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8499039., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9704262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10307871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14534338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13122142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12627033., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9597757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9886687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17552040., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9839022., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15722791., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15050609., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14278388., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12335623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12945180., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10243300., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11827149., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8148982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5990408.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14991923., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16966692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17738862., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7005082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11241819., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16444433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8519302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3528269.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6999382.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5105394.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4611794.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9347430., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10657402., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8677596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7288917.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6086525., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4113602.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7705697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7549776., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7313349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9493041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15074042., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5457731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8971501., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6799615.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8051518.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3008786.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4639804., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9128566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9667955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3778930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3190198., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2872091., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3693051., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2593014.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10939391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4142406.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4711407., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3344520.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3673372.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7279244., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1777873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6885858., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4068095., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6894872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514708., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7244326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9311288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6410914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8235747., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7093110.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13935314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10797031., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12246342., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8611411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11271773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8343978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9164961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8019552.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5190926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4717731., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12822777., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9863908., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12074526., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11606274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10899737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8076048.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1809516.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8852709., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17219298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11817389., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10243158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12174732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12656116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3029219.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3443468.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2754174.7500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(2792769.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1879597.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1763528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3799728.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514074., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4467313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4313427., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12966444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7309652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10123357., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10578972., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8691960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9782135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8822600., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7839323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10516262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13268333., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9224332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9242220., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9460240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9592894., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13802574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9374995., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9874981., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18539234., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14468386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14551535., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11082356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14264810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11592949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7400487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(26562604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7028689.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7353644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4618390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5066586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12272247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1329375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7355712.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4052490.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3981374.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4156377.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17938410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8356662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3170437., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6254907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8261980.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7296187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5310899.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13696678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4229356.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6190494., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14670570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7718594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8516178., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4494114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3884480.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1350355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5833307., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9051832., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5407318.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5879688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3263989.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3221257.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3441237.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034337., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7200073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3854234.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1397295.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5242704.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1612103.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4492041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4956236.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5399752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2956289.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6887627.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4248085., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8997899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8914227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(461094.3438, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7301284., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11674562., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6178556., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11973547., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7886586., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5589825., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9299158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8388463.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3336379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8072263.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4957603.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7821551.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7296622.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7724143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10267082., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8496088., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13673021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10046687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18828596., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13717929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11545872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4568806.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12738838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15646658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13028484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3712190.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3721997.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8600144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6534871., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3705507., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2357771., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2775391., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4089091.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4192526.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4276692.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11172610., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9494372., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9174404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3676219., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11164010., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7210177.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8476105., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8613227., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8369172., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12739077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8055170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12529877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11117991., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7977529., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12811595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9636065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8177511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11833046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14786347., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(19619000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10699086., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11909867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8855016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6845231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16626505., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7737551., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(27559274., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11130422., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12069309., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9928137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7289124.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4084829.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4359079., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(20342834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9165352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4085139., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3341362., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7394527.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3989601.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5356960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4973000., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9785827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8628615., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8000435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6063129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10968310., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13017654., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7124874.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6711087., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4088011., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3549221.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5916268., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10699267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5426366.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3504298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5592155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6527873.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5998103.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2031196.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6095920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3301105.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3504412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4074679.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3502843., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1851553., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5695311.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4485900.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3465593.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1804969.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6849026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1436928.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8126133., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6554179., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11537934., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4755123.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6307780.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1910154.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12043880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5038918.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10092355., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10450710., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13993890., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10278845., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11406128., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8027657., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12840580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9535980., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3718198.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12883409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9306425., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9372386., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10767538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15209084., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9844504., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12548514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13441628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7949469.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6585765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9235417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3355506.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4546572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1086613.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8577884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3574468., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2237587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4000243.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4334727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6544231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10824805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8070463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2276912., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9532986., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12733401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8271711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10188065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9924971., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13417094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13200810., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8949322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9257266., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11167318., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11162276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8517827., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12590008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10426594., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12522415., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7510737., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12762644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6847975.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6127731.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5323199., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10002794., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4571566., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14125979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13022182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10809754., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17429496., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9045371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2885953.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8660626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4004389.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8352248.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4757773., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8324155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6820332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8438405., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6724652.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6111872., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7244742.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4317866.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8054468.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13000289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9598436., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5093597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13558041., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9274449., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7559231.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13844421., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6671973., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3535939., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4908390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3187661.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17008886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2464472.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1797122.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5327548.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2353116.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3025339.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2584427.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2092285.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514350., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3449613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5890571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3397581.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2832021.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3591595.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2391642.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3957599.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1479030.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7047814.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7009969., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(816428.4375, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8670377., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8286217.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9109029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14898884., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9275688., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6643034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10325751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11512019., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7639432.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10252861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10258195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8392196., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7678301.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3722504.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13323855., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5295901., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11714717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8158599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9885412., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12195824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20163842., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9408653., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9626404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13229542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4116262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3321095.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2470943.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2764981.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2488436.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4713920., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(792951.1875, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6694393., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9275592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4041775., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8302903., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11439495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7744687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3507254.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9575034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4327607.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11422269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3073393.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11195803., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11711382., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10495344., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9316658., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9133878., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10265108., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10472110., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11393522., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10926652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12118416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13093942., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11277322., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(25322606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8801399., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10816793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14803673., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11642373., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3501148.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11963916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6585899., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4644116., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12858137., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6535380.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8203569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6850905., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7413259., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9261419., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20896296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4414497., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8073081.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1529876., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7907143., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13062176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7691509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8426142., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4640286., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9191169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7717815.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4356571., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9639334., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4734730., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12537066., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6111660., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5291024.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2311520.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5329696., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7803132., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5152698.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1227939.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4804456.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3210268.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2669195.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2125809.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1350364.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4514924., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1668444.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3649548.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4597257.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4512390.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5757569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2998195.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3836778.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9196844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21346192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9728864., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11001492., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7137550.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7253368.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4200288., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11739580., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9717025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11563210., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11959849., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12941844., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4090276.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10076767., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10025418., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8010273.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13738836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8375462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14818873., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7972019.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15433276., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11507628., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14268332., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13213447., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9583267., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13695245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5093613., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6091936., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2636474.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8520861., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5488784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(985855.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3863444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4352936.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2734788.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4413148., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3123027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3651989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5643326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8337038., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6625312., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5641618., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12712772., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13386324., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11016104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8949473., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11302413., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10589587., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11845209., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9385217., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9078578., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9234269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11742298., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9171250., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12076852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11168021., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12741538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10573417., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10503460., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13659500., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3767274.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11961700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7148703., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12697211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4639769., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11573686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17353416., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14050575., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8087586.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7933686., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8454156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3343569., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8356751., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11317181., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8276727.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5145369., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7853979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4205718.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3970987.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7701511., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7338223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8133778., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3823975.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10243243., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20749698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14422001., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3160272.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7585905.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11023870., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2934083.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2088048.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9564579., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2378302.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5416016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3103170., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6115697., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13421114., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9910165., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2521762.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1243133.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4940542.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1640864.3750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1268731.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1495404.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4772375., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5327481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2455395.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4280953., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2474874., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12655225., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9040949., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10238013., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8499770., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9932104., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11349208., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14798280., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10219814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12801488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12527932., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6465247., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4010959., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8290090.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11602462., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12806599., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4870498.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17349214., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12518223., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9141302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6835176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8439360., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9932026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10510138., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16092376., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12738970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5608221., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13966818., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2799743.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3333488.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2946060.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2967572.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6551699.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3112869., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3304665.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4111637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3408506.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6478313., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12573846., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7028360.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5160970.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10717410., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6958539., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6324037., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8246356., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8818583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9349156., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10117528., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12688763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16127674., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11014404., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8481880., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11599879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7317329.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10442374., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11689484., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11363394., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12151358., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10297979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3627052.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10153481., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20906046., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7564824., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10738363., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16391189., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10734495., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10950004., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7703554., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13336463., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4554928., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1454991.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3034573.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7966596.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4939558., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4365930., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3465566.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3214597., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7954678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8024139.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7558129., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3248053.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4748294.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12710428., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5539295.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5556633., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3650291.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6892917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8300637., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5216804.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8845112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4873569.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5251866., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5798276.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2721550.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7353659.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2811902., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3092413.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4145929., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8722339., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1247419.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8998647., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2302676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1834291.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5586204.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3300608.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4360442., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1268372.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6927723.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7365651.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7083686.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8262321., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11624493., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6983310.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8778629., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8973027., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18050976., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9034216., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6373989., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6935093., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11540352., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11647441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13651990., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8712295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14146297., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11375439., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6039225.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10525155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11922248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14216750., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10370157., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9322296., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5615689., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17324982., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9576503., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12551811., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13936583., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3657997.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3590250.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10021200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5528204., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2841353.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2831949.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4354065., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9003627., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4738081., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3996593.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10314626., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10745073., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6447409., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7035805., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6446119.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6633115.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10838191., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8741852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11023338., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11885140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9853729., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10133678., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8888289., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10038195., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13083218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8179448., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5449659., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13740005., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13244371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12547509., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9707474., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11326765., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8477572., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9823192., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4374905.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11425717., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12435623., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7579021.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17222644., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13946724., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11605962., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7306140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6198640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2996876.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10293403., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9202465., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10857349., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5378648., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3210761.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12140687., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(18778026., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7921834.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9136914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2762993.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8135879., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9625852., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20556236., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7586480., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3754194.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5525736.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7160182.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2103228.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4943187.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3446089.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1379194.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1929892.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6716014., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8593112., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9072806., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5983961., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(750471.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4250766., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2918078., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1360017.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5711003., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6059323., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1998512.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5736622., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7562174., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5249315., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11906433., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11706150., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7066523.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11822763., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11806911., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8580059., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14637608., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11246568., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8163542., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9837327., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10268029., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7963391.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8933488., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7708667.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7417763.5000, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(5978663.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11161113., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6646528.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11435624., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13198567., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4280519., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17465240., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9945295., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12638680., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9150967., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9638994., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9946233., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11015834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3142230.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6254784.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6600168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2949954.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2971715.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3053262., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2496435., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5963783., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8794955., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4138862.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10267714., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6939168.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8578411., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10369836., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9526514., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9425856., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10847793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7682175.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12261083., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10815670., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12151927., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12743926., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6536044., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12167008., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11509159., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9008877., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10550555., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14529947., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8108745., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12334122., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9507487., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10280207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9873218., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7262907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8522712., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12171732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10407814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7251695.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14211431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17919016., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3655793., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6878662.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3383831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7551523., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7858914., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7794563., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9308640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7475211., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6711854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12286182., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3690367.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21069158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7171023.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8295444., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17914698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8808428., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9108015., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3772853., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4826134.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9172025., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3449266.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1877000.6250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11662970., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3372308.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1335721.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1255522.1250, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5495379.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6516891., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5235282., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4395441., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2782964., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3599140.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2592211.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4073481.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4151410.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6415369.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1088264., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4834557., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7443595., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8172895., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1608000.8750, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12045006., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4988800., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6822932.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3724752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8972135., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8401249., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7414554.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11490698., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3714814., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4220991.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7583907., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12470326., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9028302., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8644077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9761732., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8011158., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9449917., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5459747.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8760365., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11278830., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5001314., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11543077., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11599831., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7907875., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3370163.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(21965434., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11852960., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3598731.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2879390., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3385757., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2540144.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6323951.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3986381.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3474604., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2316774.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2998221.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4476486.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12558601., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7045068., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3971906.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10601167., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6718538., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10872057., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10726246., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9049348., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9848401., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16791140., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10110245., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9575700., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8637043., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15028248., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10297978., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8270592., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10410639., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12096891., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is  tensor(13123144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12796147., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10512662., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16008378., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7870200., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9633620., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11909752., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7521960.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11093998., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5924139.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6388269., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10313176., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6631358.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2499860.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10989207., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7085652., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6763709.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7792375.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6261034., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9074177., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3049091.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9105692., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12092061., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6657456., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10226691., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6787155., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9182887., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7894768., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9073867., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13489868., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8102574., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8331179.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1219508.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2620684.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4407353., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3321676., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2855916., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(1199854., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3388957.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6089886., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3567973.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6893979., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5133606., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5501711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5567787.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2666529.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7679349.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(2393093.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4205699., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4985834., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7027690., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3336558.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5752547.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10645168., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9078544., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(7871197.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(14516144., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(13887371., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8785169., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(15154570., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(9129364., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11361146., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10294640., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10932881., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10054184., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(6797876.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8551471., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(12936816., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(4426118.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3503268.2500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(17294950., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(11652711., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3836700.7500, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10341431., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(3993558.5000, grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(8409094., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(5003839., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(16818838., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(20376552., grad_fn=<AddBackward0>)\n",
      "The loss is  tensor(10893537., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] 拒绝访问。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-be5bbfa13722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# source_image = plt.imread(inputs[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\synchronize.py\u001b[0m in \u001b[0;36m__getstate__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicate_for_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36mduplicate_for_child\u001b[1;34m(self, handle)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mget_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytouch\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mduplicate\u001b[1;34m(handle, target_process, inheritable)\u001b[0m\n\u001b[0;32m     75\u001b[0m         return _winapi.DuplicateHandle(\n\u001b[0;32m     76\u001b[0m             \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetCurrentProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_process\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             0, inheritable, _winapi.DUPLICATE_SAME_ACCESS)\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msteal_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_pid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] 拒绝访问。"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs = data\n",
    "        # source_image = plt.imread(inputs[0])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        source_image = Image.open(inputs[0]).convert('RGB')\n",
    "        # image = transform_1(source_image).unsqueeze(0)\n",
    "        # width, height = source_image.size\n",
    "        source_image1 = transform_1(source_image)\n",
    "        # image_tensor = source_image1.to(device, torch.float)\n",
    "        # source_image1 = torch.from_numpy(source_image).float()\n",
    "        # source_image1 = source_image1.type(torch.FloatTensor)\n",
    "        image_tensor= source_image1.unsqueeze(0)\n",
    "        \n",
    "        image_tensor = Variable(image_tensor)\n",
    "        \n",
    "        \n",
    "        \n",
    "        target_image = Image.open(target_image_array[i]).convert('RGB')\n",
    "        # image = transform_1(target_image).unsqueeze(0)\n",
    "        target_image1 = transform_1(target_image)\n",
    "        target_image_tensor= target_image1.unsqueeze(0)\n",
    "        target_image_tensor = Variable(target_image_tensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        x_1,x_2,y_1,y_2 = reg_net(image_tensor,target_image_tensor)\n",
    "        # plt.imshow(image)\n",
    "        # plt.imshow(target_image)\n",
    "        source_image_landmark = source_image_landmarks[i]\n",
    "        current = pd.read_csv(source_image_landmark)\n",
    "        X = current['X']\n",
    "        Y = current['Y']\n",
    "        # X = X.transpose()\n",
    "        X = torch.FloatTensor(X[:70])\n",
    "        X = X.unsqueeze(0)\n",
    "        \n",
    "        Y = torch.FloatTensor(Y[:70])\n",
    "        Y = Y.unsqueeze(0)\n",
    "        loss_1 = loss(x_1, X)\n",
    "        loss_2 = loss(x_2, Y)\n",
    "        \n",
    "        ######\n",
    "        target_image_landmark = target_image_landmarks[i]\n",
    "        current = pd.read_csv(target_image_landmark)\n",
    "        X = current['X']\n",
    "        Y = current['Y']\n",
    "        \n",
    "        X = torch.FloatTensor(X[:70])\n",
    "        X = X.unsqueeze(0)\n",
    "        \n",
    "        Y = torch.FloatTensor(Y[:70])\n",
    "        Y = Y.unsqueeze(0)\n",
    "        \n",
    "        loss_3 = loss(y_1, X)\n",
    "        loss_4 = loss(y_2, Y)\n",
    "        \n",
    "        \n",
    "        loss_all = loss_1+loss_2+loss_3+loss_4\n",
    "        loss_all.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        print(\"The loss is \",loss_all)\n",
    "        \n",
    "    \n",
    "print(x_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9935435\n",
    "50788820\n",
    "1689682\n",
    "10893537"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
