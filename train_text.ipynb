{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from model.fcn import fcnRegressor\n",
    "from config_folder_guard import config_folder_guard\n",
    "from gen_batches import gen_batches\n",
    "from logger import my_logger as logger\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/COAD_01/scale-25pc/S3.jpg\n",
      "images/COAD_01/scale-25pc/S3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "def read_csv_file():\n",
    "\n",
    "\n",
    "    DATASET_MEDIUM_DIR = 'dataset_medium.csv'\n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "    imgs_dirs = []\n",
    "    dataset_read_result = pd.read_csv(DATASET_MEDIUM_DIR)\n",
    "    i = 0\n",
    "    for each_img_dir, \\\n",
    "        each_landmarks_dir, \\\n",
    "        each_target_image, \\\n",
    "        each_target_landmarks, \\\n",
    "        each_status in zip(dataset_read_result['Source image'],\n",
    "                           dataset_read_result['Source landmarks'],\n",
    "                           dataset_read_result['Target image'],\n",
    "                           dataset_read_result['Target landmarks'],\n",
    "                           dataset_read_result['status']):\n",
    "        each_img_dir = 'images/' + each_img_dir\n",
    "        each_landmarks_dir = 'landmarks/' + each_landmarks_dir\n",
    "        each_target_image = 'images/' + each_target_image\n",
    "        each_target_landmarks = 'landmarks/' + each_target_landmarks\n",
    "\n",
    "        dataset_read_result.set_value(index=i, col='Source image', value=each_img_dir)\n",
    "        dataset_read_result.set_value(index=i, col='Source landmarks', value=each_landmarks_dir)\n",
    "        dataset_read_result.set_value(index=i, col='Target image', value=each_target_image)\n",
    "        dataset_read_result.set_value(index=i, col='Target landmarks', value=each_target_landmarks)\n",
    "\n",
    "        imgs_dirs.append(each_img_dir)\n",
    "        i = i + 1\n",
    "\n",
    "    print(dataset_read_result['Source image'][1])\n",
    "    print(imgs_dirs[1])\n",
    "    return dataset_read_result\n",
    "\n",
    "\n",
    "dataset_read_result = read_csv_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches(dataset_read_result):\n",
    "    source_image_array = dataset_read_result['Source image']\n",
    "    target_image_array = dataset_read_result['Target image']\n",
    "\n",
    "    # 如果参考图像数量和待配准图像数量不同，那么意味着出错了\n",
    "    assert len(source_image_array) == len(target_image_array)\n",
    "\n",
    "    source_image_array = tf.cast(source_image_array, tf.string)\n",
    "    target_image_array = tf.cast(target_image_array, tf.string)\n",
    "\n",
    "    input_queue = tf.train.slice_input_producer([source_image_array, target_image_array])\n",
    "    source_image_array = tf.read_file(input_queue[0])\n",
    "    target_image_array = tf.read_file(input_queue[1])\n",
    "    source_image_array = tf.image.decode_jpeg(source_image_array, channels=3)\n",
    "    target_image_array = tf.image.decode_jpeg(target_image_array, channels=3)\n",
    "\n",
    "    # resize\n",
    "    source_image_array = tf.image.resize_images(source_image_array, [128, 128], method=tf.image.ResizeMethod.BICUBIC)\n",
    "    target_image_array = tf.image.resize_images(target_image_array, [128, 128], method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "    source_image_array = tf.cast(source_image_array, tf.float32)\n",
    "    target_image_array = tf.cast(target_image_array, tf.float32)\n",
    "\n",
    "    source_image_array = tf.image.per_image_standardization(source_image_array)\n",
    "    target_image_array = tf.image.per_image_standardization(target_image_array)\n",
    "\n",
    "    # 标准化数据\n",
    "    source_image_array, target_image_array = tf.train.batch([source_image_array, target_image_array],\n",
    "                                                            batch_size=10,\n",
    "                                                            num_threads=32,  # 线程\n",
    "                                                            capacity=256)\n",
    "    return source_image_array, target_image_array\n",
    "\n",
    "\n",
    "source_image_array, target_image_array = gen_batches(dataset_read_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-bbda1636cf59>:4: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'>, OOM when allocating tensor with shape[12747,11956,3] and type uint8 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\n",
      "\t [[{{node DecodeJpeg_1}} = DecodeJpeg[acceptable_fraction=1, channels=3, dct_method=\"\", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile_1)]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "source_image_array, target_image_array = sess.run([source_image_array, target_image_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
